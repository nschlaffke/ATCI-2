Number at position 1 =   3.00
Number at position 2 =   6.00
Number at position 3 =  18.00
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.68468 seconds. Average reconstruction error is: 29.6438
 epoch 2/20. Took 0.67642 seconds. Average reconstruction error is: 16.7001
 epoch 3/20. Took 0.64432 seconds. Average reconstruction error is: 14.2818
 epoch 4/20. Took 0.67675 seconds. Average reconstruction error is: 12.946
 epoch 5/20. Took 0.67065 seconds. Average reconstruction error is: 12.0418
 epoch 6/20. Took 0.75521 seconds. Average reconstruction error is: 11.3252
 epoch 7/20. Took 0.68002 seconds. Average reconstruction error is: 10.8105
 epoch 8/20. Took 0.67633 seconds. Average reconstruction error is: 10.4091
 epoch 9/20. Took 0.65707 seconds. Average reconstruction error is: 10.084
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.67961 seconds. Average reconstruction error is: 29.4687
 epoch 2/20. Took 0.67771 seconds. Average reconstruction error is: 16.8682
 epoch 3/20. Took 0.66453 seconds. Average reconstruction error is: 14.434
 epoch 4/20. Took 0.69304 seconds. Average reconstruction error is: 13.1031
 epoch 5/20. Took 0.73457 seconds. Average reconstruction error is: 12.19
 epoch 6/20. Took 0.6776 seconds. Average reconstruction error is: 11.5028
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 2000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 5000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000$$$Pretrain: 0trainingExamples: 10000epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.713 seconds. Average reconstruction error is: 30.0694
 epoch 2/20. Took 0.69659 seconds. Average reconstruction error is: 17.0562
 epoch 3/20. Took 0.65782 seconds. Average reconstruction error is: 14.5016
 epoch 4/20. Took 0.68295 seconds. Average reconstruction error is: 13.1337
 epoch 5/20. Took 0.62638 seconds. Average reconstruction error is: 12.1862
 epoch 6/20. Took 0.68979 seconds. Average reconstruction error is: 11.4764
 epoch 7/20. Took 0.64509 seconds. Average reconstruction error is: 10.9377
 epoch 8/20. Took 0.66631 seconds. Average reconstruction error is: 10.4999
 epoch 9/20. Took 0.65853 seconds. Average reconstruction error is: 10.1665
 epoch 10/20. Took 0.66774 seconds. Average reconstruction error is: 9.8893
 epoch 11/20. Took 0.71626 seconds. Average reconstruction error is: 9.6651
 epoch 12/20. Took 0.61859 seconds. Average reconstruction error is: 9.4856
 epoch 13/20. Took 0.63968 seconds. Average reconstruction error is: 9.3896
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.67818 seconds. Average reconstruction error is: 29.806
 epoch 2/20. Took 0.64037 seconds. Average reconstruction error is: 16.8487
 epoch 3/20. Took 0.67375 seconds. Average reconstruction error is: 14.4769
 epoch 4/20. Took 0.66621 seconds. Average reconstruction error is: 13.1251
 epoch 5/20. Took 0.6935 seconds. Average reconstruction error is: 12.2037
 epoch 6/20. Took 0.70088 seconds. Average reconstruction error is: 11.5403
 epoch 7/20. Took 0.63912 seconds. Average reconstruction error is: 11.018
 epoch 8/20. Took 0.664 seconds. Average reconstruction error is: 10.5514
 epoch 9/20. Took 0.67412 seconds. Average reconstruction error is: 10.2386
 epoch 10/20. Took 0.69558 seconds. Average reconstruction error is: 9.9551
 epoch 11/20. Took 0.72898 seconds. Average reconstruction error is: 9.7508
 epoch 12/20. Took 0.70012 seconds. Average reconstruction error is: 9.5944
 epoch 13/20. Took 0.67822 seconds. Average reconstruction error is: 9.4386
 epoch 14/20. Took 0.67077 seconds. Average reconstruction error is: 9.3025
 epoch 15/20. Took 0.65907 seconds. Average reconstruction error is: 9.1953
 epoch 16/20. Took 0.64543 seconds. Average reconstruction error is: 9.1336
 epoch 17/20. Took 0.67811 seconds. Average reconstruction error is: 9.0142
if system_dependent('IsDebugMode')==1, dbquit; end
rbmtrain
{Not enough input arguments.

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('rbmtrain', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/ToolboxDeepLearning/DBN/rbmtrain.m', 2)" style="font-weight:bold">rbmtrain</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/ToolboxDeepLearning/DBN/rbmtrain.m',2,0)">line 2</a>)
    assert(isfloat(x), 'x must be a float');
} 
rbmtrain
{Not enough input arguments.

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('rbmtrain', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/ToolboxDeepLearning/DBN/rbmtrain.m', 2)" style="font-weight:bold">rbmtrain</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/ToolboxDeepLearning/DBN/rbmtrain.m',2,0)">line 2</a>)
    assert(isfloat(x), 'x must be a float');
} 
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 2000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 5000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 1.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 2.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 50.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 200.000000	 learningRateBP: 0.001000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.100000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.010000
$$$Pretrain: 0.000000	trainingExamples: 10000.000000	epochsBP: 200.000000	hiddenLayers: 3.000000	hiddenUnits: 500.000000	 learningRateBP: 0.001000
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
if system_dependent('IsDebugMode')==1, dbcont; end
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.70417 seconds. Average reconstruction error is: 30.7191
 epoch 2/20. Took 0.71132 seconds. Average reconstruction error is: 17.343
 epoch 3/20. Took 0.66532 seconds. Average reconstruction error is: 14.7874
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	 learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	 learningRateBP: 0.001000
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010000
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001000
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 5000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 500	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 50	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 200	learningRateBP: 0.001
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.100
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.010
$$$Pretrain: 0	trainingExamples: 10000	epochsBP: 200	hiddenLayers: 3	hiddenUnits: 500	learningRateBP: 0.001
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 3 (200  200  200)
Training binary-binary RBM in layer 1 (784  200) with CD1 for 20 epochs (batchsize: 100)
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: 0	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
{Error using <a href="matlab:matlab.internal.language.introspective.errorDocCallback('LoadData_MNIST')" style="font-weight:bold">LoadData_MNIST</a>
Too many input arguments.

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 42)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',42,0)">line 42</a>)
                   Data = LoadData_MNIST(trainingExamples);
} 
x = 30 * 4

x =

   120

[50] * 3

ans =

   150

v=repmat(500,360,1);
v

v =

   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500
   500

v=repmat(500,360,-1);
v

v =

  3600 empty <a href="matlab:helpPopup double" style="font-weight:bold">double</a> matrix

v=repmat(500,1);
v

v =

   500

v=repmat(50, 3);
v

v =

    50    50    50
    50    50    50
    50    50    50

v=repmat(50, 1, 3);
v

v =

    50    50    50

DeepBPN_RBM_example_complete_MNIST
{Undefined function or variable 'pretrain'.

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 42)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',42,0)">line 42</a>)
                   pretrain, trainingExamples, epochsBP, hiddenLayers, hiddenUnits, learningRateBP);
} 
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.31171 seconds. 
  Full-batch training loss = 0.599435, test loss = 0.589667
  Training set accuracy = 0.868700, Test set accuracy = 0.870900
 epoch 2/20. Took 0.18728 seconds. 
  Full-batch training loss = 0.413656, test loss = 0.413797
  Training set accuracy = 0.889500, Test set accuracy = 0.889300
 epoch 3/20. Took 0.18489 seconds. 
  Full-batch training loss = 0.336638, test loss = 0.345084
  Training set accuracy = 0.912100, Test set accuracy = 0.905800
 epoch 4/20. Took 0.17881 seconds. 
  Full-batch training loss = 0.301291, test loss = 0.317260
  Training set accuracy = 0.918800, Test set accuracy = 0.907800
 epoch 5/20. Took 0.19506 seconds. 
  Full-batch training loss = 0.276301, test loss = 0.296633
  Training set accuracy = 0.923900, Test set accuracy = 0.914300
 epoch 6/20. Took 0.18982 seconds. 
  Full-batch training loss = 0.257468, test loss = 0.284651
  Training set accuracy = 0.929000, Test set accuracy = 0.916200
 epoch 7/20. Took 0.17705 seconds. 
  Full-batch training loss = 0.241475, test loss = 0.272846
  Training set accuracy = 0.934200, Test set accuracy = 0.920700
 epoch 8/20. Took 0.17588 seconds. 
  Full-batch training loss = 0.227583, test loss = 0.263331
  Training set accuracy = 0.937500, Test set accuracy = 0.924500
 epoch 9/20. Took 0.18059 seconds. 
  Full-batch training loss = 0.212340, test loss = 0.251749
  Training set accuracy = 0.943100, Test set accuracy = 0.927900
 epoch 10/20. Took 0.19821 seconds. 
  Full-batch training loss = 0.203079, test loss = 0.247202
  Training set accuracy = 0.944500, Test set accuracy = 0.929400
 epoch 11/20. Took 0.19941 seconds. 
  Full-batch training loss = 0.191514, test loss = 0.239612
  Training set accuracy = 0.948900, Test set accuracy = 0.930600
 epoch 12/20. Took 0.18421 seconds. 
  Full-batch training loss = 0.183191, test loss = 0.234808
  Training set accuracy = 0.949900, Test set accuracy = 0.932900
 epoch 13/20. Took 0.17722 seconds. 
  Full-batch training loss = 0.172982, test loss = 0.226767
  Training set accuracy = 0.954000, Test set accuracy = 0.934600
 epoch 14/20. Took 0.17578 seconds. 
  Full-batch training loss = 0.170452, test loss = 0.229926
  Training set accuracy = 0.953900, Test set accuracy = 0.933500
 epoch 15/20. Took 0.18385 seconds. 
  Full-batch training loss = 0.157054, test loss = 0.218423
  Training set accuracy = 0.958200, Test set accuracy = 0.935800
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.22851 seconds. 
  Full-batch training loss = 0.612414, test loss = 0.601913
  Training set accuracy = 0.854300, Test set accuracy = 0.856500
 epoch 2/200. Took 0.17216 seconds. 
  Full-batch training loss = 0.412139, test loss = 0.414152
  Training set accuracy = 0.893800, Test set accuracy = 0.892400
 epoch 3/200. Took 0.19479 seconds. 
  Full-batch training loss = 0.341318, test loss = 0.349244
  Training set accuracy = 0.905100, Test set accuracy = 0.905000
 epoch 4/200. Took 0.17747 seconds. 
  Full-batch training loss = 0.304888, test loss = 0.320355
  Training set accuracy = 0.914000, Test set accuracy = 0.910400
 epoch 5/200. Took 0.17155 seconds. 
  Full-batch training loss = 0.275240, test loss = 0.296696
  Training set accuracy = 0.922400, Test set accuracy = 0.916000
 epoch 6/200. Took 0.19809 seconds. 
  Full-batch training loss = 0.253557, test loss = 0.281213
  Training set accuracy = 0.931500, Test set accuracy = 0.922200
 epoch 7/200. Took 0.17149 seconds. 
  Full-batch training loss = 0.242385, test loss = 0.274255
  Training set accuracy = 0.933400, Test set accuracy = 0.920600
 epoch 8/200. Took 0.18046 seconds. 
  Full-batch training loss = 0.226965, test loss = 0.263654
  Training set accuracy = 0.936500, Test set accuracy = 0.922600
 epoch 9/200. Took 0.16949 seconds. 
  Full-batch training loss = 0.212160, test loss = 0.254394
  Training set accuracy = 0.942000, Test set accuracy = 0.923200
 epoch 10/200. Took 0.17749 seconds. 
  Full-batch training loss = 0.201989, test loss = 0.247394
  Training set accuracy = 0.945600, Test set accuracy = 0.930000
 epoch 11/200. Took 0.19427 seconds. 
  Full-batch training loss = 0.193166, test loss = 0.243679
  Training set accuracy = 0.946700, Test set accuracy = 0.929700
 epoch 12/200. Took 0.1726 seconds. 
  Full-batch training loss = 0.182690, test loss = 0.235269
  Training set accuracy = 0.950700, Test set accuracy = 0.929600
 epoch 13/200. Took 0.16015 seconds. 
  Full-batch training loss = 0.172023, test loss = 0.229509
  Training set accuracy = 0.953700, Test set accuracy = 0.931300
 epoch 14/200. Took 0.17072 seconds. 
  Full-batch training loss = 0.164487, test loss = 0.224486
  Training set accuracy = 0.957600, Test set accuracy = 0.933000
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 2	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 10000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 2 (50  50)
Training NN  (784   50   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.26984 seconds. 
  Full-batch training loss = 1.721677, test loss = 1.707720
  Training set accuracy = 0.520400, Test set accuracy = 0.526700
 epoch 2/200. Took 0.19955 seconds. 
  Full-batch training loss = 0.786257, test loss = 0.768626
  Training set accuracy = 0.764600, Test set accuracy = 0.777900
 epoch 3/200. Took 0.19649 seconds. 
  Full-batch training loss = 0.541162, test loss = 0.526493
  Training set accuracy = 0.840100, Test set accuracy = 0.842700
 epoch 4/200. Took 0.20903 seconds. 
  Full-batch training loss = 0.421399, test loss = 0.414015
  Training set accuracy = 0.881700, Test set accuracy = 0.881800
 epoch 5/200. Took 0.19992 seconds. 
  Full-batch training loss = 0.363550, test loss = 0.364184
  Training set accuracy = 0.893900, Test set accuracy = 0.896700
 epoch 6/200. Took 0.21769 seconds. 
  Full-batch training loss = 0.326207, test loss = 0.334777
  Training set accuracy = 0.903600, Test set accuracy = 0.903400
 epoch 7/200. Took 0.19454 seconds. 
  Full-batch training loss = 0.298650, test loss = 0.312524
  Training set accuracy = 0.911800, Test set accuracy = 0.908400
 epoch 8/200. Took 0.19971 seconds. 
  Full-batch training loss = 0.276079, test loss = 0.293348
  Training set accuracy = 0.917900, Test set accuracy = 0.914800
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Setting parameters
Start Training
{Reference to non-existent field 'train_x'.

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_train_model', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m', 14)" style="font-weight:bold">DeepBPN_RBM_train_model</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m',14,0)">line 14</a>)
  r = randperm(size(Data.train_x,1));

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 55)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',55,0)">line 55</a>)
                   [DBNNet BPNNet] = DeepBPN_RBM_train_model (Data, ReducedData, Network);
} 
opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m',14,0)
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
{Output argument "imdb" (and maybe others) not assigned during call to "LoadData_MNIST_".

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 45)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',45,0)">line 45</a>)
                   Data = LoadData_MNIST_(trainingExamples);
} 
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
{Index exceeds the number of array elements (2000).

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_train_model', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m', 15)" style="font-weight:bold">DeepBPN_RBM_train_model</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m',15,0)">line 15</a>)
  Data.train_x = Data.train_x(r(1:ReducedData),:);

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 55)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',55,0)">line 55</a>)
                   [DBNNet BPNNet] = DeepBPN_RBM_train_model (Data, ReducedData, Network);
} 
opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_train_model.m',15,0)
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.070283 seconds. 
  Full-batch training loss = 1.756618, test loss = 1.776042
  Training set accuracy = 0.623500, Test set accuracy = 0.613600
 epoch 2/200. Took 0.029916 seconds. 
  Full-batch training loss = 1.173212, test loss = 1.216818
  Training set accuracy = 0.763500, Test set accuracy = 0.731100
 epoch 3/200. Took 0.031391 seconds. 
  Full-batch training loss = 0.844145, test loss = 0.890041
  Training set accuracy = 0.816000, Test set accuracy = 0.790900
 epoch 4/200. Took 0.032856 seconds. 
  Full-batch training loss = 0.667949, test loss = 0.712662
  Training set accuracy = 0.858000, Test set accuracy = 0.835300
 epoch 5/200. Took 0.032893 seconds. 
  Full-batch training loss = 0.562548, test loss = 0.612852
  Training set accuracy = 0.876500, Test set accuracy = 0.854100
 epoch 6/200. Took 0.031049 seconds. 
  Full-batch training loss = 0.497910, test loss = 0.553330
  Training set accuracy = 0.880500, Test set accuracy = 0.861100
 epoch 7/200. Took 0.03082 seconds. 
  Full-batch training loss = 0.443982, test loss = 0.504852
  Training set accuracy = 0.898000, Test set accuracy = 0.876900
 epoch 8/200. Took 0.029378 seconds. 
  Full-batch training loss = 0.401760, test loss = 0.471155
  Training set accuracy = 0.903500, Test set accuracy = 0.879700
 epoch 9/200. Took 0.029371 seconds. 
  Full-batch training loss = 0.373528, test loss = 0.452204
  Training set accuracy = 0.908000, Test set accuracy = 0.879900
 epoch 10/200. Took 0.028965 seconds. 
  Full-batch training loss = 0.346414, test loss = 0.426123
  Training set accuracy = 0.916500, Test set accuracy = 0.887000
 epoch 11/200. Took 0.034136 seconds. 
  Full-batch training loss = 0.327853, test loss = 0.416817
  Training set accuracy = 0.915500, Test set accuracy = 0.884700
 epoch 12/200. Took 0.030202 seconds. 
  Full-batch training loss = 0.308660, test loss = 0.403290
  Training set accuracy = 0.927000, Test set accuracy = 0.889500
 epoch 13/200. Took 0.030505 seconds. 
  Full-batch training loss = 0.294340, test loss = 0.392342
  Training set accuracy = 0.925000, Test set accuracy = 0.891400
 epoch 14/200. Took 0.033054 seconds. 
  Full-batch training loss = 0.280695, test loss = 0.386466
  Training set accuracy = 0.932000, Test set accuracy = 0.890900
 epoch 15/200. Took 0.031262 seconds. 
  Full-batch training loss = 0.266461, test loss = 0.380759
  Training set accuracy = 0.935500, Test set accuracy = 0.893400
 epoch 16/200. Took 0.029917 seconds. 
  Full-batch training loss = 0.260541, test loss = 0.379499
  Training set accuracy = 0.932000, Test set accuracy = 0.889700
 epoch 17/200. Took 0.030588 seconds. 
  Full-batch training loss = 0.245267, test loss = 0.369912
  Training set accuracy = 0.940500, Test set accuracy = 0.894200
 epoch 18/200. Took 0.029249 seconds. 
  Full-batch training loss = 0.236317, test loss = 0.365199
  Training set accuracy = 0.939000, Test set accuracy = 0.894500
 epoch 19/200. Took 0.028075 seconds. 
  Full-batch training loss = 0.228119, test loss = 0.365235
  Training set accuracy = 0.944000, Test set accuracy = 0.894700
 epoch 20/200. Took 0.032908 seconds. 
  Full-batch training loss = 0.220247, test loss = 0.363159
  Training set accuracy = 0.947500, Test set accuracy = 0.893100
 epoch 21/200. Took 0.028901 seconds. 
  Full-batch training loss = 0.212391, test loss = 0.357586
  Training set accuracy = 0.947500, Test set accuracy = 0.896400
 epoch 22/200. Took 0.030041 seconds. 
  Full-batch training loss = 0.203052, test loss = 0.352783
  Training set accuracy = 0.948000, Test set accuracy = 0.897800
 epoch 23/200. Took 0.033024 seconds. 
  Full-batch training loss = 0.197295, test loss = 0.351115
  Training set accuracy = 0.950500, Test set accuracy = 0.896800
 epoch 24/200. Took 0.032411 seconds. 
  Full-batch training loss = 0.191641, test loss = 0.354497
  Training set accuracy = 0.952500, Test set accuracy = 0.895400
 epoch 25/200. Took 0.031203 seconds. 
  Full-batch training loss = 0.185186, test loss = 0.352522
  Training set accuracy = 0.954500, Test set accuracy = 0.896300
 epoch 26/200. Took 0.040369 seconds. 
  Full-batch training loss = 0.178345, test loss = 0.350650
  Training set accuracy = 0.956000, Test set accuracy = 0.896500
 epoch 27/200. Took 0.033355 seconds. 
  Full-batch training loss = 0.170151, test loss = 0.343547
  Training set accuracy = 0.958500, Test set accuracy = 0.899900
 epoch 28/200. Took 0.031996 seconds. 
  Full-batch training loss = 0.167930, test loss = 0.347637
  Training set accuracy = 0.957000, Test set accuracy = 0.896200
 epoch 29/200. Took 0.037765 seconds. 
  Full-batch training loss = 0.159305, test loss = 0.341642
  Training set accuracy = 0.961000, Test set accuracy = 0.899300
 epoch 30/200. Took 0.02967 seconds. 
  Full-batch training loss = 0.156178, test loss = 0.341435
  Training set accuracy = 0.963000, Test set accuracy = 0.899800
 epoch 31/200. Took 0.029879 seconds. 
  Full-batch training loss = 0.150695, test loss = 0.341986
  Training set accuracy = 0.965500, Test set accuracy = 0.900000
 epoch 32/200. Took 0.033394 seconds. 
  Full-batch training loss = 0.145218, test loss = 0.340887
  Training set accuracy = 0.968000, Test set accuracy = 0.901300
 epoch 33/200. Took 0.038725 seconds. 
  Full-batch training loss = 0.141236, test loss = 0.339750
  Training set accuracy = 0.966500, Test set accuracy = 0.900000
 epoch 34/200. Took 0.031661 seconds. 
  Full-batch training loss = 0.137812, test loss = 0.344809
  Training set accuracy = 0.966500, Test set accuracy = 0.899000
 epoch 35/200. Took 0.0341 seconds. 
  Full-batch training loss = 0.134635, test loss = 0.342697
  Training set accuracy = 0.968000, Test set accuracy = 0.897800
 epoch 36/200. Took 0.029496 seconds. 
  Full-batch training loss = 0.128031, test loss = 0.337361
  Training set accuracy = 0.973500, Test set accuracy = 0.899900
 epoch 37/200. Took 0.029255 seconds. 
  Full-batch training loss = 0.124829, test loss = 0.341381
  Training set accuracy = 0.971500, Test set accuracy = 0.900500
 epoch 38/200. Took 0.028382 seconds. 
  Full-batch training loss = 0.120611, test loss = 0.340837
  Training set accuracy = 0.973500, Test set accuracy = 0.900400
 epoch 39/200. Took 0.030534 seconds. 
  Full-batch training loss = 0.118310, test loss = 0.338878
  Training set accuracy = 0.974000, Test set accuracy = 0.900700
 epoch 40/200. Took 0.029326 seconds. 
  Full-batch training loss = 0.114803, test loss = 0.338206
  Training set accuracy = 0.977500, Test set accuracy = 0.901000
 epoch 41/200. Took 0.030947 seconds. 
  Full-batch training loss = 0.109803, test loss = 0.336771
  Training set accuracy = 0.977000, Test set accuracy = 0.900100
 epoch 42/200. Took 0.029631 seconds. 
  Full-batch training loss = 0.107636, test loss = 0.339319
  Training set accuracy = 0.981500, Test set accuracy = 0.900400
 epoch 43/200. Took 0.037151 seconds. 
  Full-batch training loss = 0.103481, test loss = 0.338337
  Training set accuracy = 0.980500, Test set accuracy = 0.900400
 epoch 44/200. Took 0.032842 seconds. 
  Full-batch training loss = 0.100438, test loss = 0.338379
  Training set accuracy = 0.982000, Test set accuracy = 0.901000
 epoch 45/200. Took 0.030782 seconds. 
  Full-batch training loss = 0.097655, test loss = 0.336647
  Training set accuracy = 0.982500, Test set accuracy = 0.901500
 epoch 46/200. Took 0.031623 seconds. 
  Full-batch training loss = 0.095575, test loss = 0.338267
  Training set accuracy = 0.985000, Test set accuracy = 0.900400
 epoch 47/200. Took 0.033025 seconds. 
  Full-batch training loss = 0.092655, test loss = 0.338676
  Training set accuracy = 0.984000, Test set accuracy = 0.901300
 epoch 48/200. Took 0.033429 seconds. 
  Full-batch training loss = 0.090533, test loss = 0.344320
  Training set accuracy = 0.985500, Test set accuracy = 0.898900
 epoch 49/200. Took 0.028516 seconds. 
  Full-batch training loss = 0.087122, test loss = 0.337294
  Training set accuracy = 0.987000, Test set accuracy = 0.900900
 epoch 50/200. Took 0.03093 seconds. 
  Full-batch training loss = 0.084819, test loss = 0.339684
  Training set accuracy = 0.987500, Test set accuracy = 0.900700
 epoch 51/200. Took 0.037258 seconds. 
  Full-batch training loss = 0.082090, test loss = 0.339952
  Training set accuracy = 0.988500, Test set accuracy = 0.901600
 epoch 52/200. Took 0.035856 seconds. 
  Full-batch training loss = 0.079709, test loss = 0.336194
  Training set accuracy = 0.989500, Test set accuracy = 0.902200
 epoch 53/200. Took 0.036687 seconds. 
  Full-batch training loss = 0.077330, test loss = 0.340958
  Training set accuracy = 0.992000, Test set accuracy = 0.902200
 epoch 54/200. Took 0.036242 seconds. 
  Full-batch training loss = 0.075878, test loss = 0.342597
  Training set accuracy = 0.991000, Test set accuracy = 0.901400
 epoch 55/200. Took 0.030755 seconds. 
  Full-batch training loss = 0.074644, test loss = 0.345976
  Training set accuracy = 0.993000, Test set accuracy = 0.900200
 epoch 56/200. Took 0.032504 seconds. 
  Full-batch training loss = 0.075625, test loss = 0.351843
  Training set accuracy = 0.991500, Test set accuracy = 0.899700
 epoch 57/200. Took 0.028324 seconds. 
  Full-batch training loss = 0.068669, test loss = 0.340155
  Training set accuracy = 0.994500, Test set accuracy = 0.902800
 epoch 58/200. Took 0.028765 seconds. 
  Full-batch training loss = 0.068099, test loss = 0.343624
  Training set accuracy = 0.994000, Test set accuracy = 0.900300
 epoch 59/200. Took 0.032347 seconds. 
  Full-batch training loss = 0.065492, test loss = 0.340796
  Training set accuracy = 0.996500, Test set accuracy = 0.902000
 epoch 60/200. Took 0.028253 seconds. 
  Full-batch training loss = 0.064226, test loss = 0.341197
  Training set accuracy = 0.996500, Test set accuracy = 0.902400
 epoch 61/200. Took 0.028664 seconds. 
  Full-batch training loss = 0.062171, test loss = 0.343718
  Training set accuracy = 0.996000, Test set accuracy = 0.901100
 epoch 62/200. Took 0.030194 seconds. 
  Full-batch training loss = 0.060642, test loss = 0.339335
  Training set accuracy = 0.996500, Test set accuracy = 0.904200
 epoch 63/200. Took 0.031369 seconds. 
  Full-batch training loss = 0.058788, test loss = 0.342797
  Training set accuracy = 0.996500, Test set accuracy = 0.902900
 epoch 64/200. Took 0.031417 seconds. 
  Full-batch training loss = 0.057339, test loss = 0.343009
  Training set accuracy = 0.997500, Test set accuracy = 0.901900
 epoch 65/200. Took 0.027709 seconds. 
  Full-batch training loss = 0.056166, test loss = 0.344979
  Training set accuracy = 0.998500, Test set accuracy = 0.901900
 epoch 66/200. Took 0.031523 seconds. 
  Full-batch training loss = 0.054922, test loss = 0.344572
  Training set accuracy = 0.997500, Test set accuracy = 0.902300
 epoch 67/200. Took 0.030805 seconds. 
  Full-batch training loss = 0.053393, test loss = 0.345597
  Training set accuracy = 0.998500, Test set accuracy = 0.900800
 epoch 68/200. Took 0.028638 seconds. 
  Full-batch training loss = 0.052012, test loss = 0.342826
  Training set accuracy = 0.999000, Test set accuracy = 0.903600
 epoch 69/200. Took 0.02852 seconds. 
  Full-batch training loss = 0.050899, test loss = 0.345741
  Training set accuracy = 0.998500, Test set accuracy = 0.901200
 epoch 70/200. Took 0.0319 seconds. 
  Full-batch training loss = 0.049324, test loss = 0.344094
  Training set accuracy = 0.999000, Test set accuracy = 0.903100
 epoch 71/200. Took 0.030205 seconds. 
  Full-batch training loss = 0.048318, test loss = 0.345336
  Training set accuracy = 0.999000, Test set accuracy = 0.902700
 epoch 72/200. Took 0.031093 seconds. 
  Full-batch training loss = 0.047151, test loss = 0.345405
  Training set accuracy = 0.999500, Test set accuracy = 0.903400
 epoch 73/200. Took 0.028834 seconds. 
  Full-batch training loss = 0.046159, test loss = 0.344773
  Training set accuracy = 0.999500, Test set accuracy = 0.903600
 epoch 74/200. Took 0.030493 seconds. 
  Full-batch training loss = 0.045348, test loss = 0.346979
  Training set accuracy = 0.999500, Test set accuracy = 0.903200
 epoch 75/200. Took 0.032312 seconds. 
  Full-batch training loss = 0.044375, test loss = 0.344937
  Training set accuracy = 0.999500, Test set accuracy = 0.903500
 epoch 76/200. Took 0.033335 seconds. 
  Full-batch training loss = 0.042880, test loss = 0.346208
  Training set accuracy = 0.999500, Test set accuracy = 0.904000
 epoch 77/200. Took 0.027758 seconds. 
  Full-batch training loss = 0.042242, test loss = 0.345928
  Training set accuracy = 0.999500, Test set accuracy = 0.902800
 epoch 78/200. Took 0.02918 seconds. 
  Full-batch training loss = 0.041263, test loss = 0.345101
  Training set accuracy = 0.999000, Test set accuracy = 0.904600
 epoch 79/200. Took 0.02942 seconds. 
  Full-batch training loss = 0.040193, test loss = 0.346956
  Training set accuracy = 0.999500, Test set accuracy = 0.904100
 epoch 80/200. Took 0.03127 seconds. 
  Full-batch training loss = 0.039578, test loss = 0.348243
  Training set accuracy = 0.999500, Test set accuracy = 0.902700
 epoch 81/200. Took 0.03423 seconds. 
  Full-batch training loss = 0.038575, test loss = 0.348400
  Training set accuracy = 0.999500, Test set accuracy = 0.904200
 epoch 82/200. Took 0.031819 seconds. 
  Full-batch training loss = 0.038256, test loss = 0.347532
  Training set accuracy = 0.999500, Test set accuracy = 0.903900
 epoch 83/200. Took 0.028654 seconds. 
  Full-batch training loss = 0.037087, test loss = 0.348226
  Training set accuracy = 0.999500, Test set accuracy = 0.903600
 epoch 84/200. Took 0.033647 seconds. 
  Full-batch training loss = 0.036392, test loss = 0.348882
  Training set accuracy = 1.000000, Test set accuracy = 0.903300
 epoch 85/200. Took 0.031074 seconds. 
  Full-batch training loss = 0.035447, test loss = 0.349461
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 86/200. Took 0.031709 seconds. 
  Full-batch training loss = 0.034783, test loss = 0.350313
  Training set accuracy = 0.999500, Test set accuracy = 0.904000
 epoch 87/200. Took 0.03565 seconds. 
  Full-batch training loss = 0.034088, test loss = 0.349770
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 88/200. Took 0.030882 seconds. 
  Full-batch training loss = 0.033548, test loss = 0.350089
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 89/200. Took 0.031668 seconds. 
  Full-batch training loss = 0.032876, test loss = 0.351263
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 90/200. Took 0.035004 seconds. 
  Full-batch training loss = 0.032318, test loss = 0.349564
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 91/200. Took 0.03125 seconds. 
  Full-batch training loss = 0.031640, test loss = 0.350959
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 92/200. Took 0.031946 seconds. 
  Full-batch training loss = 0.031243, test loss = 0.350369
  Training set accuracy = 1.000000, Test set accuracy = 0.903700
 epoch 93/200. Took 0.035963 seconds. 
  Full-batch training loss = 0.030688, test loss = 0.353536
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 94/200. Took 0.032187 seconds. 
  Full-batch training loss = 0.029927, test loss = 0.352240
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 95/200. Took 0.032326 seconds. 
  Full-batch training loss = 0.029381, test loss = 0.352097
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 96/200. Took 0.035373 seconds. 
  Full-batch training loss = 0.028918, test loss = 0.352716
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 97/200. Took 0.028574 seconds. 
  Full-batch training loss = 0.028354, test loss = 0.353309
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 98/200. Took 0.029085 seconds. 
  Full-batch training loss = 0.027941, test loss = 0.353215
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 99/200. Took 0.032169 seconds. 
  Full-batch training loss = 0.027440, test loss = 0.353778
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 100/200. Took 0.028572 seconds. 
  Full-batch training loss = 0.027004, test loss = 0.354496
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 101/200. Took 0.031882 seconds. 
  Full-batch training loss = 0.026524, test loss = 0.354711
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 102/200. Took 0.030918 seconds. 
  Full-batch training loss = 0.026170, test loss = 0.354915
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 103/200. Took 0.032353 seconds. 
  Full-batch training loss = 0.025637, test loss = 0.355461
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 104/200. Took 0.030366 seconds. 
  Full-batch training loss = 0.025231, test loss = 0.355758
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 105/200. Took 0.031479 seconds. 
  Full-batch training loss = 0.024848, test loss = 0.355404
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 106/200. Took 0.031533 seconds. 
  Full-batch training loss = 0.024569, test loss = 0.355578
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 107/200. Took 0.031863 seconds. 
  Full-batch training loss = 0.024148, test loss = 0.355797
  Training set accuracy = 1.000000, Test set accuracy = 0.904800
 epoch 108/200. Took 0.035128 seconds. 
  Full-batch training loss = 0.023736, test loss = 0.357410
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 109/200. Took 0.031718 seconds. 
  Full-batch training loss = 0.023329, test loss = 0.356992
  Training set accuracy = 1.000000, Test set accuracy = 0.904700
 epoch 110/200. Took 0.028988 seconds. 
  Full-batch training loss = 0.023000, test loss = 0.357325
  Training set accuracy = 1.000000, Test set accuracy = 0.904900
 epoch 111/200. Took 0.029083 seconds. 
  Full-batch training loss = 0.022722, test loss = 0.357486
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 112/200. Took 0.037412 seconds. 
  Full-batch training loss = 0.022434, test loss = 0.357224
  Training set accuracy = 1.000000, Test set accuracy = 0.905200
 epoch 113/200. Took 0.033074 seconds. 
  Full-batch training loss = 0.022009, test loss = 0.358461
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 114/200. Took 0.034919 seconds. 
  Full-batch training loss = 0.021696, test loss = 0.358479
  Training set accuracy = 1.000000, Test set accuracy = 0.904800
 epoch 115/200. Took 0.033666 seconds. 
  Full-batch training loss = 0.021379, test loss = 0.358731
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 116/200. Took 0.031576 seconds. 
  Full-batch training loss = 0.021110, test loss = 0.359779
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 117/200. Took 0.034422 seconds. 
  Full-batch training loss = 0.020805, test loss = 0.359409
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 118/200. Took 0.031443 seconds. 
  Full-batch training loss = 0.020509, test loss = 0.359597
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 119/200. Took 0.036569 seconds. 
  Full-batch training loss = 0.020288, test loss = 0.360874
  Training set accuracy = 1.000000, Test set accuracy = 0.904800
 epoch 120/200. Took 0.035613 seconds. 
  Full-batch training loss = 0.019944, test loss = 0.360316
  Training set accuracy = 1.000000, Test set accuracy = 0.904800
 epoch 121/200. Took 0.031413 seconds. 
  Full-batch training loss = 0.019701, test loss = 0.360115
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 122/200. Took 0.030702 seconds. 
  Full-batch training loss = 0.019436, test loss = 0.360883
  Training set accuracy = 1.000000, Test set accuracy = 0.905000
 epoch 123/200. Took 0.035618 seconds. 
  Full-batch training loss = 0.019174, test loss = 0.361272
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 124/200. Took 0.027798 seconds. 
  Full-batch training loss = 0.018923, test loss = 0.361594
  Training set accuracy = 1.000000, Test set accuracy = 0.904900
 epoch 125/200. Took 0.032508 seconds. 
  Full-batch training loss = 0.018678, test loss = 0.362075
  Training set accuracy = 1.000000, Test set accuracy = 0.904700
 epoch 126/200. Took 0.039621 seconds. 
  Full-batch training loss = 0.018461, test loss = 0.362117
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 127/200. Took 0.029081 seconds. 
  Full-batch training loss = 0.018218, test loss = 0.362053
  Training set accuracy = 1.000000, Test set accuracy = 0.904900
 epoch 128/200. Took 0.031179 seconds. 
  Full-batch training loss = 0.018001, test loss = 0.363034
  Training set accuracy = 1.000000, Test set accuracy = 0.904900
 epoch 129/200. Took 0.033915 seconds. 
  Full-batch training loss = 0.017816, test loss = 0.363794
  Training set accuracy = 1.000000, Test set accuracy = 0.905200
 epoch 130/200. Took 0.031577 seconds. 
  Full-batch training loss = 0.017547, test loss = 0.363460
  Training set accuracy = 1.000000, Test set accuracy = 0.905200
 epoch 131/200. Took 0.0318 seconds. 
  Full-batch training loss = 0.017335, test loss = 0.363835
  Training set accuracy = 1.000000, Test set accuracy = 0.905200
 epoch 132/200. Took 0.035579 seconds. 
  Full-batch training loss = 0.017122, test loss = 0.363732
  Training set accuracy = 1.000000, Test set accuracy = 0.905000
 epoch 133/200. Took 0.03656 seconds. 
  Full-batch training loss = 0.016928, test loss = 0.364572
  Training set accuracy = 1.000000, Test set accuracy = 0.905800
 epoch 134/200. Took 0.031619 seconds. 
  Full-batch training loss = 0.016712, test loss = 0.363639
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 135/200. Took 0.033377 seconds. 
  Full-batch training loss = 0.016534, test loss = 0.364435
  Training set accuracy = 1.000000, Test set accuracy = 0.905000
 epoch 136/200. Took 0.031803 seconds. 
  Full-batch training loss = 0.016326, test loss = 0.365037
  Training set accuracy = 1.000000, Test set accuracy = 0.905200
 epoch 137/200. Took 0.032957 seconds. 
  Full-batch training loss = 0.016137, test loss = 0.365322
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 138/200. Took 0.033727 seconds. 
  Full-batch training loss = 0.015953, test loss = 0.365589
  Training set accuracy = 1.000000, Test set accuracy = 0.904800
 epoch 139/200. Took 0.031719 seconds. 
  Full-batch training loss = 0.015781, test loss = 0.365937
  Training set accuracy = 1.000000, Test set accuracy = 0.905400
 epoch 140/200. Took 0.035993 seconds. 
  Full-batch training loss = 0.015694, test loss = 0.366577
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 141/200. Took 0.031512 seconds. 
  Full-batch training loss = 0.015438, test loss = 0.366246
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 142/200. Took 0.03154 seconds. 
  Full-batch training loss = 0.015263, test loss = 0.366604
  Training set accuracy = 1.000000, Test set accuracy = 0.905300
 epoch 143/200. Took 0.033334 seconds. 
  Full-batch training loss = 0.015096, test loss = 0.367476
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 144/200. Took 0.031814 seconds. 
  Full-batch training loss = 0.014929, test loss = 0.367787
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 145/200. Took 0.028548 seconds. 
  Full-batch training loss = 0.014766, test loss = 0.367110
  Training set accuracy = 1.000000, Test set accuracy = 0.905100
 epoch 146/200. Took 0.029342 seconds. 
  Full-batch training loss = 0.014610, test loss = 0.367405
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 147/200. Took 0.036569 seconds. 
  Full-batch training loss = 0.014459, test loss = 0.368464
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 148/200. Took 0.031088 seconds. 
  Full-batch training loss = 0.014299, test loss = 0.368240
  Training set accuracy = 1.000000, Test set accuracy = 0.905800
 epoch 149/200. Took 0.03169 seconds. 
  Full-batch training loss = 0.014154, test loss = 0.368524
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 150/200. Took 0.034382 seconds. 
  Full-batch training loss = 0.014000, test loss = 0.368473
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 151/200. Took 0.031845 seconds. 
  Full-batch training loss = 0.013855, test loss = 0.368961
  Training set accuracy = 1.000000, Test set accuracy = 0.905800
 epoch 152/200. Took 0.030807 seconds. 
  Full-batch training loss = 0.013717, test loss = 0.369341
  Training set accuracy = 1.000000, Test set accuracy = 0.905800
 epoch 153/200. Took 0.033963 seconds. 
  Full-batch training loss = 0.013582, test loss = 0.369697
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 154/200. Took 0.032034 seconds. 
  Full-batch training loss = 0.013448, test loss = 0.369324
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 155/200. Took 0.031987 seconds. 
  Full-batch training loss = 0.013315, test loss = 0.369782
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 156/200. Took 0.031387 seconds. 
  Full-batch training loss = 0.013181, test loss = 0.369855
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 157/200. Took 0.028705 seconds. 
  Full-batch training loss = 0.013057, test loss = 0.371083
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 158/200. Took 0.029227 seconds. 
  Full-batch training loss = 0.012944, test loss = 0.370900
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 159/200. Took 0.033429 seconds. 
  Full-batch training loss = 0.012812, test loss = 0.370544
  Training set accuracy = 1.000000, Test set accuracy = 0.905300
 epoch 160/200. Took 0.031321 seconds. 
  Full-batch training loss = 0.012678, test loss = 0.370960
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 161/200. Took 0.029779 seconds. 
  Full-batch training loss = 0.012561, test loss = 0.371080
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 162/200. Took 0.029168 seconds. 
  Full-batch training loss = 0.012438, test loss = 0.371576
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 163/200. Took 0.028477 seconds. 
  Full-batch training loss = 0.012328, test loss = 0.371612
  Training set accuracy = 1.000000, Test set accuracy = 0.905400
 epoch 164/200. Took 0.02845 seconds. 
  Full-batch training loss = 0.012222, test loss = 0.372338
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 165/200. Took 0.028962 seconds. 
  Full-batch training loss = 0.012094, test loss = 0.372759
  Training set accuracy = 1.000000, Test set accuracy = 0.905800
 epoch 166/200. Took 0.029014 seconds. 
  Full-batch training loss = 0.011987, test loss = 0.372412
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
 epoch 167/200. Took 0.028658 seconds. 
  Full-batch training loss = 0.011875, test loss = 0.372644
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 168/200. Took 0.028842 seconds. 
  Full-batch training loss = 0.011770, test loss = 0.372956
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 169/200. Took 0.037667 seconds. 
  Full-batch training loss = 0.011671, test loss = 0.373358
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 170/200. Took 0.030804 seconds. 
  Full-batch training loss = 0.011562, test loss = 0.373188
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 171/200. Took 0.029089 seconds. 
  Full-batch training loss = 0.011472, test loss = 0.373895
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 172/200. Took 0.031201 seconds. 
  Full-batch training loss = 0.011360, test loss = 0.374327
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 173/200. Took 0.028958 seconds. 
  Full-batch training loss = 0.011257, test loss = 0.374156
  Training set accuracy = 1.000000, Test set accuracy = 0.905500
 epoch 174/200. Took 0.028987 seconds. 
  Full-batch training loss = 0.011161, test loss = 0.374663
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 175/200. Took 0.032434 seconds. 
  Full-batch training loss = 0.011063, test loss = 0.374582
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 176/200. Took 0.037014 seconds. 
  Full-batch training loss = 0.010976, test loss = 0.374924
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 177/200. Took 0.030712 seconds. 
  Full-batch training loss = 0.010882, test loss = 0.375484
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 178/200. Took 0.030174 seconds. 
  Full-batch training loss = 0.010786, test loss = 0.375710
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 179/200. Took 0.031389 seconds. 
  Full-batch training loss = 0.010702, test loss = 0.375672
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 180/200. Took 0.031562 seconds. 
  Full-batch training loss = 0.010613, test loss = 0.376217
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 181/200. Took 0.029666 seconds. 
  Full-batch training loss = 0.010528, test loss = 0.376010
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 182/200. Took 0.040772 seconds. 
  Full-batch training loss = 0.010444, test loss = 0.376254
  Training set accuracy = 1.000000, Test set accuracy = 0.905700
 epoch 183/200. Took 0.046318 seconds. 
  Full-batch training loss = 0.010358, test loss = 0.376916
  Training set accuracy = 1.000000, Test set accuracy = 0.905600
 epoch 184/200. Took 0.03774 seconds. 
  Full-batch training loss = 0.010266, test loss = 0.376384
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 185/200. Took 0.035231 seconds. 
  Full-batch training loss = 0.010181, test loss = 0.376810
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 186/200. Took 0.03503 seconds. 
  Full-batch training loss = 0.010100, test loss = 0.376804
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
 epoch 187/200. Took 0.034627 seconds. 
  Full-batch training loss = 0.010027, test loss = 0.377219
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 188/200. Took 0.031802 seconds. 
  Full-batch training loss = 0.009946, test loss = 0.377056
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 189/200. Took 0.036493 seconds. 
  Full-batch training loss = 0.009869, test loss = 0.378472
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 190/200. Took 0.031447 seconds. 
  Full-batch training loss = 0.009793, test loss = 0.377539
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
 epoch 191/200. Took 0.031492 seconds. 
  Full-batch training loss = 0.009710, test loss = 0.378271
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
 epoch 192/200. Took 0.030579 seconds. 
  Full-batch training loss = 0.009641, test loss = 0.378478
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 193/200. Took 0.031055 seconds. 
  Full-batch training loss = 0.009566, test loss = 0.378339
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
 epoch 194/200. Took 0.031912 seconds. 
  Full-batch training loss = 0.009493, test loss = 0.379025
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 195/200. Took 0.032036 seconds. 
  Full-batch training loss = 0.009419, test loss = 0.379180
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 196/200. Took 0.036566 seconds. 
  Full-batch training loss = 0.009352, test loss = 0.379085
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 197/200. Took 0.032218 seconds. 
  Full-batch training loss = 0.009284, test loss = 0.378962
  Training set accuracy = 1.000000, Test set accuracy = 0.905900
 epoch 198/200. Took 0.031337 seconds. 
  Full-batch training loss = 0.009211, test loss = 0.379734
  Training set accuracy = 1.000000, Test set accuracy = 0.906000
 epoch 199/200. Took 0.031373 seconds. 
  Full-batch training loss = 0.009148, test loss = 0.379416
  Training set accuracy = 1.000000, Test set accuracy = 0.906300
 epoch 200/200. Took 0.034399 seconds. 
  Full-batch training loss = 0.009076, test loss = 0.380096
  Training set accuracy = 1.000000, Test set accuracy = 0.906100
Elapsed time is 28.219164 seconds.
End Training
{Output argument "DBNNet" (and maybe others) not assigned during call to "DeepBPN_RBM_train_model".

Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('DeepBPN_RBM_example_complete_MNIST', '/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m', 56)" style="font-weight:bold">DeepBPN_RBM_example_complete_MNIST</a> (<a href="matlab: opentoline('/home/ns/Dokumenty/UPC/atci/proj2/DeepLearningSoftware/ToolboxDeepLearning-RasmusBergPalm/DeepBPN_RBM_example_complete_MNIST.m',56,0)">line 56</a>)
                   [DBNNet BPNNet] = DeepBPN_RBM_train_model (Data, ReducedData, Network);
} 
DeepBPN_RBM_example_complete_MNIST
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.070667 seconds. 
  Full-batch training loss = 1.809835, test loss = 1.821169
  Training set accuracy = 0.499000, Test set accuracy = 0.481800
 epoch 2/200. Took 0.030661 seconds. 
  Full-batch training loss = 1.235697, test loss = 1.241722
  Training set accuracy = 0.692000, Test set accuracy = 0.676700
 epoch 3/200. Took 0.029373 seconds. 
  Full-batch training loss = 0.880831, test loss = 0.891314
  Training set accuracy = 0.791500, Test set accuracy = 0.793400
 epoch 4/200. Took 0.032166 seconds. 
  Full-batch training loss = 0.700741, test loss = 0.716778
  Training set accuracy = 0.849500, Test set accuracy = 0.838100
 epoch 5/200. Took 0.030257 seconds. 
  Full-batch training loss = 0.593990, test loss = 0.615498
  Training set accuracy = 0.862000, Test set accuracy = 0.853600
 epoch 6/200. Took 0.031477 seconds. 
  Full-batch training loss = 0.520620, test loss = 0.546081
  Training set accuracy = 0.876500, Test set accuracy = 0.864600
 epoch 7/200. Took 0.030679 seconds. 
  Full-batch training loss = 0.468919, test loss = 0.500503
  Training set accuracy = 0.885500, Test set accuracy = 0.871400
 epoch 8/200. Took 0.028876 seconds. 
  Full-batch training loss = 0.434216, test loss = 0.472554
  Training set accuracy = 0.895500, Test set accuracy = 0.873000
 epoch 9/200. Took 0.029314 seconds. 
  Full-batch training loss = 0.395978, test loss = 0.442935
  Training set accuracy = 0.903500, Test set accuracy = 0.882200
 epoch 10/200. Took 0.028475 seconds. 
  Full-batch training loss = 0.373904, test loss = 0.423598
  Training set accuracy = 0.909000, Test set accuracy = 0.885900
 epoch 11/200. Took 0.029441 seconds. 
  Full-batch training loss = 0.348926, test loss = 0.409771
  Training set accuracy = 0.914500, Test set accuracy = 0.887400
 epoch 12/200. Took 0.029703 seconds. 
  Full-batch training loss = 0.331009, test loss = 0.397411
  Training set accuracy = 0.917500, Test set accuracy = 0.888300
 epoch 13/200. Took 0.031698 seconds. 
  Full-batch training loss = 0.318825, test loss = 0.393066
  Training set accuracy = 0.925000, Test set accuracy = 0.891400
 epoch 14/200. Took 0.028735 seconds. 
  Full-batch training loss = 0.297860, test loss = 0.381923
  Training set accuracy = 0.930500, Test set accuracy = 0.892100
 epoch 15/200. Took 0.041799 seconds. 
  Full-batch training loss = 0.281396, test loss = 0.370491
  Training set accuracy = 0.934000, Test set accuracy = 0.895000
 epoch 16/200. Took 0.033056 seconds. 
  Full-batch training loss = 0.268183, test loss = 0.362369
  Training set accuracy = 0.937500, Test set accuracy = 0.894700
 epoch 17/200. Took 0.035695 seconds. 
  Full-batch training loss = 0.254660, test loss = 0.355402
  Training set accuracy = 0.941500, Test set accuracy = 0.897500
 epoch 18/200. Took 0.03491 seconds. 
  Full-batch training loss = 0.245548, test loss = 0.354104
  Training set accuracy = 0.946500, Test set accuracy = 0.896800
 epoch 19/200. Took 0.037819 seconds. 
  Full-batch training loss = 0.235611, test loss = 0.350367
  Training set accuracy = 0.948000, Test set accuracy = 0.895800
 epoch 20/200. Took 0.031541 seconds. 
  Full-batch training loss = 0.225731, test loss = 0.345881
  Training set accuracy = 0.946500, Test set accuracy = 0.897000
 epoch 21/200. Took 0.031292 seconds. 
  Full-batch training loss = 0.218601, test loss = 0.344530
  Training set accuracy = 0.947500, Test set accuracy = 0.897400
 epoch 22/200. Took 0.034082 seconds. 
  Full-batch training loss = 0.208449, test loss = 0.338488
  Training set accuracy = 0.954000, Test set accuracy = 0.898900
 epoch 23/200. Took 0.030795 seconds. 
  Full-batch training loss = 0.205080, test loss = 0.340264
  Training set accuracy = 0.954500, Test set accuracy = 0.898000
 epoch 24/200. Took 0.036333 seconds. 
  Full-batch training loss = 0.193342, test loss = 0.335596
  Training set accuracy = 0.957500, Test set accuracy = 0.898500
 epoch 25/200. Took 0.032349 seconds. 
  Full-batch training loss = 0.188512, test loss = 0.333488
  Training set accuracy = 0.959000, Test set accuracy = 0.898600
 epoch 26/200. Took 0.03703 seconds. 
  Full-batch training loss = 0.180667, test loss = 0.331475
  Training set accuracy = 0.961000, Test set accuracy = 0.900000
 epoch 27/200. Took 0.030605 seconds. 
  Full-batch training loss = 0.177980, test loss = 0.336985
  Training set accuracy = 0.962000, Test set accuracy = 0.897300
 epoch 28/200. Took 0.030528 seconds. 
  Full-batch training loss = 0.168807, test loss = 0.329975
  Training set accuracy = 0.965000, Test set accuracy = 0.899200
 epoch 29/200. Took 0.030274 seconds. 
  Full-batch training loss = 0.163442, test loss = 0.328657
  Training set accuracy = 0.969000, Test set accuracy = 0.899600
 epoch 30/200. Took 0.031349 seconds. 
  Full-batch training loss = 0.157074, test loss = 0.325912
  Training set accuracy = 0.967000, Test set accuracy = 0.901700
 epoch 31/200. Took 0.031587 seconds. 
  Full-batch training loss = 0.151922, test loss = 0.326795
  Training set accuracy = 0.969000, Test set accuracy = 0.899600
 epoch 32/200. Took 0.031496 seconds. 
  Full-batch training loss = 0.147729, test loss = 0.326836
  Training set accuracy = 0.969500, Test set accuracy = 0.899700
 epoch 33/200. Took 0.031552 seconds. 
  Full-batch training loss = 0.142562, test loss = 0.324175
  Training set accuracy = 0.969500, Test set accuracy = 0.901000
 epoch 34/200. Took 0.03073 seconds. 
  Full-batch training loss = 0.137996, test loss = 0.324273
  Training set accuracy = 0.971500, Test set accuracy = 0.901600
 epoch 35/200. Took 0.035861 seconds. 
  Full-batch training loss = 0.135996, test loss = 0.324648
  Training set accuracy = 0.975500, Test set accuracy = 0.899400
 epoch 36/200. Took 0.032361 seconds. 
  Full-batch training loss = 0.130593, test loss = 0.325579
  Training set accuracy = 0.976000, Test set accuracy = 0.899500
 epoch 37/200. Took 0.032175 seconds. 
  Full-batch training loss = 0.128927, test loss = 0.326798
  Training set accuracy = 0.975000, Test set accuracy = 0.900200
 epoch 38/200. Took 0.031469 seconds. 
  Full-batch training loss = 0.121519, test loss = 0.321110
  Training set accuracy = 0.979500, Test set accuracy = 0.900700
 epoch 39/200. Took 0.032987 seconds. 
  Full-batch training loss = 0.118875, test loss = 0.322398
  Training set accuracy = 0.979000, Test set accuracy = 0.901800
 epoch 40/200. Took 0.032837 seconds. 
  Full-batch training loss = 0.116221, test loss = 0.323016
  Training set accuracy = 0.982000, Test set accuracy = 0.901800
 epoch 41/200. Took 0.032 seconds. 
  Full-batch training loss = 0.111395, test loss = 0.321942
  Training set accuracy = 0.981500, Test set accuracy = 0.900900
 epoch 42/200. Took 0.032376 seconds. 
  Full-batch training loss = 0.109423, test loss = 0.324560
  Training set accuracy = 0.981000, Test set accuracy = 0.900200
 epoch 43/200. Took 0.037125 seconds. 
  Full-batch training loss = 0.104391, test loss = 0.320913
  Training set accuracy = 0.985000, Test set accuracy = 0.901700
 epoch 44/200. Took 0.033856 seconds. 
  Full-batch training loss = 0.101726, test loss = 0.320344
  Training set accuracy = 0.983500, Test set accuracy = 0.903500
 epoch 45/200. Took 0.030574 seconds. 
  Full-batch training loss = 0.098647, test loss = 0.321495
  Training set accuracy = 0.987000, Test set accuracy = 0.901900
 epoch 46/200. Took 0.031954 seconds. 
  Full-batch training loss = 0.096724, test loss = 0.321710
  Training set accuracy = 0.985000, Test set accuracy = 0.901200
 epoch 47/200. Took 0.030753 seconds. 
  Full-batch training loss = 0.093639, test loss = 0.321406
  Training set accuracy = 0.986500, Test set accuracy = 0.902600
 epoch 48/200. Took 0.030725 seconds. 
  Full-batch training loss = 0.090855, test loss = 0.321867
  Training set accuracy = 0.987000, Test set accuracy = 0.902500
 epoch 49/200. Took 0.031253 seconds. 
  Full-batch training loss = 0.088587, test loss = 0.321711
  Training set accuracy = 0.990000, Test set accuracy = 0.901800
 epoch 50/200. Took 0.031343 seconds. 
  Full-batch training loss = 0.087134, test loss = 0.323204
  Training set accuracy = 0.988500, Test set accuracy = 0.900900
 epoch 51/200. Took 0.034788 seconds. 
  Full-batch training loss = 0.083766, test loss = 0.320518
  Training set accuracy = 0.989500, Test set accuracy = 0.903500
 epoch 52/200. Took 0.034426 seconds. 
  Full-batch training loss = 0.081667, test loss = 0.322928
  Training set accuracy = 0.991000, Test set accuracy = 0.901900
 epoch 53/200. Took 0.03475 seconds. 
  Full-batch training loss = 0.079915, test loss = 0.323551
  Training set accuracy = 0.991500, Test set accuracy = 0.901800
 epoch 54/200. Took 0.030595 seconds. 
  Full-batch training loss = 0.076687, test loss = 0.321098
  Training set accuracy = 0.991500, Test set accuracy = 0.902800
 epoch 55/200. Took 0.032545 seconds. 
  Full-batch training loss = 0.074690, test loss = 0.322350
  Training set accuracy = 0.991500, Test set accuracy = 0.902700
 epoch 56/200. Took 0.029816 seconds. 
  Full-batch training loss = 0.072888, test loss = 0.321485
  Training set accuracy = 0.993000, Test set accuracy = 0.903200
 epoch 57/200. Took 0.031342 seconds. 
  Full-batch training loss = 0.071072, test loss = 0.322122
  Training set accuracy = 0.992500, Test set accuracy = 0.903400
 epoch 58/200. Took 0.030483 seconds. 
  Full-batch training loss = 0.068951, test loss = 0.321933
  Training set accuracy = 0.993000, Test set accuracy = 0.903200
 epoch 59/200. Took 0.03069 seconds. 
  Full-batch training loss = 0.067360, test loss = 0.322494
  Training set accuracy = 0.994000, Test set accuracy = 0.903500
 epoch 60/200. Took 0.030828 seconds. 
  Full-batch training loss = 0.065697, test loss = 0.322799
  Training set accuracy = 0.994500, Test set accuracy = 0.903400
 epoch 61/200. Took 0.03191 seconds. 
  Full-batch training loss = 0.064732, test loss = 0.323550
  Training set accuracy = 0.993000, Test set accuracy = 0.903800
 epoch 62/200. Took 0.031406 seconds. 
  Full-batch training loss = 0.062820, test loss = 0.324552
  Training set accuracy = 0.994500, Test set accuracy = 0.903000
 epoch 63/200. Took 0.031245 seconds. 
  Full-batch training loss = 0.061965, test loss = 0.325798
  Training set accuracy = 0.994500, Test set accuracy = 0.901900
 epoch 64/200. Took 0.035899 seconds. 
  Full-batch training loss = 0.059594, test loss = 0.324659
  Training set accuracy = 0.995500, Test set accuracy = 0.903300
 epoch 65/200. Took 0.030672 seconds. 
  Full-batch training loss = 0.059133, test loss = 0.327469
  Training set accuracy = 0.995500, Test set accuracy = 0.901500
 epoch 66/200. Took 0.031692 seconds. 
  Full-batch training loss = 0.057767, test loss = 0.325113
  Training set accuracy = 0.995500, Test set accuracy = 0.904600
 epoch 67/200. Took 0.029887 seconds. 
  Full-batch training loss = 0.055519, test loss = 0.325852
  Training set accuracy = 0.996000, Test set accuracy = 0.904200
 epoch 68/200. Took 0.031008 seconds. 
  Full-batch training loss = 0.054070, test loss = 0.325333
  Training set accuracy = 0.995500, Test set accuracy = 0.904000
 epoch 69/200. Took 0.028488 seconds. 
  Full-batch training loss = 0.054534, test loss = 0.329037
  Training set accuracy = 0.995500, Test set accuracy = 0.903000
 epoch 70/200. Took 0.031608 seconds. 
  Full-batch training loss = 0.051670, test loss = 0.326007
  Training set accuracy = 0.996500, Test set accuracy = 0.903800
 epoch 71/200. Took 0.034555 seconds. 
  Full-batch training loss = 0.051266, test loss = 0.328219
  Training set accuracy = 0.996000, Test set accuracy = 0.903100
 epoch 72/200. Took 0.036292 seconds. 
  Full-batch training loss = 0.049525, test loss = 0.326844
  Training set accuracy = 0.996500, Test set accuracy = 0.903900
 epoch 73/200. Took 0.032469 seconds. 
  Full-batch training loss = 0.048396, test loss = 0.327104
  Training set accuracy = 0.997500, Test set accuracy = 0.904300
 epoch 74/200. Took 0.033242 seconds. 
  Full-batch training loss = 0.047487, test loss = 0.328610
  Training set accuracy = 0.996500, Test set accuracy = 0.903600
 epoch 75/200. Took 0.038819 seconds. 
  Full-batch training loss = 0.046260, test loss = 0.327467
  Training set accuracy = 0.997500, Test set accuracy = 0.904400
 epoch 76/200. Took 0.032453 seconds. 
  Full-batch training loss = 0.045199, test loss = 0.327708
  Training set accuracy = 0.997000, Test set accuracy = 0.904900
 epoch 77/200. Took 0.031531 seconds. 
  Full-batch training loss = 0.044375, test loss = 0.328492
  Training set accuracy = 0.997000, Test set accuracy = 0.904300
 epoch 78/200. Took 0.030357 seconds. 
  Full-batch training loss = 0.043412, test loss = 0.329027
  Training set accuracy = 0.997500, Test set accuracy = 0.904500
 epoch 79/200. Took 0.028907 seconds. 
  Full-batch training loss = 0.042585, test loss = 0.330335
  Training set accuracy = 0.997500, Test set accuracy = 0.902400
 epoch 80/200. Took 0.027538 seconds. 
  Full-batch training loss = 0.041769, test loss = 0.328908
  Training set accuracy = 0.997500, Test set accuracy = 0.904700
 epoch 81/200. Took 0.029655 seconds. 
  Full-batch training loss = 0.040890, test loss = 0.330276
  Training set accuracy = 0.997500, Test set accuracy = 0.903800
 epoch 82/200. Took 0.03215 seconds. 
  Full-batch training loss = 0.040034, test loss = 0.330342
  Training set accuracy = 0.997500, Test set accuracy = 0.903800
 epoch 83/200. Took 0.030884 seconds. 
  Full-batch training loss = 0.039186, test loss = 0.331359
  Training set accuracy = 0.998000, Test set accuracy = 0.903400
 epoch 84/200. Took 0.031846 seconds. 
  Full-batch training loss = 0.038358, test loss = 0.331414
  Training set accuracy = 0.998000, Test set accuracy = 0.903400
 epoch 85/200. Took 0.031553 seconds. 
  Full-batch training loss = 0.037795, test loss = 0.332082
  Training set accuracy = 0.998000, Test set accuracy = 0.903600
 epoch 86/200. Took 0.032637 seconds. 
  Full-batch training loss = 0.036856, test loss = 0.331841
  Training set accuracy = 0.998000, Test set accuracy = 0.903600
 epoch 87/200. Took 0.030234 seconds. 
  Full-batch training loss = 0.036233, test loss = 0.331835
  Training set accuracy = 0.998000, Test set accuracy = 0.904900
 epoch 88/200. Took 0.031445 seconds. 
  Full-batch training loss = 0.035440, test loss = 0.333232
  Training set accuracy = 0.998500, Test set accuracy = 0.903100
 epoch 89/200. Took 0.028275 seconds. 
  Full-batch training loss = 0.034783, test loss = 0.333363
  Training set accuracy = 0.998000, Test set accuracy = 0.903800
 epoch 90/200. Took 0.032831 seconds. 
  Full-batch training loss = 0.034162, test loss = 0.333647
  Training set accuracy = 0.998000, Test set accuracy = 0.904000
 epoch 91/200. Took 0.030425 seconds. 
  Full-batch training loss = 0.033431, test loss = 0.333639
  Training set accuracy = 0.998000, Test set accuracy = 0.904000
 epoch 92/200. Took 0.03181 seconds. 
  Full-batch training loss = 0.032856, test loss = 0.333589
  Training set accuracy = 0.998500, Test set accuracy = 0.904800
 epoch 93/200. Took 0.031241 seconds. 
  Full-batch training loss = 0.032283, test loss = 0.334081
  Training set accuracy = 0.999000, Test set accuracy = 0.904700
 epoch 94/200. Took 0.031106 seconds. 
  Full-batch training loss = 0.031774, test loss = 0.336264
  Training set accuracy = 0.999000, Test set accuracy = 0.902900
 epoch 95/200. Took 0.03087 seconds. 
  Full-batch training loss = 0.031181, test loss = 0.335202
  Training set accuracy = 0.999500, Test set accuracy = 0.903800
 epoch 96/200. Took 0.030551 seconds. 
  Full-batch training loss = 0.030600, test loss = 0.335735
  Training set accuracy = 0.998500, Test set accuracy = 0.903800
 epoch 97/200. Took 0.031102 seconds. 
  Full-batch training loss = 0.030047, test loss = 0.335546
  Training set accuracy = 0.999000, Test set accuracy = 0.904300
 epoch 98/200. Took 0.03077 seconds. 
  Full-batch training loss = 0.029652, test loss = 0.336529
  Training set accuracy = 0.999000, Test set accuracy = 0.903200
 epoch 99/200. Took 0.035003 seconds. 
  Full-batch training loss = 0.029060, test loss = 0.336315
  Training set accuracy = 0.999500, Test set accuracy = 0.904900
 epoch 100/200. Took 0.028089 seconds. 
  Full-batch training loss = 0.028536, test loss = 0.336914
  Training set accuracy = 0.999500, Test set accuracy = 0.904500
 epoch 101/200. Took 0.033477 seconds. 
  Full-batch training loss = 0.028158, test loss = 0.338494
  Training set accuracy = 0.999000, Test set accuracy = 0.902700
 epoch 102/200. Took 0.031079 seconds. 
  Full-batch training loss = 0.027665, test loss = 0.337512
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 103/200. Took 0.037746 seconds. 
  Full-batch training loss = 0.027267, test loss = 0.337977
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 104/200. Took 0.031685 seconds. 
  Full-batch training loss = 0.026840, test loss = 0.338987
  Training set accuracy = 0.999500, Test set accuracy = 0.903300
 epoch 105/200. Took 0.031968 seconds. 
  Full-batch training loss = 0.026367, test loss = 0.339327
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 106/200. Took 0.032121 seconds. 
  Full-batch training loss = 0.026023, test loss = 0.338651
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 107/200. Took 0.03013 seconds. 
  Full-batch training loss = 0.025521, test loss = 0.339989
  Training set accuracy = 1.000000, Test set accuracy = 0.903700
 epoch 108/200. Took 0.030758 seconds. 
  Full-batch training loss = 0.025129, test loss = 0.340150
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 109/200. Took 0.031329 seconds. 
  Full-batch training loss = 0.024717, test loss = 0.340277
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 110/200. Took 0.031158 seconds. 
  Full-batch training loss = 0.024419, test loss = 0.340789
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 111/200. Took 0.030936 seconds. 
  Full-batch training loss = 0.024008, test loss = 0.340690
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 112/200. Took 0.035505 seconds. 
  Full-batch training loss = 0.023687, test loss = 0.340986
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 113/200. Took 0.03255 seconds. 
  Full-batch training loss = 0.023357, test loss = 0.342264
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 114/200. Took 0.031839 seconds. 
  Full-batch training loss = 0.023038, test loss = 0.342056
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 115/200. Took 0.028266 seconds. 
  Full-batch training loss = 0.022680, test loss = 0.342079
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 116/200. Took 0.029288 seconds. 
  Full-batch training loss = 0.022365, test loss = 0.342911
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 117/200. Took 0.028478 seconds. 
  Full-batch training loss = 0.022051, test loss = 0.342808
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 118/200. Took 0.030943 seconds. 
  Full-batch training loss = 0.021745, test loss = 0.343357
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 119/200. Took 0.030895 seconds. 
  Full-batch training loss = 0.021468, test loss = 0.344397
  Training set accuracy = 1.000000, Test set accuracy = 0.903400
 epoch 120/200. Took 0.036427 seconds. 
  Full-batch training loss = 0.021140, test loss = 0.343963
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 121/200. Took 0.031575 seconds. 
  Full-batch training loss = 0.020879, test loss = 0.344812
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 122/200. Took 0.02871 seconds. 
  Full-batch training loss = 0.020606, test loss = 0.344346
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 123/200. Took 0.027335 seconds. 
  Full-batch training loss = 0.020311, test loss = 0.344686
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 124/200. Took 0.030417 seconds. 
  Full-batch training loss = 0.020073, test loss = 0.345491
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 125/200. Took 0.034082 seconds. 
  Full-batch training loss = 0.019837, test loss = 0.345612
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 126/200. Took 0.031611 seconds. 
  Full-batch training loss = 0.019547, test loss = 0.345640
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 127/200. Took 0.03293 seconds. 
  Full-batch training loss = 0.019304, test loss = 0.346326
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 128/200. Took 0.030839 seconds. 
  Full-batch training loss = 0.019066, test loss = 0.346482
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 129/200. Took 0.033381 seconds. 
  Full-batch training loss = 0.018821, test loss = 0.346786
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 130/200. Took 0.030484 seconds. 
  Full-batch training loss = 0.018590, test loss = 0.347002
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 131/200. Took 0.031534 seconds. 
  Full-batch training loss = 0.018353, test loss = 0.347842
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 132/200. Took 0.028132 seconds. 
  Full-batch training loss = 0.018145, test loss = 0.348032
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 133/200. Took 0.031588 seconds. 
  Full-batch training loss = 0.017928, test loss = 0.347990
  Training set accuracy = 1.000000, Test set accuracy = 0.903900
 epoch 134/200. Took 0.035782 seconds. 
  Full-batch training loss = 0.017744, test loss = 0.348222
  Training set accuracy = 1.000000, Test set accuracy = 0.903400
 epoch 135/200. Took 0.031743 seconds. 
  Full-batch training loss = 0.017504, test loss = 0.348979
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 136/200. Took 0.028933 seconds. 
  Full-batch training loss = 0.017293, test loss = 0.348875
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 137/200. Took 0.031481 seconds. 
  Full-batch training loss = 0.017099, test loss = 0.349032
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 138/200. Took 0.035662 seconds. 
  Full-batch training loss = 0.016909, test loss = 0.349909
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 139/200. Took 0.031305 seconds. 
  Full-batch training loss = 0.016754, test loss = 0.350889
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 140/200. Took 0.033229 seconds. 
  Full-batch training loss = 0.016527, test loss = 0.350050
  Training set accuracy = 1.000000, Test set accuracy = 0.903900
 epoch 141/200. Took 0.035611 seconds. 
  Full-batch training loss = 0.016339, test loss = 0.350543
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 142/200. Took 0.03196 seconds. 
  Full-batch training loss = 0.016155, test loss = 0.350931
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 143/200. Took 0.031606 seconds. 
  Full-batch training loss = 0.015981, test loss = 0.351269
  Training set accuracy = 1.000000, Test set accuracy = 0.903700
 epoch 144/200. Took 0.029023 seconds. 
  Full-batch training loss = 0.015814, test loss = 0.351514
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 145/200. Took 0.028654 seconds. 
  Full-batch training loss = 0.015635, test loss = 0.351488
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 146/200. Took 0.031445 seconds. 
  Full-batch training loss = 0.015475, test loss = 0.352003
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 147/200. Took 0.031228 seconds. 
  Full-batch training loss = 0.015320, test loss = 0.351791
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 148/200. Took 0.033484 seconds. 
  Full-batch training loss = 0.015150, test loss = 0.352567
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 149/200. Took 0.034805 seconds. 
  Full-batch training loss = 0.014981, test loss = 0.352822
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 150/200. Took 0.031134 seconds. 
  Full-batch training loss = 0.014833, test loss = 0.352957
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 151/200. Took 0.031823 seconds. 
  Full-batch training loss = 0.014687, test loss = 0.353612
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 152/200. Took 0.031296 seconds. 
  Full-batch training loss = 0.014526, test loss = 0.353773
  Training set accuracy = 1.000000, Test set accuracy = 0.904000
 epoch 153/200. Took 0.033304 seconds. 
  Full-batch training loss = 0.014383, test loss = 0.353963
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 154/200. Took 0.03301 seconds. 
  Full-batch training loss = 0.014238, test loss = 0.354085
  Training set accuracy = 1.000000, Test set accuracy = 0.903800
 epoch 155/200. Took 0.036731 seconds. 
  Full-batch training loss = 0.014093, test loss = 0.354652
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 156/200. Took 0.031181 seconds. 
  Full-batch training loss = 0.013962, test loss = 0.354869
  Training set accuracy = 1.000000, Test set accuracy = 0.903600
 epoch 157/200. Took 0.031097 seconds. 
  Full-batch training loss = 0.013820, test loss = 0.355259
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 158/200. Took 0.031046 seconds. 
  Full-batch training loss = 0.013691, test loss = 0.355008
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 159/200. Took 0.030649 seconds. 
  Full-batch training loss = 0.013563, test loss = 0.355499
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 160/200. Took 0.03179 seconds. 
  Full-batch training loss = 0.013427, test loss = 0.356009
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 161/200. Took 0.029167 seconds. 
  Full-batch training loss = 0.013302, test loss = 0.355955
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 162/200. Took 0.031627 seconds. 
  Full-batch training loss = 0.013171, test loss = 0.356337
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 163/200. Took 0.029053 seconds. 
  Full-batch training loss = 0.013065, test loss = 0.356514
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 164/200. Took 0.035773 seconds. 
  Full-batch training loss = 0.012935, test loss = 0.356977
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 165/200. Took 0.031291 seconds. 
  Full-batch training loss = 0.012815, test loss = 0.357341
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 166/200. Took 0.032212 seconds. 
  Full-batch training loss = 0.012690, test loss = 0.357434
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 167/200. Took 0.032126 seconds. 
  Full-batch training loss = 0.012573, test loss = 0.357489
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 168/200. Took 0.03197 seconds. 
  Full-batch training loss = 0.012463, test loss = 0.357880
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 169/200. Took 0.028794 seconds. 
  Full-batch training loss = 0.012350, test loss = 0.358116
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 170/200. Took 0.028099 seconds. 
  Full-batch training loss = 0.012241, test loss = 0.358234
  Training set accuracy = 1.000000, Test set accuracy = 0.904700
 epoch 171/200. Took 0.028799 seconds. 
  Full-batch training loss = 0.012138, test loss = 0.358352
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 172/200. Took 0.03214 seconds. 
  Full-batch training loss = 0.012027, test loss = 0.358546
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 173/200. Took 0.031311 seconds. 
  Full-batch training loss = 0.011919, test loss = 0.358993
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 174/200. Took 0.032005 seconds. 
  Full-batch training loss = 0.011818, test loss = 0.359336
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 175/200. Took 0.032125 seconds. 
  Full-batch training loss = 0.011718, test loss = 0.359541
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 176/200. Took 0.028628 seconds. 
  Full-batch training loss = 0.011624, test loss = 0.360142
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 177/200. Took 0.036992 seconds. 
  Full-batch training loss = 0.011521, test loss = 0.359940
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 178/200. Took 0.028944 seconds. 
  Full-batch training loss = 0.011420, test loss = 0.360364
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 179/200. Took 0.030113 seconds. 
  Full-batch training loss = 0.011328, test loss = 0.360798
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 180/200. Took 0.02929 seconds. 
  Full-batch training loss = 0.011236, test loss = 0.361181
  Training set accuracy = 1.000000, Test set accuracy = 0.904100
 epoch 181/200. Took 0.032141 seconds. 
  Full-batch training loss = 0.011138, test loss = 0.360862
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 182/200. Took 0.029522 seconds. 
  Full-batch training loss = 0.011045, test loss = 0.361161
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 183/200. Took 0.03118 seconds. 
  Full-batch training loss = 0.010963, test loss = 0.361352
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 184/200. Took 0.030727 seconds. 
  Full-batch training loss = 0.010874, test loss = 0.361693
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 185/200. Took 0.030381 seconds. 
  Full-batch training loss = 0.010782, test loss = 0.362090
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 186/200. Took 0.030781 seconds. 
  Full-batch training loss = 0.010698, test loss = 0.362272
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 187/200. Took 0.031731 seconds. 
  Full-batch training loss = 0.010609, test loss = 0.362270
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 188/200. Took 0.035932 seconds. 
  Full-batch training loss = 0.010530, test loss = 0.362891
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 189/200. Took 0.032418 seconds. 
  Full-batch training loss = 0.010446, test loss = 0.363148
  Training set accuracy = 1.000000, Test set accuracy = 0.904300
 epoch 190/200. Took 0.033117 seconds. 
  Full-batch training loss = 0.010361, test loss = 0.362983
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 191/200. Took 0.031025 seconds. 
  Full-batch training loss = 0.010283, test loss = 0.363340
  Training set accuracy = 1.000000, Test set accuracy = 0.904400
 epoch 192/200. Took 0.031795 seconds. 
  Full-batch training loss = 0.010206, test loss = 0.363631
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 193/200. Took 0.031004 seconds. 
  Full-batch training loss = 0.010126, test loss = 0.363779
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 194/200. Took 0.030955 seconds. 
  Full-batch training loss = 0.010049, test loss = 0.364327
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 195/200. Took 0.030447 seconds. 
  Full-batch training loss = 0.009973, test loss = 0.364351
  Training set accuracy = 1.000000, Test set accuracy = 0.904200
 epoch 196/200. Took 0.030631 seconds. 
  Full-batch training loss = 0.009898, test loss = 0.364334
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 197/200. Took 0.031811 seconds. 
  Full-batch training loss = 0.009825, test loss = 0.364560
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 198/200. Took 0.031069 seconds. 
  Full-batch training loss = 0.009753, test loss = 0.364802
  Training set accuracy = 1.000000, Test set accuracy = 0.904600
 epoch 199/200. Took 0.035322 seconds. 
  Full-batch training loss = 0.009679, test loss = 0.365085
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
 epoch 200/200. Took 0.031436 seconds. 
  Full-batch training loss = 0.009612, test loss = 0.365688
  Training set accuracy = 1.000000, Test set accuracy = 0.904500
Elapsed time is 28.493367 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.039547 seconds. 
  Full-batch training loss = 2.241622, test loss = 2.241239
  Training set accuracy = 0.278000, Test set accuracy = 0.282600
 epoch 2/200. Took 0.034615 seconds. 
  Full-batch training loss = 2.164410, test loss = 2.164969
  Training set accuracy = 0.529500, Test set accuracy = 0.510200
 epoch 3/200. Took 0.033767 seconds. 
  Full-batch training loss = 2.096520, test loss = 2.097987
  Training set accuracy = 0.589000, Test set accuracy = 0.578200
 epoch 4/200. Took 0.031964 seconds. 
  Full-batch training loss = 2.027582, test loss = 2.029749
  Training set accuracy = 0.639500, Test set accuracy = 0.630600
 epoch 5/200. Took 0.03615 seconds. 
  Full-batch training loss = 1.958832, test loss = 1.961573
  Training set accuracy = 0.659000, Test set accuracy = 0.652100
 epoch 6/200. Took 0.032579 seconds. 
  Full-batch training loss = 1.888393, test loss = 1.891979
  Training set accuracy = 0.672500, Test set accuracy = 0.659600
 epoch 7/200. Took 0.030187 seconds. 
  Full-batch training loss = 1.817307, test loss = 1.821525
  Training set accuracy = 0.688000, Test set accuracy = 0.679100
 epoch 8/200. Took 0.037617 seconds. 
  Full-batch training loss = 1.746227, test loss = 1.750944
  Training set accuracy = 0.701000, Test set accuracy = 0.698700
 epoch 9/200. Took 0.033025 seconds. 
  Full-batch training loss = 1.675302, test loss = 1.680936
  Training set accuracy = 0.710000, Test set accuracy = 0.705900
 epoch 10/200. Took 0.036446 seconds. 
  Full-batch training loss = 1.605238, test loss = 1.611536
  Training set accuracy = 0.719500, Test set accuracy = 0.713300
 epoch 11/200. Took 0.03034 seconds. 
  Full-batch training loss = 1.537316, test loss = 1.544385
  Training set accuracy = 0.728000, Test set accuracy = 0.721000
 epoch 12/200. Took 0.030957 seconds. 
  Full-batch training loss = 1.471593, test loss = 1.479630
  Training set accuracy = 0.739000, Test set accuracy = 0.732800
 epoch 13/200. Took 0.030311 seconds. 
  Full-batch training loss = 1.408735, test loss = 1.417432
  Training set accuracy = 0.747000, Test set accuracy = 0.744300
 epoch 14/200. Took 0.030348 seconds. 
  Full-batch training loss = 1.349261, test loss = 1.358857
  Training set accuracy = 0.755000, Test set accuracy = 0.751400
 epoch 15/200. Took 0.030485 seconds. 
  Full-batch training loss = 1.293104, test loss = 1.303886
  Training set accuracy = 0.763500, Test set accuracy = 0.761000
 epoch 16/200. Took 0.032173 seconds. 
  Full-batch training loss = 1.240567, test loss = 1.252148
  Training set accuracy = 0.773000, Test set accuracy = 0.767900
 epoch 17/200. Took 0.032769 seconds. 
  Full-batch training loss = 1.191442, test loss = 1.203626
  Training set accuracy = 0.783000, Test set accuracy = 0.783300
 epoch 18/200. Took 0.032 seconds. 
  Full-batch training loss = 1.145749, test loss = 1.158893
  Training set accuracy = 0.787000, Test set accuracy = 0.784800
 epoch 19/200. Took 0.036814 seconds. 
  Full-batch training loss = 1.103149, test loss = 1.117200
  Training set accuracy = 0.794500, Test set accuracy = 0.790900
 epoch 20/200. Took 0.031775 seconds. 
  Full-batch training loss = 1.063662, test loss = 1.078982
  Training set accuracy = 0.800500, Test set accuracy = 0.796300
 epoch 21/200. Took 0.029882 seconds. 
  Full-batch training loss = 1.026836, test loss = 1.042423
  Training set accuracy = 0.806000, Test set accuracy = 0.803000
 epoch 22/200. Took 0.031275 seconds. 
  Full-batch training loss = 0.992351, test loss = 1.008994
  Training set accuracy = 0.817000, Test set accuracy = 0.809600
 epoch 23/200. Took 0.029819 seconds. 
  Full-batch training loss = 0.960622, test loss = 0.978208
  Training set accuracy = 0.818500, Test set accuracy = 0.813000
 epoch 24/200. Took 0.029543 seconds. 
  Full-batch training loss = 0.930765, test loss = 0.949319
  Training set accuracy = 0.824000, Test set accuracy = 0.816400
 epoch 25/200. Took 0.029674 seconds. 
  Full-batch training loss = 0.903085, test loss = 0.922549
  Training set accuracy = 0.830500, Test set accuracy = 0.817700
 epoch 26/200. Took 0.038007 seconds. 
  Full-batch training loss = 0.877190, test loss = 0.896965
  Training set accuracy = 0.834000, Test set accuracy = 0.826200
 epoch 27/200. Took 0.030885 seconds. 
  Full-batch training loss = 0.852804, test loss = 0.873472
  Training set accuracy = 0.836000, Test set accuracy = 0.829300
 epoch 28/200. Took 0.035029 seconds. 
  Full-batch training loss = 0.830025, test loss = 0.851610
  Training set accuracy = 0.839500, Test set accuracy = 0.831000
 epoch 29/200. Took 0.032342 seconds. 
  Full-batch training loss = 0.808479, test loss = 0.830910
  Training set accuracy = 0.845000, Test set accuracy = 0.835400
 epoch 30/200. Took 0.033332 seconds. 
  Full-batch training loss = 0.788395, test loss = 0.811789
  Training set accuracy = 0.847500, Test set accuracy = 0.836000
 epoch 31/200. Took 0.033353 seconds. 
  Full-batch training loss = 0.769440, test loss = 0.793362
  Training set accuracy = 0.851500, Test set accuracy = 0.839100
 epoch 32/200. Took 0.032425 seconds. 
  Full-batch training loss = 0.751392, test loss = 0.776094
  Training set accuracy = 0.853500, Test set accuracy = 0.842600
 epoch 33/200. Took 0.037108 seconds. 
  Full-batch training loss = 0.734395, test loss = 0.759953
  Training set accuracy = 0.858500, Test set accuracy = 0.843600
 epoch 34/200. Took 0.032926 seconds. 
  Full-batch training loss = 0.718561, test loss = 0.744666
  Training set accuracy = 0.856000, Test set accuracy = 0.844300
 epoch 35/200. Took 0.034508 seconds. 
  Full-batch training loss = 0.703235, test loss = 0.730315
  Training set accuracy = 0.862000, Test set accuracy = 0.848400
 epoch 36/200. Took 0.033025 seconds. 
  Full-batch training loss = 0.688736, test loss = 0.716410
  Training set accuracy = 0.860000, Test set accuracy = 0.849200
 epoch 37/200. Took 0.033014 seconds. 
  Full-batch training loss = 0.674983, test loss = 0.703510
  Training set accuracy = 0.862500, Test set accuracy = 0.850500
 epoch 38/200. Took 0.036752 seconds. 
  Full-batch training loss = 0.661793, test loss = 0.691022
  Training set accuracy = 0.866000, Test set accuracy = 0.853400
 epoch 39/200. Took 0.032439 seconds. 
  Full-batch training loss = 0.649283, test loss = 0.679249
  Training set accuracy = 0.865500, Test set accuracy = 0.854700
 epoch 40/200. Took 0.034029 seconds. 
  Full-batch training loss = 0.637284, test loss = 0.668160
  Training set accuracy = 0.867500, Test set accuracy = 0.855800
 epoch 41/200. Took 0.032446 seconds. 
  Full-batch training loss = 0.625786, test loss = 0.657257
  Training set accuracy = 0.872000, Test set accuracy = 0.858000
 epoch 42/200. Took 0.032554 seconds. 
  Full-batch training loss = 0.615090, test loss = 0.647209
  Training set accuracy = 0.873000, Test set accuracy = 0.859400
 epoch 43/200. Took 0.033821 seconds. 
  Full-batch training loss = 0.604514, test loss = 0.637324
  Training set accuracy = 0.878000, Test set accuracy = 0.860800
 epoch 44/200. Took 0.033351 seconds. 
  Full-batch training loss = 0.594513, test loss = 0.627986
  Training set accuracy = 0.879500, Test set accuracy = 0.862800
 epoch 45/200. Took 0.031312 seconds. 
  Full-batch training loss = 0.584780, test loss = 0.619119
  Training set accuracy = 0.881000, Test set accuracy = 0.863000
 epoch 46/200. Took 0.031978 seconds. 
  Full-batch training loss = 0.575561, test loss = 0.610928
  Training set accuracy = 0.881500, Test set accuracy = 0.863400
 epoch 47/200. Took 0.033505 seconds. 
  Full-batch training loss = 0.566694, test loss = 0.602477
  Training set accuracy = 0.885500, Test set accuracy = 0.865200
 epoch 48/200. Took 0.035814 seconds. 
  Full-batch training loss = 0.558136, test loss = 0.594855
  Training set accuracy = 0.886000, Test set accuracy = 0.865500
 epoch 49/200. Took 0.032472 seconds. 
  Full-batch training loss = 0.549830, test loss = 0.587015
  Training set accuracy = 0.885500, Test set accuracy = 0.865700
 epoch 50/200. Took 0.035047 seconds. 
  Full-batch training loss = 0.541938, test loss = 0.580041
  Training set accuracy = 0.887500, Test set accuracy = 0.866900
 epoch 51/200. Took 0.032477 seconds. 
  Full-batch training loss = 0.534285, test loss = 0.573218
  Training set accuracy = 0.888000, Test set accuracy = 0.868800
 epoch 52/200. Took 0.029838 seconds. 
  Full-batch training loss = 0.526859, test loss = 0.566256
  Training set accuracy = 0.890000, Test set accuracy = 0.869400
 epoch 53/200. Took 0.029705 seconds. 
  Full-batch training loss = 0.519733, test loss = 0.559863
  Training set accuracy = 0.890000, Test set accuracy = 0.869900
 epoch 54/200. Took 0.030457 seconds. 
  Full-batch training loss = 0.512764, test loss = 0.553446
  Training set accuracy = 0.893500, Test set accuracy = 0.871800
 epoch 55/200. Took 0.03016 seconds. 
  Full-batch training loss = 0.506143, test loss = 0.547676
  Training set accuracy = 0.894500, Test set accuracy = 0.870700
 epoch 56/200. Took 0.029498 seconds. 
  Full-batch training loss = 0.499768, test loss = 0.541911
  Training set accuracy = 0.894500, Test set accuracy = 0.871900
 epoch 57/200. Took 0.02978 seconds. 
  Full-batch training loss = 0.493412, test loss = 0.536568
  Training set accuracy = 0.897000, Test set accuracy = 0.873300
 epoch 58/200. Took 0.032307 seconds. 
  Full-batch training loss = 0.487405, test loss = 0.531194
  Training set accuracy = 0.897000, Test set accuracy = 0.873800
 epoch 59/200. Took 0.036859 seconds. 
  Full-batch training loss = 0.481515, test loss = 0.526039
  Training set accuracy = 0.898500, Test set accuracy = 0.875000
 epoch 60/200. Took 0.031931 seconds. 
  Full-batch training loss = 0.475911, test loss = 0.520830
  Training set accuracy = 0.899000, Test set accuracy = 0.876300
 epoch 61/200. Took 0.03249 seconds. 
  Full-batch training loss = 0.470382, test loss = 0.516255
  Training set accuracy = 0.900000, Test set accuracy = 0.876200
 epoch 62/200. Took 0.032162 seconds. 
  Full-batch training loss = 0.465019, test loss = 0.511470
  Training set accuracy = 0.900000, Test set accuracy = 0.877100
 epoch 63/200. Took 0.031834 seconds. 
  Full-batch training loss = 0.459829, test loss = 0.507093
  Training set accuracy = 0.900500, Test set accuracy = 0.878000
 epoch 64/200. Took 0.033194 seconds. 
  Full-batch training loss = 0.454759, test loss = 0.502661
  Training set accuracy = 0.902500, Test set accuracy = 0.878000
 epoch 65/200. Took 0.034882 seconds. 
  Full-batch training loss = 0.449881, test loss = 0.498534
  Training set accuracy = 0.900500, Test set accuracy = 0.878900
 epoch 66/200. Took 0.032205 seconds. 
  Full-batch training loss = 0.445139, test loss = 0.494358
  Training set accuracy = 0.901500, Test set accuracy = 0.879000
 epoch 67/200. Took 0.03058 seconds. 
  Full-batch training loss = 0.440432, test loss = 0.490604
  Training set accuracy = 0.904000, Test set accuracy = 0.880200
 epoch 68/200. Took 0.033229 seconds. 
  Full-batch training loss = 0.435947, test loss = 0.486854
  Training set accuracy = 0.901500, Test set accuracy = 0.879900
 epoch 69/200. Took 0.030284 seconds. 
  Full-batch training loss = 0.431582, test loss = 0.482981
  Training set accuracy = 0.906500, Test set accuracy = 0.881200
 epoch 70/200. Took 0.031873 seconds. 
  Full-batch training loss = 0.427279, test loss = 0.479408
  Training set accuracy = 0.905000, Test set accuracy = 0.881400
 epoch 71/200. Took 0.037143 seconds. 
  Full-batch training loss = 0.423140, test loss = 0.475764
  Training set accuracy = 0.905000, Test set accuracy = 0.881600
 epoch 72/200. Took 0.03293 seconds. 
  Full-batch training loss = 0.419063, test loss = 0.472330
  Training set accuracy = 0.907000, Test set accuracy = 0.882200
 epoch 73/200. Took 0.032397 seconds. 
  Full-batch training loss = 0.415197, test loss = 0.469070
  Training set accuracy = 0.907500, Test set accuracy = 0.882800
 epoch 74/200. Took 0.032205 seconds. 
  Full-batch training loss = 0.411267, test loss = 0.465818
  Training set accuracy = 0.909500, Test set accuracy = 0.883000
 epoch 75/200. Took 0.032488 seconds. 
  Full-batch training loss = 0.407520, test loss = 0.462796
  Training set accuracy = 0.910500, Test set accuracy = 0.883300
 epoch 76/200. Took 0.036551 seconds. 
  Full-batch training loss = 0.403838, test loss = 0.459902
  Training set accuracy = 0.908000, Test set accuracy = 0.883900
 epoch 77/200. Took 0.032607 seconds. 
  Full-batch training loss = 0.400214, test loss = 0.456885
  Training set accuracy = 0.909000, Test set accuracy = 0.883900
 epoch 78/200. Took 0.03134 seconds. 
  Full-batch training loss = 0.396759, test loss = 0.454066
  Training set accuracy = 0.909500, Test set accuracy = 0.884200
 epoch 79/200. Took 0.031821 seconds. 
  Full-batch training loss = 0.393262, test loss = 0.451197
  Training set accuracy = 0.909000, Test set accuracy = 0.884100
 epoch 80/200. Took 0.02967 seconds. 
  Full-batch training loss = 0.389969, test loss = 0.448591
  Training set accuracy = 0.910500, Test set accuracy = 0.883900
 epoch 81/200. Took 0.032567 seconds. 
  Full-batch training loss = 0.386683, test loss = 0.446073
  Training set accuracy = 0.913000, Test set accuracy = 0.884600
 epoch 82/200. Took 0.029394 seconds. 
  Full-batch training loss = 0.383467, test loss = 0.443465
  Training set accuracy = 0.913500, Test set accuracy = 0.884700
 epoch 83/200. Took 0.034477 seconds. 
  Full-batch training loss = 0.380378, test loss = 0.441022
  Training set accuracy = 0.914000, Test set accuracy = 0.884700
 epoch 84/200. Took 0.029085 seconds. 
  Full-batch training loss = 0.377285, test loss = 0.438565
  Training set accuracy = 0.914500, Test set accuracy = 0.884900
 epoch 85/200. Took 0.03388 seconds. 
  Full-batch training loss = 0.374329, test loss = 0.436283
  Training set accuracy = 0.915500, Test set accuracy = 0.886000
 epoch 86/200. Took 0.033218 seconds. 
  Full-batch training loss = 0.371320, test loss = 0.433986
  Training set accuracy = 0.916500, Test set accuracy = 0.885300
 epoch 87/200. Took 0.030745 seconds. 
  Full-batch training loss = 0.368459, test loss = 0.431587
  Training set accuracy = 0.915000, Test set accuracy = 0.885800
 epoch 88/200. Took 0.031119 seconds. 
  Full-batch training loss = 0.365680, test loss = 0.429671
  Training set accuracy = 0.917000, Test set accuracy = 0.885800
 epoch 89/200. Took 0.032187 seconds. 
  Full-batch training loss = 0.362908, test loss = 0.427278
  Training set accuracy = 0.916000, Test set accuracy = 0.888000
 epoch 90/200. Took 0.032335 seconds. 
  Full-batch training loss = 0.360191, test loss = 0.425521
  Training set accuracy = 0.917500, Test set accuracy = 0.886700
 epoch 91/200. Took 0.029969 seconds. 
  Full-batch training loss = 0.357498, test loss = 0.423293
  Training set accuracy = 0.918000, Test set accuracy = 0.887200
 epoch 92/200. Took 0.037252 seconds. 
  Full-batch training loss = 0.354873, test loss = 0.421314
  Training set accuracy = 0.918000, Test set accuracy = 0.887100
 epoch 93/200. Took 0.02996 seconds. 
  Full-batch training loss = 0.352355, test loss = 0.419356
  Training set accuracy = 0.918000, Test set accuracy = 0.887000
 epoch 94/200. Took 0.030276 seconds. 
  Full-batch training loss = 0.349815, test loss = 0.417454
  Training set accuracy = 0.918000, Test set accuracy = 0.887600
 epoch 95/200. Took 0.032941 seconds. 
  Full-batch training loss = 0.347402, test loss = 0.415810
  Training set accuracy = 0.918000, Test set accuracy = 0.887800
 epoch 96/200. Took 0.033352 seconds. 
  Full-batch training loss = 0.344966, test loss = 0.414056
  Training set accuracy = 0.918500, Test set accuracy = 0.888400
 epoch 97/200. Took 0.034634 seconds. 
  Full-batch training loss = 0.342556, test loss = 0.412100
  Training set accuracy = 0.920000, Test set accuracy = 0.887800
 epoch 98/200. Took 0.032942 seconds. 
  Full-batch training loss = 0.340229, test loss = 0.410638
  Training set accuracy = 0.919500, Test set accuracy = 0.888400
 epoch 99/200. Took 0.032539 seconds. 
  Full-batch training loss = 0.337931, test loss = 0.408915
  Training set accuracy = 0.919000, Test set accuracy = 0.888500
 epoch 100/200. Took 0.030283 seconds. 
  Full-batch training loss = 0.335655, test loss = 0.407130
  Training set accuracy = 0.920000, Test set accuracy = 0.888800
 epoch 101/200. Took 0.035981 seconds. 
  Full-batch training loss = 0.333465, test loss = 0.405367
  Training set accuracy = 0.919000, Test set accuracy = 0.888800
 epoch 102/200. Took 0.03014 seconds. 
  Full-batch training loss = 0.331270, test loss = 0.404127
  Training set accuracy = 0.919000, Test set accuracy = 0.890000
 epoch 103/200. Took 0.030246 seconds. 
  Full-batch training loss = 0.329123, test loss = 0.402442
  Training set accuracy = 0.920500, Test set accuracy = 0.890400
 epoch 104/200. Took 0.029624 seconds. 
  Full-batch training loss = 0.327014, test loss = 0.400777
  Training set accuracy = 0.921500, Test set accuracy = 0.890200
 epoch 105/200. Took 0.031072 seconds. 
  Full-batch training loss = 0.324922, test loss = 0.399413
  Training set accuracy = 0.921000, Test set accuracy = 0.890000
 epoch 106/200. Took 0.03547 seconds. 
  Full-batch training loss = 0.322853, test loss = 0.398034
  Training set accuracy = 0.922000, Test set accuracy = 0.890600
 epoch 107/200. Took 0.031074 seconds. 
  Full-batch training loss = 0.320824, test loss = 0.396627
  Training set accuracy = 0.923000, Test set accuracy = 0.890600
 epoch 108/200. Took 0.034726 seconds. 
  Full-batch training loss = 0.318894, test loss = 0.395435
  Training set accuracy = 0.920500, Test set accuracy = 0.890800
 epoch 109/200. Took 0.032513 seconds. 
  Full-batch training loss = 0.316882, test loss = 0.393928
  Training set accuracy = 0.923000, Test set accuracy = 0.891200
 epoch 110/200. Took 0.0334 seconds. 
  Full-batch training loss = 0.314990, test loss = 0.392406
  Training set accuracy = 0.923000, Test set accuracy = 0.891600
 epoch 111/200. Took 0.02939 seconds. 
  Full-batch training loss = 0.313052, test loss = 0.391320
  Training set accuracy = 0.922500, Test set accuracy = 0.891400
 epoch 112/200. Took 0.034004 seconds. 
  Full-batch training loss = 0.311202, test loss = 0.389935
  Training set accuracy = 0.923500, Test set accuracy = 0.892000
 epoch 113/200. Took 0.032593 seconds. 
  Full-batch training loss = 0.309326, test loss = 0.388753
  Training set accuracy = 0.923000, Test set accuracy = 0.891900
 epoch 114/200. Took 0.032138 seconds. 
  Full-batch training loss = 0.307527, test loss = 0.387475
  Training set accuracy = 0.924000, Test set accuracy = 0.892400
 epoch 115/200. Took 0.03189 seconds. 
  Full-batch training loss = 0.305723, test loss = 0.386411
  Training set accuracy = 0.924500, Test set accuracy = 0.892800
 epoch 116/200. Took 0.032264 seconds. 
  Full-batch training loss = 0.303971, test loss = 0.385246
  Training set accuracy = 0.925000, Test set accuracy = 0.893000
 epoch 117/200. Took 0.030171 seconds. 
  Full-batch training loss = 0.302205, test loss = 0.384093
  Training set accuracy = 0.925000, Test set accuracy = 0.892900
 epoch 118/200. Took 0.030012 seconds. 
  Full-batch training loss = 0.300459, test loss = 0.382887
  Training set accuracy = 0.926000, Test set accuracy = 0.893800
 epoch 119/200. Took 0.029653 seconds. 
  Full-batch training loss = 0.298758, test loss = 0.381846
  Training set accuracy = 0.926500, Test set accuracy = 0.893900
 epoch 120/200. Took 0.034388 seconds. 
  Full-batch training loss = 0.297108, test loss = 0.380736
  Training set accuracy = 0.927000, Test set accuracy = 0.894000
 epoch 121/200. Took 0.032192 seconds. 
  Full-batch training loss = 0.295429, test loss = 0.379782
  Training set accuracy = 0.927000, Test set accuracy = 0.894200
 epoch 122/200. Took 0.031239 seconds. 
  Full-batch training loss = 0.293889, test loss = 0.378800
  Training set accuracy = 0.926500, Test set accuracy = 0.893800
 epoch 123/200. Took 0.030662 seconds. 
  Full-batch training loss = 0.292229, test loss = 0.377688
  Training set accuracy = 0.927500, Test set accuracy = 0.894600
 epoch 124/200. Took 0.033906 seconds. 
  Full-batch training loss = 0.290595, test loss = 0.376724
  Training set accuracy = 0.928500, Test set accuracy = 0.895400
 epoch 125/200. Took 0.033821 seconds. 
  Full-batch training loss = 0.288986, test loss = 0.375614
  Training set accuracy = 0.928000, Test set accuracy = 0.895100
 epoch 126/200. Took 0.034204 seconds. 
  Full-batch training loss = 0.287466, test loss = 0.374733
  Training set accuracy = 0.929000, Test set accuracy = 0.895200
 epoch 127/200. Took 0.037447 seconds. 
  Full-batch training loss = 0.285930, test loss = 0.373679
  Training set accuracy = 0.929500, Test set accuracy = 0.895800
 epoch 128/200. Took 0.032418 seconds. 
  Full-batch training loss = 0.284385, test loss = 0.372821
  Training set accuracy = 0.930000, Test set accuracy = 0.896200
 epoch 129/200. Took 0.033504 seconds. 
  Full-batch training loss = 0.282893, test loss = 0.371670
  Training set accuracy = 0.930000, Test set accuracy = 0.895800
 epoch 130/200. Took 0.033285 seconds. 
  Full-batch training loss = 0.281396, test loss = 0.370961
  Training set accuracy = 0.929500, Test set accuracy = 0.895400
 epoch 131/200. Took 0.034668 seconds. 
  Full-batch training loss = 0.279934, test loss = 0.369907
  Training set accuracy = 0.931000, Test set accuracy = 0.896700
 epoch 132/200. Took 0.033184 seconds. 
  Full-batch training loss = 0.278484, test loss = 0.369257
  Training set accuracy = 0.930500, Test set accuracy = 0.896000
 epoch 133/200. Took 0.032643 seconds. 
  Full-batch training loss = 0.277032, test loss = 0.368252
  Training set accuracy = 0.931500, Test set accuracy = 0.897000
 epoch 134/200. Took 0.03539 seconds. 
  Full-batch training loss = 0.275645, test loss = 0.367576
  Training set accuracy = 0.931500, Test set accuracy = 0.897000
 epoch 135/200. Took 0.033459 seconds. 
  Full-batch training loss = 0.274200, test loss = 0.366565
  Training set accuracy = 0.932000, Test set accuracy = 0.897200
 epoch 136/200. Took 0.033162 seconds. 
  Full-batch training loss = 0.272805, test loss = 0.365890
  Training set accuracy = 0.932000, Test set accuracy = 0.897100
 epoch 137/200. Took 0.03291 seconds. 
  Full-batch training loss = 0.271433, test loss = 0.364845
  Training set accuracy = 0.932500, Test set accuracy = 0.897600
 epoch 138/200. Took 0.032537 seconds. 
  Full-batch training loss = 0.270072, test loss = 0.364164
  Training set accuracy = 0.933000, Test set accuracy = 0.897800
 epoch 139/200. Took 0.036928 seconds. 
  Full-batch training loss = 0.268722, test loss = 0.363478
  Training set accuracy = 0.934000, Test set accuracy = 0.897700
 epoch 140/200. Took 0.032646 seconds. 
  Full-batch training loss = 0.267393, test loss = 0.362709
  Training set accuracy = 0.934000, Test set accuracy = 0.897700
 epoch 141/200. Took 0.035716 seconds. 
  Full-batch training loss = 0.266050, test loss = 0.361921
  Training set accuracy = 0.934000, Test set accuracy = 0.898000
 epoch 142/200. Took 0.030402 seconds. 
  Full-batch training loss = 0.264760, test loss = 0.361215
  Training set accuracy = 0.934500, Test set accuracy = 0.898500
 epoch 143/200. Took 0.031114 seconds. 
  Full-batch training loss = 0.263496, test loss = 0.360591
  Training set accuracy = 0.934500, Test set accuracy = 0.898300
 epoch 144/200. Took 0.02918 seconds. 
  Full-batch training loss = 0.262166, test loss = 0.359805
  Training set accuracy = 0.935000, Test set accuracy = 0.898700
 epoch 145/200. Took 0.031281 seconds. 
  Full-batch training loss = 0.260901, test loss = 0.359077
  Training set accuracy = 0.934000, Test set accuracy = 0.899300
 epoch 146/200. Took 0.033074 seconds. 
  Full-batch training loss = 0.259656, test loss = 0.358300
  Training set accuracy = 0.934000, Test set accuracy = 0.899300
 epoch 147/200. Took 0.030232 seconds. 
  Full-batch training loss = 0.258405, test loss = 0.357716
  Training set accuracy = 0.935000, Test set accuracy = 0.899100
 epoch 148/200. Took 0.035327 seconds. 
  Full-batch training loss = 0.257200, test loss = 0.356923
  Training set accuracy = 0.935000, Test set accuracy = 0.899000
 epoch 149/200. Took 0.032552 seconds. 
  Full-batch training loss = 0.256003, test loss = 0.356313
  Training set accuracy = 0.936000, Test set accuracy = 0.899200
 epoch 150/200. Took 0.029628 seconds. 
  Full-batch training loss = 0.254715, test loss = 0.355605
  Training set accuracy = 0.935500, Test set accuracy = 0.899400
 epoch 151/200. Took 0.035664 seconds. 
  Full-batch training loss = 0.253517, test loss = 0.355074
  Training set accuracy = 0.935500, Test set accuracy = 0.899500
 epoch 152/200. Took 0.029525 seconds. 
  Full-batch training loss = 0.252343, test loss = 0.354307
  Training set accuracy = 0.937000, Test set accuracy = 0.899400
 epoch 153/200. Took 0.036796 seconds. 
  Full-batch training loss = 0.251174, test loss = 0.353896
  Training set accuracy = 0.937000, Test set accuracy = 0.899700
 epoch 154/200. Took 0.032486 seconds. 
  Full-batch training loss = 0.249971, test loss = 0.353263
  Training set accuracy = 0.936000, Test set accuracy = 0.899300
 epoch 155/200. Took 0.03129 seconds. 
  Full-batch training loss = 0.248857, test loss = 0.352328
  Training set accuracy = 0.937000, Test set accuracy = 0.900200
 epoch 156/200. Took 0.030547 seconds. 
  Full-batch training loss = 0.247701, test loss = 0.351805
  Training set accuracy = 0.937500, Test set accuracy = 0.900400
 epoch 157/200. Took 0.030465 seconds. 
  Full-batch training loss = 0.246573, test loss = 0.351448
  Training set accuracy = 0.938500, Test set accuracy = 0.900400
 epoch 158/200. Took 0.032622 seconds. 
  Full-batch training loss = 0.245416, test loss = 0.350731
  Training set accuracy = 0.937500, Test set accuracy = 0.900100
 epoch 159/200. Took 0.030623 seconds. 
  Full-batch training loss = 0.244299, test loss = 0.350152
  Training set accuracy = 0.938500, Test set accuracy = 0.900500
 epoch 160/200. Took 0.035172 seconds. 
  Full-batch training loss = 0.243209, test loss = 0.349895
  Training set accuracy = 0.938500, Test set accuracy = 0.900700
 epoch 161/200. Took 0.03723 seconds. 
  Full-batch training loss = 0.242087, test loss = 0.349092
  Training set accuracy = 0.939000, Test set accuracy = 0.900800
 epoch 162/200. Took 0.032084 seconds. 
  Full-batch training loss = 0.241013, test loss = 0.348586
  Training set accuracy = 0.938500, Test set accuracy = 0.900900
 epoch 163/200. Took 0.030849 seconds. 
  Full-batch training loss = 0.239935, test loss = 0.348119
  Training set accuracy = 0.939500, Test set accuracy = 0.901300
 epoch 164/200. Took 0.029344 seconds. 
  Full-batch training loss = 0.238838, test loss = 0.347449
  Training set accuracy = 0.939500, Test set accuracy = 0.900800
 epoch 165/200. Took 0.033551 seconds. 
  Full-batch training loss = 0.237803, test loss = 0.347119
  Training set accuracy = 0.939500, Test set accuracy = 0.901000
 epoch 166/200. Took 0.029769 seconds. 
  Full-batch training loss = 0.236735, test loss = 0.346591
  Training set accuracy = 0.940000, Test set accuracy = 0.901100
 epoch 167/200. Took 0.033771 seconds. 
  Full-batch training loss = 0.235654, test loss = 0.345977
  Training set accuracy = 0.940000, Test set accuracy = 0.901200
 epoch 168/200. Took 0.033844 seconds. 
  Full-batch training loss = 0.234685, test loss = 0.345448
  Training set accuracy = 0.941000, Test set accuracy = 0.901100
 epoch 169/200. Took 0.031639 seconds. 
  Full-batch training loss = 0.233623, test loss = 0.344856
  Training set accuracy = 0.940000, Test set accuracy = 0.901100
 epoch 170/200. Took 0.029702 seconds. 
  Full-batch training loss = 0.232601, test loss = 0.344612
  Training set accuracy = 0.941000, Test set accuracy = 0.901300
 epoch 171/200. Took 0.030382 seconds. 
  Full-batch training loss = 0.231565, test loss = 0.344086
  Training set accuracy = 0.941000, Test set accuracy = 0.901200
 epoch 172/200. Took 0.030399 seconds. 
  Full-batch training loss = 0.230571, test loss = 0.343414
  Training set accuracy = 0.940500, Test set accuracy = 0.901300
 epoch 173/200. Took 0.029356 seconds. 
  Full-batch training loss = 0.229590, test loss = 0.343199
  Training set accuracy = 0.940000, Test set accuracy = 0.902400
 epoch 174/200. Took 0.030656 seconds. 
  Full-batch training loss = 0.228560, test loss = 0.342548
  Training set accuracy = 0.941000, Test set accuracy = 0.902200
 epoch 175/200. Took 0.032535 seconds. 
  Full-batch training loss = 0.227603, test loss = 0.342204
  Training set accuracy = 0.941000, Test set accuracy = 0.902300
 epoch 176/200. Took 0.032489 seconds. 
  Full-batch training loss = 0.226606, test loss = 0.341721
  Training set accuracy = 0.942500, Test set accuracy = 0.902000
 epoch 177/200. Took 0.030016 seconds. 
  Full-batch training loss = 0.225631, test loss = 0.341299
  Training set accuracy = 0.941500, Test set accuracy = 0.902100
 epoch 178/200. Took 0.03195 seconds. 
  Full-batch training loss = 0.224697, test loss = 0.340695
  Training set accuracy = 0.943000, Test set accuracy = 0.902700
 epoch 179/200. Took 0.02936 seconds. 
  Full-batch training loss = 0.223739, test loss = 0.340445
  Training set accuracy = 0.943000, Test set accuracy = 0.902100
 epoch 180/200. Took 0.033167 seconds. 
  Full-batch training loss = 0.222764, test loss = 0.340125
  Training set accuracy = 0.943000, Test set accuracy = 0.902500
 epoch 181/200. Took 0.030578 seconds. 
  Full-batch training loss = 0.221836, test loss = 0.339418
  Training set accuracy = 0.943500, Test set accuracy = 0.902500
 epoch 182/200. Took 0.030666 seconds. 
  Full-batch training loss = 0.220872, test loss = 0.339199
  Training set accuracy = 0.943500, Test set accuracy = 0.903200
 epoch 183/200. Took 0.035762 seconds. 
  Full-batch training loss = 0.219948, test loss = 0.338833
  Training set accuracy = 0.944500, Test set accuracy = 0.902900
 epoch 184/200. Took 0.02974 seconds. 
  Full-batch training loss = 0.219038, test loss = 0.338211
  Training set accuracy = 0.945000, Test set accuracy = 0.902800
 epoch 185/200. Took 0.035805 seconds. 
  Full-batch training loss = 0.218131, test loss = 0.338008
  Training set accuracy = 0.945500, Test set accuracy = 0.902700
 epoch 186/200. Took 0.029907 seconds. 
  Full-batch training loss = 0.217226, test loss = 0.337541
  Training set accuracy = 0.946000, Test set accuracy = 0.903100
 epoch 187/200. Took 0.033098 seconds. 
  Full-batch training loss = 0.216329, test loss = 0.336942
  Training set accuracy = 0.946000, Test set accuracy = 0.903500
 epoch 188/200. Took 0.033232 seconds. 
  Full-batch training loss = 0.215401, test loss = 0.336924
  Training set accuracy = 0.945500, Test set accuracy = 0.903100
 epoch 189/200. Took 0.029477 seconds. 
  Full-batch training loss = 0.214512, test loss = 0.336353
  Training set accuracy = 0.946000, Test set accuracy = 0.903700
 epoch 190/200. Took 0.030796 seconds. 
  Full-batch training loss = 0.213624, test loss = 0.335974
  Training set accuracy = 0.947500, Test set accuracy = 0.903000
 epoch 191/200. Took 0.029629 seconds. 
  Full-batch training loss = 0.212747, test loss = 0.335611
  Training set accuracy = 0.947500, Test set accuracy = 0.903500
 epoch 192/200. Took 0.034413 seconds. 
  Full-batch training loss = 0.211905, test loss = 0.335502
  Training set accuracy = 0.947000, Test set accuracy = 0.903500
 epoch 193/200. Took 0.030237 seconds. 
  Full-batch training loss = 0.211026, test loss = 0.334957
  Training set accuracy = 0.948000, Test set accuracy = 0.904000
 epoch 194/200. Took 0.032993 seconds. 
  Full-batch training loss = 0.210205, test loss = 0.334594
  Training set accuracy = 0.949500, Test set accuracy = 0.903300
 epoch 195/200. Took 0.035584 seconds. 
  Full-batch training loss = 0.209284, test loss = 0.334236
  Training set accuracy = 0.949500, Test set accuracy = 0.904100
 epoch 196/200. Took 0.030393 seconds. 
  Full-batch training loss = 0.208459, test loss = 0.333814
  Training set accuracy = 0.949500, Test set accuracy = 0.904100
 epoch 197/200. Took 0.033013 seconds. 
  Full-batch training loss = 0.207627, test loss = 0.333728
  Training set accuracy = 0.950000, Test set accuracy = 0.904000
 epoch 198/200. Took 0.029513 seconds. 
  Full-batch training loss = 0.206770, test loss = 0.333309
  Training set accuracy = 0.951000, Test set accuracy = 0.904500
 epoch 199/200. Took 0.031739 seconds. 
  Full-batch training loss = 0.205940, test loss = 0.332866
  Training set accuracy = 0.950000, Test set accuracy = 0.904100
 epoch 200/200. Took 0.032119 seconds. 
  Full-batch training loss = 0.205132, test loss = 0.332816
  Training set accuracy = 0.950000, Test set accuracy = 0.903900
Elapsed time is 29.985009 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.001
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.034188 seconds. 
  Full-batch training loss = 2.415582, test loss = 2.407367
  Training set accuracy = 0.096000, Test set accuracy = 0.097400
 epoch 2/200. Took 0.030769 seconds. 
  Full-batch training loss = 2.370397, test loss = 2.364901
  Training set accuracy = 0.096000, Test set accuracy = 0.097400
 epoch 3/200. Took 0.033908 seconds. 
  Full-batch training loss = 2.339497, test loss = 2.336218
  Training set accuracy = 0.096000, Test set accuracy = 0.097400
 epoch 4/200. Took 0.034843 seconds. 
  Full-batch training loss = 2.316360, test loss = 2.314988
  Training set accuracy = 0.096000, Test set accuracy = 0.097900
 epoch 5/200. Took 0.034425 seconds. 
  Full-batch training loss = 2.297364, test loss = 2.297743
  Training set accuracy = 0.105500, Test set accuracy = 0.105700
 epoch 6/200. Took 0.031168 seconds. 
  Full-batch training loss = 2.282043, test loss = 2.283878
  Training set accuracy = 0.119500, Test set accuracy = 0.119900
 epoch 7/200. Took 0.034388 seconds. 
  Full-batch training loss = 2.268820, test loss = 2.271939
  Training set accuracy = 0.134000, Test set accuracy = 0.137300
 epoch 8/200. Took 0.030889 seconds. 
  Full-batch training loss = 2.257042, test loss = 2.261317
  Training set accuracy = 0.165000, Test set accuracy = 0.166800
 epoch 9/200. Took 0.034075 seconds. 
  Full-batch training loss = 2.246238, test loss = 2.251579
  Training set accuracy = 0.219500, Test set accuracy = 0.210500
 epoch 10/200. Took 0.031218 seconds. 
  Full-batch training loss = 2.236241, test loss = 2.242492
  Training set accuracy = 0.292500, Test set accuracy = 0.272200
 epoch 11/200. Took 0.031171 seconds. 
  Full-batch training loss = 2.227014, test loss = 2.234025
  Training set accuracy = 0.345500, Test set accuracy = 0.323600
 epoch 12/200. Took 0.031363 seconds. 
  Full-batch training loss = 2.218019, test loss = 2.225794
  Training set accuracy = 0.367000, Test set accuracy = 0.355600
 epoch 13/200. Took 0.028793 seconds. 
  Full-batch training loss = 2.209418, test loss = 2.217852
  Training set accuracy = 0.393500, Test set accuracy = 0.374200
 epoch 14/200. Took 0.028628 seconds. 
  Full-batch training loss = 2.200951, test loss = 2.210047
  Training set accuracy = 0.410000, Test set accuracy = 0.386000
 epoch 15/200. Took 0.028964 seconds. 
  Full-batch training loss = 2.192899, test loss = 2.202509
  Training set accuracy = 0.418500, Test set accuracy = 0.394100
 epoch 16/200. Took 0.027774 seconds. 
  Full-batch training loss = 2.184734, test loss = 2.194900
  Training set accuracy = 0.419500, Test set accuracy = 0.396900
 epoch 17/200. Took 0.028469 seconds. 
  Full-batch training loss = 2.176854, test loss = 2.187417
  Training set accuracy = 0.426000, Test set accuracy = 0.400100
 epoch 18/200. Took 0.028242 seconds. 
  Full-batch training loss = 2.168882, test loss = 2.179934
  Training set accuracy = 0.423500, Test set accuracy = 0.400400
 epoch 19/200. Took 0.029033 seconds. 
  Full-batch training loss = 2.161107, test loss = 2.172517
  Training set accuracy = 0.438000, Test set accuracy = 0.408400
 epoch 20/200. Took 0.028403 seconds. 
  Full-batch training loss = 2.153253, test loss = 2.165123
  Training set accuracy = 0.439500, Test set accuracy = 0.410600
 epoch 21/200. Took 0.028856 seconds. 
  Full-batch training loss = 2.145503, test loss = 2.157666
  Training set accuracy = 0.445000, Test set accuracy = 0.414100
 epoch 22/200. Took 0.028722 seconds. 
  Full-batch training loss = 2.137736, test loss = 2.150257
  Training set accuracy = 0.447500, Test set accuracy = 0.418900
 epoch 23/200. Took 0.028368 seconds. 
  Full-batch training loss = 2.130005, test loss = 2.142948
  Training set accuracy = 0.449500, Test set accuracy = 0.422200
 epoch 24/200. Took 0.027535 seconds. 
  Full-batch training loss = 2.122374, test loss = 2.135540
  Training set accuracy = 0.457500, Test set accuracy = 0.428500
 epoch 25/200. Took 0.02985 seconds. 
  Full-batch training loss = 2.114622, test loss = 2.128188
  Training set accuracy = 0.459500, Test set accuracy = 0.429000
 epoch 26/200. Took 0.029293 seconds. 
  Full-batch training loss = 2.106919, test loss = 2.120755
  Training set accuracy = 0.469500, Test set accuracy = 0.437900
 epoch 27/200. Took 0.028833 seconds. 
  Full-batch training loss = 2.099235, test loss = 2.113405
  Training set accuracy = 0.473500, Test set accuracy = 0.440600
 epoch 28/200. Took 0.030722 seconds. 
  Full-batch training loss = 2.091519, test loss = 2.106026
  Training set accuracy = 0.476000, Test set accuracy = 0.444800
 epoch 29/200. Took 0.028505 seconds. 
  Full-batch training loss = 2.083835, test loss = 2.098560
  Training set accuracy = 0.481500, Test set accuracy = 0.450600
 epoch 30/200. Took 0.029148 seconds. 
  Full-batch training loss = 2.076194, test loss = 2.091169
  Training set accuracy = 0.488000, Test set accuracy = 0.456100
 epoch 31/200. Took 0.028757 seconds. 
  Full-batch training loss = 2.068469, test loss = 2.083832
  Training set accuracy = 0.490000, Test set accuracy = 0.459700
 epoch 32/200. Took 0.031141 seconds. 
  Full-batch training loss = 2.060826, test loss = 2.076415
  Training set accuracy = 0.496500, Test set accuracy = 0.466100
 epoch 33/200. Took 0.028397 seconds. 
  Full-batch training loss = 2.053118, test loss = 2.068993
  Training set accuracy = 0.501000, Test set accuracy = 0.470700
 epoch 34/200. Took 0.032383 seconds. 
  Full-batch training loss = 2.045444, test loss = 2.061604
  Training set accuracy = 0.504000, Test set accuracy = 0.474600
 epoch 35/200. Took 0.029228 seconds. 
  Full-batch training loss = 2.037766, test loss = 2.054105
  Training set accuracy = 0.511500, Test set accuracy = 0.481000
 epoch 36/200. Took 0.035625 seconds. 
  Full-batch training loss = 2.030050, test loss = 2.046692
  Training set accuracy = 0.513000, Test set accuracy = 0.484800
 epoch 37/200. Took 0.031793 seconds. 
  Full-batch training loss = 2.022335, test loss = 2.039251
  Training set accuracy = 0.517500, Test set accuracy = 0.489200
 epoch 38/200. Took 0.031404 seconds. 
  Full-batch training loss = 2.014686, test loss = 2.031672
  Training set accuracy = 0.525500, Test set accuracy = 0.499700
 epoch 39/200. Took 0.031248 seconds. 
  Full-batch training loss = 2.006941, test loss = 2.024299
  Training set accuracy = 0.526000, Test set accuracy = 0.498200
 epoch 40/200. Took 0.031748 seconds. 
  Full-batch training loss = 1.999248, test loss = 2.016847
  Training set accuracy = 0.529500, Test set accuracy = 0.503600
 epoch 41/200. Took 0.031271 seconds. 
  Full-batch training loss = 1.991499, test loss = 2.009381
  Training set accuracy = 0.535500, Test set accuracy = 0.507400
 epoch 42/200. Took 0.031082 seconds. 
  Full-batch training loss = 1.983784, test loss = 2.001949
  Training set accuracy = 0.536000, Test set accuracy = 0.510800
 epoch 43/200. Took 0.03117 seconds. 
  Full-batch training loss = 1.976082, test loss = 1.994427
  Training set accuracy = 0.541000, Test set accuracy = 0.516300
 epoch 44/200. Took 0.031062 seconds. 
  Full-batch training loss = 1.968350, test loss = 1.986948
  Training set accuracy = 0.546000, Test set accuracy = 0.522000
 epoch 45/200. Took 0.033089 seconds. 
  Full-batch training loss = 1.960639, test loss = 1.979472
  Training set accuracy = 0.553000, Test set accuracy = 0.526300
 epoch 46/200. Took 0.031878 seconds. 
  Full-batch training loss = 1.952863, test loss = 1.971993
  Training set accuracy = 0.552000, Test set accuracy = 0.525900
 epoch 47/200. Took 0.036067 seconds. 
  Full-batch training loss = 1.945160, test loss = 1.964533
  Training set accuracy = 0.557500, Test set accuracy = 0.528900
 epoch 48/200. Took 0.030495 seconds. 
  Full-batch training loss = 1.937438, test loss = 1.956928
  Training set accuracy = 0.566000, Test set accuracy = 0.537700
 epoch 49/200. Took 0.03465 seconds. 
  Full-batch training loss = 1.929696, test loss = 1.949426
  Training set accuracy = 0.573500, Test set accuracy = 0.540800
 epoch 50/200. Took 0.03052 seconds. 
  Full-batch training loss = 1.921915, test loss = 1.941973
  Training set accuracy = 0.572500, Test set accuracy = 0.543700
 epoch 51/200. Took 0.032048 seconds. 
  Full-batch training loss = 1.914163, test loss = 1.934421
  Training set accuracy = 0.576000, Test set accuracy = 0.547100
 epoch 52/200. Took 0.031219 seconds. 
  Full-batch training loss = 1.906424, test loss = 1.927070
  Training set accuracy = 0.579000, Test set accuracy = 0.548500
 epoch 53/200. Took 0.031489 seconds. 
  Full-batch training loss = 1.898715, test loss = 1.919480
  Training set accuracy = 0.582000, Test set accuracy = 0.553400
 epoch 54/200. Took 0.031258 seconds. 
  Full-batch training loss = 1.890938, test loss = 1.911909
  Training set accuracy = 0.583000, Test set accuracy = 0.555600
 epoch 55/200. Took 0.03018 seconds. 
  Full-batch training loss = 1.883193, test loss = 1.904461
  Training set accuracy = 0.586500, Test set accuracy = 0.559000
 epoch 56/200. Took 0.030831 seconds. 
  Full-batch training loss = 1.875461, test loss = 1.896898
  Training set accuracy = 0.590000, Test set accuracy = 0.561700
 epoch 57/200. Took 0.030628 seconds. 
  Full-batch training loss = 1.867694, test loss = 1.889398
  Training set accuracy = 0.594500, Test set accuracy = 0.565000
 epoch 58/200. Took 0.035143 seconds. 
  Full-batch training loss = 1.859950, test loss = 1.881794
  Training set accuracy = 0.600000, Test set accuracy = 0.571200
 epoch 59/200. Took 0.030803 seconds. 
  Full-batch training loss = 1.852209, test loss = 1.874325
  Training set accuracy = 0.602000, Test set accuracy = 0.571100
 epoch 60/200. Took 0.035295 seconds. 
  Full-batch training loss = 1.844481, test loss = 1.866814
  Training set accuracy = 0.604500, Test set accuracy = 0.574200
 epoch 61/200. Took 0.031737 seconds. 
  Full-batch training loss = 1.836730, test loss = 1.859280
  Training set accuracy = 0.610000, Test set accuracy = 0.579200
 epoch 62/200. Took 0.033213 seconds. 
  Full-batch training loss = 1.828996, test loss = 1.851879
  Training set accuracy = 0.610000, Test set accuracy = 0.579800
 epoch 63/200. Took 0.031043 seconds. 
  Full-batch training loss = 1.821333, test loss = 1.844359
  Training set accuracy = 0.615500, Test set accuracy = 0.585300
 epoch 64/200. Took 0.031769 seconds. 
  Full-batch training loss = 1.813585, test loss = 1.836837
  Training set accuracy = 0.617000, Test set accuracy = 0.586600
 epoch 65/200. Took 0.031324 seconds. 
  Full-batch training loss = 1.805878, test loss = 1.829310
  Training set accuracy = 0.623500, Test set accuracy = 0.589100
 epoch 66/200. Took 0.02889 seconds. 
  Full-batch training loss = 1.798171, test loss = 1.821836
  Training set accuracy = 0.626500, Test set accuracy = 0.590200
 epoch 67/200. Took 0.027769 seconds. 
  Full-batch training loss = 1.790456, test loss = 1.814395
  Training set accuracy = 0.624500, Test set accuracy = 0.592700
 epoch 68/200. Took 0.031351 seconds. 
  Full-batch training loss = 1.782802, test loss = 1.806953
  Training set accuracy = 0.631000, Test set accuracy = 0.598600
 epoch 69/200. Took 0.030372 seconds. 
  Full-batch training loss = 1.775158, test loss = 1.799378
  Training set accuracy = 0.635000, Test set accuracy = 0.601200
 epoch 70/200. Took 0.028096 seconds. 
  Full-batch training loss = 1.767463, test loss = 1.792062
  Training set accuracy = 0.636000, Test set accuracy = 0.601300
 epoch 71/200. Took 0.032204 seconds. 
  Full-batch training loss = 1.759781, test loss = 1.784602
  Training set accuracy = 0.639000, Test set accuracy = 0.602400
 epoch 72/200. Took 0.03021 seconds. 
  Full-batch training loss = 1.752159, test loss = 1.777189
  Training set accuracy = 0.639500, Test set accuracy = 0.604400
 epoch 73/200. Took 0.035387 seconds. 
  Full-batch training loss = 1.744490, test loss = 1.769721
  Training set accuracy = 0.641500, Test set accuracy = 0.606800
 epoch 74/200. Took 0.031209 seconds. 
  Full-batch training loss = 1.736921, test loss = 1.762370
  Training set accuracy = 0.642500, Test set accuracy = 0.609600
 epoch 75/200. Took 0.034983 seconds. 
  Full-batch training loss = 1.729318, test loss = 1.754935
  Training set accuracy = 0.646000, Test set accuracy = 0.613600
 epoch 76/200. Took 0.030832 seconds. 
  Full-batch training loss = 1.721724, test loss = 1.747482
  Training set accuracy = 0.644500, Test set accuracy = 0.614700
 epoch 77/200. Took 0.030617 seconds. 
  Full-batch training loss = 1.714184, test loss = 1.740193
  Training set accuracy = 0.647000, Test set accuracy = 0.616400
 epoch 78/200. Took 0.029064 seconds. 
  Full-batch training loss = 1.706619, test loss = 1.732864
  Training set accuracy = 0.651500, Test set accuracy = 0.619700
 epoch 79/200. Took 0.028825 seconds. 
  Full-batch training loss = 1.699092, test loss = 1.725486
  Training set accuracy = 0.654000, Test set accuracy = 0.623600
 epoch 80/200. Took 0.02867 seconds. 
  Full-batch training loss = 1.691529, test loss = 1.718200
  Training set accuracy = 0.653500, Test set accuracy = 0.622400
 epoch 81/200. Took 0.028311 seconds. 
  Full-batch training loss = 1.684071, test loss = 1.710816
  Training set accuracy = 0.660500, Test set accuracy = 0.626000
 epoch 82/200. Took 0.028485 seconds. 
  Full-batch training loss = 1.676590, test loss = 1.703545
  Training set accuracy = 0.665500, Test set accuracy = 0.627700
 epoch 83/200. Took 0.028512 seconds. 
  Full-batch training loss = 1.669142, test loss = 1.696411
  Training set accuracy = 0.665500, Test set accuracy = 0.628400
 epoch 84/200. Took 0.031697 seconds. 
  Full-batch training loss = 1.661689, test loss = 1.689129
  Training set accuracy = 0.668500, Test set accuracy = 0.633600
 epoch 85/200. Took 0.033064 seconds. 
  Full-batch training loss = 1.654274, test loss = 1.681846
  Training set accuracy = 0.669500, Test set accuracy = 0.636000
 epoch 86/200. Took 0.033519 seconds. 
  Full-batch training loss = 1.646888, test loss = 1.674651
  Training set accuracy = 0.671000, Test set accuracy = 0.636300
 epoch 87/200. Took 0.032004 seconds. 
  Full-batch training loss = 1.639515, test loss = 1.667553
  Training set accuracy = 0.671000, Test set accuracy = 0.637200
 epoch 88/200. Took 0.03548 seconds. 
  Full-batch training loss = 1.632180, test loss = 1.660418
  Training set accuracy = 0.672500, Test set accuracy = 0.638600
 epoch 89/200. Took 0.032796 seconds. 
  Full-batch training loss = 1.624871, test loss = 1.653253
  Training set accuracy = 0.676000, Test set accuracy = 0.641600
 epoch 90/200. Took 0.033445 seconds. 
  Full-batch training loss = 1.617575, test loss = 1.646040
  Training set accuracy = 0.679500, Test set accuracy = 0.645100
 epoch 91/200. Took 0.031478 seconds. 
  Full-batch training loss = 1.610302, test loss = 1.638955
  Training set accuracy = 0.680500, Test set accuracy = 0.645700
 epoch 92/200. Took 0.037686 seconds. 
  Full-batch training loss = 1.603037, test loss = 1.631884
  Training set accuracy = 0.683000, Test set accuracy = 0.648700
 epoch 93/200. Took 0.030816 seconds. 
  Full-batch training loss = 1.595833, test loss = 1.624824
  Training set accuracy = 0.683500, Test set accuracy = 0.649900
 epoch 94/200. Took 0.028846 seconds. 
  Full-batch training loss = 1.588657, test loss = 1.617895
  Training set accuracy = 0.685500, Test set accuracy = 0.652400
 epoch 95/200. Took 0.029698 seconds. 
  Full-batch training loss = 1.581515, test loss = 1.610894
  Training set accuracy = 0.686000, Test set accuracy = 0.653500
 epoch 96/200. Took 0.030116 seconds. 
  Full-batch training loss = 1.574352, test loss = 1.603890
  Training set accuracy = 0.686000, Test set accuracy = 0.654800
 epoch 97/200. Took 0.032712 seconds. 
  Full-batch training loss = 1.567266, test loss = 1.597072
  Training set accuracy = 0.689500, Test set accuracy = 0.657400
 epoch 98/200. Took 0.032294 seconds. 
  Full-batch training loss = 1.560199, test loss = 1.590200
  Training set accuracy = 0.690500, Test set accuracy = 0.658100
 epoch 99/200. Took 0.035765 seconds. 
  Full-batch training loss = 1.553132, test loss = 1.583240
  Training set accuracy = 0.692000, Test set accuracy = 0.661400
 epoch 100/200. Took 0.028968 seconds. 
  Full-batch training loss = 1.546133, test loss = 1.576383
  Training set accuracy = 0.693500, Test set accuracy = 0.663500
 epoch 101/200. Took 0.034503 seconds. 
  Full-batch training loss = 1.539156, test loss = 1.569565
  Training set accuracy = 0.694500, Test set accuracy = 0.667500
 epoch 102/200. Took 0.02838 seconds. 
  Full-batch training loss = 1.532177, test loss = 1.562758
  Training set accuracy = 0.696000, Test set accuracy = 0.668400
 epoch 103/200. Took 0.036619 seconds. 
  Full-batch training loss = 1.525279, test loss = 1.555939
  Training set accuracy = 0.699000, Test set accuracy = 0.669600
 epoch 104/200. Took 0.028504 seconds. 
  Full-batch training loss = 1.518398, test loss = 1.549312
  Training set accuracy = 0.701000, Test set accuracy = 0.672100
 epoch 105/200. Took 0.031293 seconds. 
  Full-batch training loss = 1.511530, test loss = 1.542580
  Training set accuracy = 0.703000, Test set accuracy = 0.674800
 epoch 106/200. Took 0.033077 seconds. 
  Full-batch training loss = 1.504709, test loss = 1.535883
  Training set accuracy = 0.704000, Test set accuracy = 0.674700
 epoch 107/200. Took 0.033154 seconds. 
  Full-batch training loss = 1.497912, test loss = 1.529249
  Training set accuracy = 0.706000, Test set accuracy = 0.676600
 epoch 108/200. Took 0.033694 seconds. 
  Full-batch training loss = 1.491163, test loss = 1.522609
  Training set accuracy = 0.708500, Test set accuracy = 0.678700
 epoch 109/200. Took 0.031024 seconds. 
  Full-batch training loss = 1.484439, test loss = 1.516122
  Training set accuracy = 0.709500, Test set accuracy = 0.678900
 epoch 110/200. Took 0.037224 seconds. 
  Full-batch training loss = 1.477744, test loss = 1.509562
  Training set accuracy = 0.711000, Test set accuracy = 0.682300
 epoch 111/200. Took 0.03302 seconds. 
  Full-batch training loss = 1.471084, test loss = 1.503124
  Training set accuracy = 0.710500, Test set accuracy = 0.682200
 epoch 112/200. Took 0.030071 seconds. 
  Full-batch training loss = 1.464450, test loss = 1.496561
  Training set accuracy = 0.713500, Test set accuracy = 0.684600
 epoch 113/200. Took 0.02997 seconds. 
  Full-batch training loss = 1.457914, test loss = 1.490106
  Training set accuracy = 0.715000, Test set accuracy = 0.684600
 epoch 114/200. Took 0.028329 seconds. 
  Full-batch training loss = 1.451352, test loss = 1.483772
  Training set accuracy = 0.718500, Test set accuracy = 0.686400
 epoch 115/200. Took 0.029294 seconds. 
  Full-batch training loss = 1.444833, test loss = 1.477408
  Training set accuracy = 0.718500, Test set accuracy = 0.687900
 epoch 116/200. Took 0.028545 seconds. 
  Full-batch training loss = 1.438350, test loss = 1.471098
  Training set accuracy = 0.719500, Test set accuracy = 0.688600
 epoch 117/200. Took 0.031454 seconds. 
  Full-batch training loss = 1.431917, test loss = 1.464773
  Training set accuracy = 0.719500, Test set accuracy = 0.689800
 epoch 118/200. Took 0.027479 seconds. 
  Full-batch training loss = 1.425502, test loss = 1.458525
  Training set accuracy = 0.722000, Test set accuracy = 0.690200
 epoch 119/200. Took 0.028707 seconds. 
  Full-batch training loss = 1.419141, test loss = 1.452244
  Training set accuracy = 0.725000, Test set accuracy = 0.693500
 epoch 120/200. Took 0.036079 seconds. 
  Full-batch training loss = 1.412805, test loss = 1.446113
  Training set accuracy = 0.724500, Test set accuracy = 0.694400
 epoch 121/200. Took 0.032171 seconds. 
  Full-batch training loss = 1.406517, test loss = 1.439872
  Training set accuracy = 0.726000, Test set accuracy = 0.696000
 epoch 122/200. Took 0.03124 seconds. 
  Full-batch training loss = 1.400263, test loss = 1.433736
  Training set accuracy = 0.730000, Test set accuracy = 0.696500
 epoch 123/200. Took 0.036212 seconds. 
  Full-batch training loss = 1.394033, test loss = 1.427671
  Training set accuracy = 0.731500, Test set accuracy = 0.697100
 epoch 124/200. Took 0.031845 seconds. 
  Full-batch training loss = 1.387843, test loss = 1.421639
  Training set accuracy = 0.732000, Test set accuracy = 0.698700
 epoch 125/200. Took 0.032572 seconds. 
  Full-batch training loss = 1.381680, test loss = 1.415654
  Training set accuracy = 0.731000, Test set accuracy = 0.699600
 epoch 126/200. Took 0.031696 seconds. 
  Full-batch training loss = 1.375594, test loss = 1.409654
  Training set accuracy = 0.734500, Test set accuracy = 0.700400
 epoch 127/200. Took 0.034996 seconds. 
  Full-batch training loss = 1.369488, test loss = 1.403642
  Training set accuracy = 0.736500, Test set accuracy = 0.702200
 epoch 128/200. Took 0.030956 seconds. 
  Full-batch training loss = 1.363476, test loss = 1.397786
  Training set accuracy = 0.736000, Test set accuracy = 0.703200
 epoch 129/200. Took 0.031783 seconds. 
  Full-batch training loss = 1.357463, test loss = 1.391868
  Training set accuracy = 0.738500, Test set accuracy = 0.704900
 epoch 130/200. Took 0.035006 seconds. 
  Full-batch training loss = 1.351507, test loss = 1.386032
  Training set accuracy = 0.739500, Test set accuracy = 0.706200
 epoch 131/200. Took 0.033321 seconds. 
  Full-batch training loss = 1.345592, test loss = 1.380273
  Training set accuracy = 0.740000, Test set accuracy = 0.707600
 epoch 132/200. Took 0.031535 seconds. 
  Full-batch training loss = 1.339690, test loss = 1.374508
  Training set accuracy = 0.742000, Test set accuracy = 0.708300
 epoch 133/200. Took 0.027958 seconds. 
  Full-batch training loss = 1.333857, test loss = 1.368788
  Training set accuracy = 0.743000, Test set accuracy = 0.710100
 epoch 134/200. Took 0.033894 seconds. 
  Full-batch training loss = 1.328024, test loss = 1.363044
  Training set accuracy = 0.745000, Test set accuracy = 0.712300
 epoch 135/200. Took 0.030832 seconds. 
  Full-batch training loss = 1.322268, test loss = 1.357485
  Training set accuracy = 0.745500, Test set accuracy = 0.711900
 epoch 136/200. Took 0.032381 seconds. 
  Full-batch training loss = 1.316518, test loss = 1.351846
  Training set accuracy = 0.747000, Test set accuracy = 0.714100
 epoch 137/200. Took 0.030873 seconds. 
  Full-batch training loss = 1.310842, test loss = 1.346248
  Training set accuracy = 0.747000, Test set accuracy = 0.714100
 epoch 138/200. Took 0.031458 seconds. 
  Full-batch training loss = 1.305164, test loss = 1.340676
  Training set accuracy = 0.748500, Test set accuracy = 0.715300
 epoch 139/200. Took 0.032124 seconds. 
  Full-batch training loss = 1.299551, test loss = 1.335199
  Training set accuracy = 0.750000, Test set accuracy = 0.716900
 epoch 140/200. Took 0.02843 seconds. 
  Full-batch training loss = 1.293953, test loss = 1.329617
  Training set accuracy = 0.750500, Test set accuracy = 0.718200
 epoch 141/200. Took 0.037414 seconds. 
  Full-batch training loss = 1.288399, test loss = 1.324245
  Training set accuracy = 0.750500, Test set accuracy = 0.718900
 epoch 142/200. Took 0.031209 seconds. 
  Full-batch training loss = 1.282913, test loss = 1.318897
  Training set accuracy = 0.752000, Test set accuracy = 0.719500
 epoch 143/200. Took 0.033138 seconds. 
  Full-batch training loss = 1.277407, test loss = 1.313501
  Training set accuracy = 0.753000, Test set accuracy = 0.721300
 epoch 144/200. Took 0.033224 seconds. 
  Full-batch training loss = 1.271990, test loss = 1.308150
  Training set accuracy = 0.754000, Test set accuracy = 0.722300
 epoch 145/200. Took 0.033637 seconds. 
  Full-batch training loss = 1.266580, test loss = 1.302855
  Training set accuracy = 0.753500, Test set accuracy = 0.723600
 epoch 146/200. Took 0.03285 seconds. 
  Full-batch training loss = 1.261220, test loss = 1.297621
  Training set accuracy = 0.756500, Test set accuracy = 0.724400
 epoch 147/200. Took 0.03352 seconds. 
  Full-batch training loss = 1.255906, test loss = 1.292439
  Training set accuracy = 0.756500, Test set accuracy = 0.725200
 epoch 148/200. Took 0.036612 seconds. 
  Full-batch training loss = 1.250618, test loss = 1.287265
  Training set accuracy = 0.757500, Test set accuracy = 0.727000
 epoch 149/200. Took 0.031938 seconds. 
  Full-batch training loss = 1.245376, test loss = 1.282166
  Training set accuracy = 0.758500, Test set accuracy = 0.727800
 epoch 150/200. Took 0.03013 seconds. 
  Full-batch training loss = 1.240172, test loss = 1.277056
  Training set accuracy = 0.760500, Test set accuracy = 0.729700
 epoch 151/200. Took 0.029883 seconds. 
  Full-batch training loss = 1.234985, test loss = 1.271941
  Training set accuracy = 0.760000, Test set accuracy = 0.730100
 epoch 152/200. Took 0.034649 seconds. 
  Full-batch training loss = 1.229851, test loss = 1.266886
  Training set accuracy = 0.760000, Test set accuracy = 0.731400
 epoch 153/200. Took 0.032305 seconds. 
  Full-batch training loss = 1.224744, test loss = 1.261899
  Training set accuracy = 0.761500, Test set accuracy = 0.732800
 epoch 154/200. Took 0.032752 seconds. 
  Full-batch training loss = 1.219672, test loss = 1.256958
  Training set accuracy = 0.764000, Test set accuracy = 0.733900
 epoch 155/200. Took 0.029449 seconds. 
  Full-batch training loss = 1.214645, test loss = 1.251942
  Training set accuracy = 0.764500, Test set accuracy = 0.736100
 epoch 156/200. Took 0.029353 seconds. 
  Full-batch training loss = 1.209656, test loss = 1.247061
  Training set accuracy = 0.767000, Test set accuracy = 0.737400
 epoch 157/200. Took 0.028698 seconds. 
  Full-batch training loss = 1.204690, test loss = 1.242280
  Training set accuracy = 0.768500, Test set accuracy = 0.737800
 epoch 158/200. Took 0.03222 seconds. 
  Full-batch training loss = 1.199750, test loss = 1.237369
  Training set accuracy = 0.769500, Test set accuracy = 0.739600
 epoch 159/200. Took 0.03275 seconds. 
  Full-batch training loss = 1.194868, test loss = 1.232605
  Training set accuracy = 0.770000, Test set accuracy = 0.740600
 epoch 160/200. Took 0.031486 seconds. 
  Full-batch training loss = 1.190022, test loss = 1.227866
  Training set accuracy = 0.771000, Test set accuracy = 0.741100
 epoch 161/200. Took 0.034655 seconds. 
  Full-batch training loss = 1.185209, test loss = 1.223153
  Training set accuracy = 0.772000, Test set accuracy = 0.741600
 epoch 162/200. Took 0.032316 seconds. 
  Full-batch training loss = 1.180400, test loss = 1.218428
  Training set accuracy = 0.772000, Test set accuracy = 0.742700
 epoch 163/200. Took 0.034074 seconds. 
  Full-batch training loss = 1.175681, test loss = 1.213891
  Training set accuracy = 0.773000, Test set accuracy = 0.743400
 epoch 164/200. Took 0.032071 seconds. 
  Full-batch training loss = 1.170939, test loss = 1.209199
  Training set accuracy = 0.773500, Test set accuracy = 0.745200
 epoch 165/200. Took 0.032474 seconds. 
  Full-batch training loss = 1.166271, test loss = 1.204591
  Training set accuracy = 0.774500, Test set accuracy = 0.746600
 epoch 166/200. Took 0.028742 seconds. 
  Full-batch training loss = 1.161623, test loss = 1.200014
  Training set accuracy = 0.774500, Test set accuracy = 0.747000
 epoch 167/200. Took 0.032468 seconds. 
  Full-batch training loss = 1.157007, test loss = 1.195502
  Training set accuracy = 0.774500, Test set accuracy = 0.747800
 epoch 168/200. Took 0.031767 seconds. 
  Full-batch training loss = 1.152450, test loss = 1.191133
  Training set accuracy = 0.775000, Test set accuracy = 0.748300
 epoch 169/200. Took 0.032085 seconds. 
  Full-batch training loss = 1.147895, test loss = 1.186601
  Training set accuracy = 0.775000, Test set accuracy = 0.749300
 epoch 170/200. Took 0.036256 seconds. 
  Full-batch training loss = 1.143376, test loss = 1.182197
  Training set accuracy = 0.777000, Test set accuracy = 0.750800
 epoch 171/200. Took 0.031369 seconds. 
  Full-batch training loss = 1.138889, test loss = 1.177767
  Training set accuracy = 0.776500, Test set accuracy = 0.751500
 epoch 172/200. Took 0.03414 seconds. 
  Full-batch training loss = 1.134478, test loss = 1.173479
  Training set accuracy = 0.779000, Test set accuracy = 0.753300
 epoch 173/200. Took 0.032476 seconds. 
  Full-batch training loss = 1.130042, test loss = 1.169091
  Training set accuracy = 0.779500, Test set accuracy = 0.754500
 epoch 174/200. Took 0.032755 seconds. 
  Full-batch training loss = 1.125679, test loss = 1.164879
  Training set accuracy = 0.782500, Test set accuracy = 0.755200
 epoch 175/200. Took 0.031207 seconds. 
  Full-batch training loss = 1.121333, test loss = 1.160609
  Training set accuracy = 0.783000, Test set accuracy = 0.755700
 epoch 176/200. Took 0.032042 seconds. 
  Full-batch training loss = 1.117018, test loss = 1.156386
  Training set accuracy = 0.785500, Test set accuracy = 0.756400
 epoch 177/200. Took 0.032022 seconds. 
  Full-batch training loss = 1.112737, test loss = 1.152185
  Training set accuracy = 0.786000, Test set accuracy = 0.757300
 epoch 178/200. Took 0.031649 seconds. 
  Full-batch training loss = 1.108487, test loss = 1.147976
  Training set accuracy = 0.787500, Test set accuracy = 0.757600
 epoch 179/200. Took 0.035998 seconds. 
  Full-batch training loss = 1.104290, test loss = 1.143882
  Training set accuracy = 0.787000, Test set accuracy = 0.758600
 epoch 180/200. Took 0.031668 seconds. 
  Full-batch training loss = 1.100093, test loss = 1.139782
  Training set accuracy = 0.788500, Test set accuracy = 0.759000
 epoch 181/200. Took 0.031917 seconds. 
  Full-batch training loss = 1.095921, test loss = 1.135719
  Training set accuracy = 0.788000, Test set accuracy = 0.758900
 epoch 182/200. Took 0.031325 seconds. 
  Full-batch training loss = 1.091797, test loss = 1.131679
  Training set accuracy = 0.790000, Test set accuracy = 0.759700
 epoch 183/200. Took 0.029058 seconds. 
  Full-batch training loss = 1.087715, test loss = 1.127640
  Training set accuracy = 0.790500, Test set accuracy = 0.760900
 epoch 184/200. Took 0.029185 seconds. 
  Full-batch training loss = 1.083659, test loss = 1.123699
  Training set accuracy = 0.791000, Test set accuracy = 0.761300
 epoch 185/200. Took 0.029604 seconds. 
  Full-batch training loss = 1.079625, test loss = 1.119797
  Training set accuracy = 0.792000, Test set accuracy = 0.761300
 epoch 186/200. Took 0.031363 seconds. 
  Full-batch training loss = 1.075620, test loss = 1.115829
  Training set accuracy = 0.793500, Test set accuracy = 0.763000
 epoch 187/200. Took 0.031129 seconds. 
  Full-batch training loss = 1.071652, test loss = 1.111938
  Training set accuracy = 0.794000, Test set accuracy = 0.763300
 epoch 188/200. Took 0.034924 seconds. 
  Full-batch training loss = 1.067690, test loss = 1.108062
  Training set accuracy = 0.794000, Test set accuracy = 0.764700
 epoch 189/200. Took 0.035606 seconds. 
  Full-batch training loss = 1.063767, test loss = 1.104265
  Training set accuracy = 0.794000, Test set accuracy = 0.765100
 epoch 190/200. Took 0.03308 seconds. 
  Full-batch training loss = 1.059890, test loss = 1.100444
  Training set accuracy = 0.794000, Test set accuracy = 0.766100
 epoch 191/200. Took 0.03129 seconds. 
  Full-batch training loss = 1.056049, test loss = 1.096649
  Training set accuracy = 0.795000, Test set accuracy = 0.767200
 epoch 192/200. Took 0.031192 seconds. 
  Full-batch training loss = 1.052196, test loss = 1.092868
  Training set accuracy = 0.795500, Test set accuracy = 0.768600
 epoch 193/200. Took 0.033386 seconds. 
  Full-batch training loss = 1.048423, test loss = 1.089239
  Training set accuracy = 0.796000, Test set accuracy = 0.768800
 epoch 194/200. Took 0.029433 seconds. 
  Full-batch training loss = 1.044641, test loss = 1.085489
  Training set accuracy = 0.796500, Test set accuracy = 0.770400
 epoch 195/200. Took 0.028803 seconds. 
  Full-batch training loss = 1.040900, test loss = 1.081847
  Training set accuracy = 0.796000, Test set accuracy = 0.771000
 epoch 196/200. Took 0.034968 seconds. 
  Full-batch training loss = 1.037199, test loss = 1.078219
  Training set accuracy = 0.797000, Test set accuracy = 0.771400
 epoch 197/200. Took 0.038545 seconds. 
  Full-batch training loss = 1.033506, test loss = 1.074614
  Training set accuracy = 0.798500, Test set accuracy = 0.771700
 epoch 198/200. Took 0.031834 seconds. 
  Full-batch training loss = 1.029827, test loss = 1.071064
  Training set accuracy = 0.799000, Test set accuracy = 0.772700
 epoch 199/200. Took 0.032488 seconds. 
  Full-batch training loss = 1.026203, test loss = 1.067457
  Training set accuracy = 0.800500, Test set accuracy = 0.773700
 epoch 200/200. Took 0.031869 seconds. 
  Full-batch training loss = 1.022608, test loss = 1.063976
  Training set accuracy = 0.801000, Test set accuracy = 0.774200
Elapsed time is 28.435730 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (200)
Training NN  (784  200   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.071723 seconds. 
  Full-batch training loss = 1.694918, test loss = 1.693944
  Training set accuracy = 0.605000, Test set accuracy = 0.602300
 epoch 2/200. Took 0.070096 seconds. 
  Full-batch training loss = 1.020165, test loss = 1.028312
  Training set accuracy = 0.719000, Test set accuracy = 0.718300
 epoch 3/200. Took 0.070196 seconds. 
  Full-batch training loss = 0.700496, test loss = 0.721370
  Training set accuracy = 0.819000, Test set accuracy = 0.812400
 epoch 4/200. Took 0.063774 seconds. 
  Full-batch training loss = 0.567026, test loss = 0.592082
  Training set accuracy = 0.855500, Test set accuracy = 0.845000
 epoch 5/200. Took 0.064888 seconds. 
  Full-batch training loss = 0.482258, test loss = 0.521166
  Training set accuracy = 0.883000, Test set accuracy = 0.861100
 epoch 6/200. Took 0.067203 seconds. 
  Full-batch training loss = 0.451229, test loss = 0.506050
  Training set accuracy = 0.874000, Test set accuracy = 0.848700
 epoch 7/200. Took 0.057836 seconds. 
  Full-batch training loss = 0.382439, test loss = 0.445316
  Training set accuracy = 0.898500, Test set accuracy = 0.878000
 epoch 8/200. Took 0.058372 seconds. 
  Full-batch training loss = 0.355404, test loss = 0.422936
  Training set accuracy = 0.907000, Test set accuracy = 0.883900
 epoch 9/200. Took 0.057622 seconds. 
  Full-batch training loss = 0.337921, test loss = 0.419011
  Training set accuracy = 0.909000, Test set accuracy = 0.879900
 epoch 10/200. Took 0.057744 seconds. 
  Full-batch training loss = 0.309314, test loss = 0.394392
  Training set accuracy = 0.914500, Test set accuracy = 0.889500
 epoch 11/200. Took 0.064025 seconds. 
  Full-batch training loss = 0.296196, test loss = 0.394452
  Training set accuracy = 0.920000, Test set accuracy = 0.884400
 epoch 12/200. Took 0.058592 seconds. 
  Full-batch training loss = 0.276234, test loss = 0.378005
  Training set accuracy = 0.923500, Test set accuracy = 0.888900
 epoch 13/200. Took 0.066597 seconds. 
  Full-batch training loss = 0.264067, test loss = 0.372116
  Training set accuracy = 0.927500, Test set accuracy = 0.892200
 epoch 14/200. Took 0.067059 seconds. 
  Full-batch training loss = 0.251032, test loss = 0.368625
  Training set accuracy = 0.933500, Test set accuracy = 0.890500
 epoch 15/200. Took 0.058247 seconds. 
  Full-batch training loss = 0.239456, test loss = 0.362390
  Training set accuracy = 0.937000, Test set accuracy = 0.895200
 epoch 16/200. Took 0.058223 seconds. 
  Full-batch training loss = 0.230279, test loss = 0.359632
  Training set accuracy = 0.941500, Test set accuracy = 0.893800
 epoch 17/200. Took 0.070865 seconds. 
  Full-batch training loss = 0.223571, test loss = 0.360505
  Training set accuracy = 0.940500, Test set accuracy = 0.890800
 epoch 18/200. Took 0.062709 seconds. 
  Full-batch training loss = 0.216953, test loss = 0.356092
  Training set accuracy = 0.940500, Test set accuracy = 0.894900
 epoch 19/200. Took 0.061985 seconds. 
  Full-batch training loss = 0.202665, test loss = 0.350459
  Training set accuracy = 0.949000, Test set accuracy = 0.897200
 epoch 20/200. Took 0.061599 seconds. 
  Full-batch training loss = 0.208855, test loss = 0.365726
  Training set accuracy = 0.941500, Test set accuracy = 0.892300
 epoch 21/200. Took 0.068813 seconds. 
  Full-batch training loss = 0.189290, test loss = 0.350377
  Training set accuracy = 0.948000, Test set accuracy = 0.895200
 epoch 22/200. Took 0.065048 seconds. 
  Full-batch training loss = 0.183362, test loss = 0.347132
  Training set accuracy = 0.955000, Test set accuracy = 0.897300
 epoch 23/200. Took 0.068348 seconds. 
  Full-batch training loss = 0.181235, test loss = 0.350644
  Training set accuracy = 0.953500, Test set accuracy = 0.896400
 epoch 24/200. Took 0.061123 seconds. 
  Full-batch training loss = 0.168196, test loss = 0.342652
  Training set accuracy = 0.962000, Test set accuracy = 0.900100
 epoch 25/200. Took 0.056285 seconds. 
  Full-batch training loss = 0.167799, test loss = 0.350286
  Training set accuracy = 0.959000, Test set accuracy = 0.894300
 epoch 26/200. Took 0.058591 seconds. 
  Full-batch training loss = 0.158708, test loss = 0.345082
  Training set accuracy = 0.965000, Test set accuracy = 0.896700
 epoch 27/200. Took 0.057499 seconds. 
  Full-batch training loss = 0.154045, test loss = 0.347131
  Training set accuracy = 0.963000, Test set accuracy = 0.896500
 epoch 28/200. Took 0.058033 seconds. 
  Full-batch training loss = 0.153055, test loss = 0.352227
  Training set accuracy = 0.965500, Test set accuracy = 0.893300
 epoch 29/200. Took 0.057765 seconds. 
  Full-batch training loss = 0.146250, test loss = 0.344368
  Training set accuracy = 0.966500, Test set accuracy = 0.897600
 epoch 30/200. Took 0.058908 seconds. 
  Full-batch training loss = 0.147554, test loss = 0.353808
  Training set accuracy = 0.964500, Test set accuracy = 0.893200
 epoch 31/200. Took 0.057846 seconds. 
  Full-batch training loss = 0.134296, test loss = 0.344631
  Training set accuracy = 0.974000, Test set accuracy = 0.897600
 epoch 32/200. Took 0.059257 seconds. 
  Full-batch training loss = 0.130021, test loss = 0.345876
  Training set accuracy = 0.976000, Test set accuracy = 0.897400
 epoch 33/200. Took 0.068585 seconds. 
  Full-batch training loss = 0.130427, test loss = 0.350552
  Training set accuracy = 0.973000, Test set accuracy = 0.896100
 epoch 34/200. Took 0.058602 seconds. 
  Full-batch training loss = 0.122503, test loss = 0.347061
  Training set accuracy = 0.977000, Test set accuracy = 0.897000
 epoch 35/200. Took 0.058225 seconds. 
  Full-batch training loss = 0.121851, test loss = 0.353226
  Training set accuracy = 0.975000, Test set accuracy = 0.894000
 epoch 36/200. Took 0.063129 seconds. 
  Full-batch training loss = 0.118294, test loss = 0.350954
  Training set accuracy = 0.978000, Test set accuracy = 0.895900
 epoch 37/200. Took 0.057754 seconds. 
  Full-batch training loss = 0.110114, test loss = 0.345621
  Training set accuracy = 0.981000, Test set accuracy = 0.897900
 epoch 38/200. Took 0.062347 seconds. 
  Full-batch training loss = 0.108569, test loss = 0.348727
  Training set accuracy = 0.983500, Test set accuracy = 0.899100
 epoch 39/200. Took 0.061194 seconds. 
  Full-batch training loss = 0.103414, test loss = 0.346944
  Training set accuracy = 0.986000, Test set accuracy = 0.897800
 epoch 40/200. Took 0.069578 seconds. 
  Full-batch training loss = 0.105125, test loss = 0.354698
  Training set accuracy = 0.983000, Test set accuracy = 0.894600
 epoch 41/200. Took 0.065853 seconds. 
  Full-batch training loss = 0.104611, test loss = 0.358417
  Training set accuracy = 0.980500, Test set accuracy = 0.896800
 epoch 42/200. Took 0.067784 seconds. 
  Full-batch training loss = 0.096675, test loss = 0.349997
  Training set accuracy = 0.985500, Test set accuracy = 0.898900
 epoch 43/200. Took 0.058686 seconds. 
  Full-batch training loss = 0.094560, test loss = 0.354948
  Training set accuracy = 0.986500, Test set accuracy = 0.897400
 epoch 44/200. Took 0.056813 seconds. 
  Full-batch training loss = 0.090842, test loss = 0.350554
  Training set accuracy = 0.987500, Test set accuracy = 0.897000
 epoch 45/200. Took 0.057989 seconds. 
  Full-batch training loss = 0.088854, test loss = 0.352311
  Training set accuracy = 0.988500, Test set accuracy = 0.898600
 epoch 46/200. Took 0.057841 seconds. 
  Full-batch training loss = 0.090443, test loss = 0.362911
  Training set accuracy = 0.987000, Test set accuracy = 0.893100
 epoch 47/200. Took 0.065872 seconds. 
  Full-batch training loss = 0.085093, test loss = 0.356071
  Training set accuracy = 0.987500, Test set accuracy = 0.898000
 epoch 48/200. Took 0.064721 seconds. 
  Full-batch training loss = 0.081567, test loss = 0.354840
  Training set accuracy = 0.990000, Test set accuracy = 0.897000
 epoch 49/200. Took 0.058665 seconds. 
  Full-batch training loss = 0.083111, test loss = 0.357495
  Training set accuracy = 0.988500, Test set accuracy = 0.897400
 epoch 50/200. Took 0.058164 seconds. 
  Full-batch training loss = 0.075822, test loss = 0.354164
  Training set accuracy = 0.992500, Test set accuracy = 0.898400
 epoch 51/200. Took 0.064252 seconds. 
  Full-batch training loss = 0.072925, test loss = 0.355947
  Training set accuracy = 0.992500, Test set accuracy = 0.898200
 epoch 52/200. Took 0.061358 seconds. 
  Full-batch training loss = 0.071990, test loss = 0.354770
  Training set accuracy = 0.991000, Test set accuracy = 0.899700
 epoch 53/200. Took 0.056441 seconds. 
  Full-batch training loss = 0.069306, test loss = 0.355282
  Training set accuracy = 0.991500, Test set accuracy = 0.900000
 epoch 54/200. Took 0.068854 seconds. 
  Full-batch training loss = 0.069939, test loss = 0.360162
  Training set accuracy = 0.991500, Test set accuracy = 0.896100
 epoch 55/200. Took 0.070773 seconds. 
  Full-batch training loss = 0.065301, test loss = 0.357031
  Training set accuracy = 0.993000, Test set accuracy = 0.901200
 epoch 56/200. Took 0.068027 seconds. 
  Full-batch training loss = 0.063157, test loss = 0.359063
  Training set accuracy = 0.993500, Test set accuracy = 0.898600
 epoch 57/200. Took 0.068275 seconds. 
  Full-batch training loss = 0.061725, test loss = 0.360306
  Training set accuracy = 0.994500, Test set accuracy = 0.898400
 epoch 58/200. Took 0.063286 seconds. 
  Full-batch training loss = 0.060971, test loss = 0.362205
  Training set accuracy = 0.994000, Test set accuracy = 0.898200
 epoch 59/200. Took 0.058887 seconds. 
  Full-batch training loss = 0.058837, test loss = 0.360923
  Training set accuracy = 0.995000, Test set accuracy = 0.898900
 epoch 60/200. Took 0.069612 seconds. 
  Full-batch training loss = 0.057443, test loss = 0.363383
  Training set accuracy = 0.994500, Test set accuracy = 0.898300
 epoch 61/200. Took 0.07812 seconds. 
  Full-batch training loss = 0.055328, test loss = 0.362005
  Training set accuracy = 0.995500, Test set accuracy = 0.898600
 epoch 62/200. Took 0.081462 seconds. 
  Full-batch training loss = 0.054305, test loss = 0.362289
  Training set accuracy = 0.996000, Test set accuracy = 0.898500
 epoch 63/200. Took 0.058657 seconds. 
  Full-batch training loss = 0.052495, test loss = 0.363442
  Training set accuracy = 0.997500, Test set accuracy = 0.899800
 epoch 64/200. Took 0.060004 seconds. 
  Full-batch training loss = 0.054202, test loss = 0.369301
  Training set accuracy = 0.996000, Test set accuracy = 0.898500
 epoch 65/200. Took 0.061734 seconds. 
  Full-batch training loss = 0.049972, test loss = 0.366696
  Training set accuracy = 0.997000, Test set accuracy = 0.898400
 epoch 66/200. Took 0.061056 seconds. 
  Full-batch training loss = 0.049262, test loss = 0.367340
  Training set accuracy = 0.997000, Test set accuracy = 0.899700
 epoch 67/200. Took 0.069425 seconds. 
  Full-batch training loss = 0.047196, test loss = 0.366256
  Training set accuracy = 0.998000, Test set accuracy = 0.900600
 epoch 68/200. Took 0.067205 seconds. 
  Full-batch training loss = 0.047206, test loss = 0.370085
  Training set accuracy = 0.998000, Test set accuracy = 0.899100
 epoch 69/200. Took 0.078715 seconds. 
  Full-batch training loss = 0.045404, test loss = 0.368006
  Training set accuracy = 0.998000, Test set accuracy = 0.900600
 epoch 70/200. Took 0.062033 seconds. 
  Full-batch training loss = 0.043866, test loss = 0.369803
  Training set accuracy = 0.997500, Test set accuracy = 0.898600
 epoch 71/200. Took 0.069544 seconds. 
  Full-batch training loss = 0.042781, test loss = 0.368671
  Training set accuracy = 0.998500, Test set accuracy = 0.898700
 epoch 72/200. Took 0.059975 seconds. 
  Full-batch training loss = 0.042003, test loss = 0.370771
  Training set accuracy = 0.998000, Test set accuracy = 0.899300
 epoch 73/200. Took 0.059046 seconds. 
  Full-batch training loss = 0.043322, test loss = 0.375122
  Training set accuracy = 0.997500, Test set accuracy = 0.898400
 epoch 74/200. Took 0.066876 seconds. 
  Full-batch training loss = 0.041541, test loss = 0.375516
  Training set accuracy = 0.998000, Test set accuracy = 0.898800
 epoch 75/200. Took 0.067638 seconds. 
  Full-batch training loss = 0.039372, test loss = 0.373095
  Training set accuracy = 0.998500, Test set accuracy = 0.899300
 epoch 76/200. Took 0.068717 seconds. 
  Full-batch training loss = 0.038944, test loss = 0.375581
  Training set accuracy = 0.998000, Test set accuracy = 0.898300
 epoch 77/200. Took 0.072333 seconds. 
  Full-batch training loss = 0.037426, test loss = 0.374575
  Training set accuracy = 0.998500, Test set accuracy = 0.898500
 epoch 78/200. Took 0.073505 seconds. 
  Full-batch training loss = 0.036151, test loss = 0.375889
  Training set accuracy = 0.999000, Test set accuracy = 0.899900
 epoch 79/200. Took 0.074612 seconds. 
  Full-batch training loss = 0.035304, test loss = 0.375990
  Training set accuracy = 0.999000, Test set accuracy = 0.899900
 epoch 80/200. Took 0.072715 seconds. 
  Full-batch training loss = 0.036133, test loss = 0.378497
  Training set accuracy = 0.999500, Test set accuracy = 0.900300
 epoch 81/200. Took 0.059397 seconds. 
  Full-batch training loss = 0.033989, test loss = 0.378423
  Training set accuracy = 0.999000, Test set accuracy = 0.899700
 epoch 82/200. Took 0.060673 seconds. 
  Full-batch training loss = 0.033372, test loss = 0.378919
  Training set accuracy = 0.999000, Test set accuracy = 0.900300
 epoch 83/200. Took 0.068464 seconds. 
  Full-batch training loss = 0.033434, test loss = 0.379850
  Training set accuracy = 0.998000, Test set accuracy = 0.899000
 epoch 84/200. Took 0.068143 seconds. 
  Full-batch training loss = 0.031737, test loss = 0.379389
  Training set accuracy = 0.999000, Test set accuracy = 0.900600
 epoch 85/200. Took 0.059038 seconds. 
  Full-batch training loss = 0.031630, test loss = 0.382411
  Training set accuracy = 0.999000, Test set accuracy = 0.898700
 epoch 86/200. Took 0.060733 seconds. 
  Full-batch training loss = 0.030432, test loss = 0.382165
  Training set accuracy = 0.999500, Test set accuracy = 0.899700
 epoch 87/200. Took 0.060124 seconds. 
  Full-batch training loss = 0.029873, test loss = 0.382534
  Training set accuracy = 1.000000, Test set accuracy = 0.900700
 epoch 88/200. Took 0.05883 seconds. 
  Full-batch training loss = 0.029428, test loss = 0.384063
  Training set accuracy = 0.999500, Test set accuracy = 0.899400
 epoch 89/200. Took 0.07026 seconds. 
  Full-batch training loss = 0.028693, test loss = 0.381958
  Training set accuracy = 1.000000, Test set accuracy = 0.900200
 epoch 90/200. Took 0.067923 seconds. 
  Full-batch training loss = 0.028791, test loss = 0.386663
  Training set accuracy = 1.000000, Test set accuracy = 0.899900
 epoch 91/200. Took 0.070904 seconds. 
  Full-batch training loss = 0.027647, test loss = 0.384504
  Training set accuracy = 1.000000, Test set accuracy = 0.899800
 epoch 92/200. Took 0.071359 seconds. 
  Full-batch training loss = 0.027278, test loss = 0.384139
  Training set accuracy = 1.000000, Test set accuracy = 0.900700
 epoch 93/200. Took 0.059426 seconds. 
  Full-batch training loss = 0.026586, test loss = 0.387754
  Training set accuracy = 1.000000, Test set accuracy = 0.900700
 epoch 94/200. Took 0.061604 seconds. 
  Full-batch training loss = 0.025851, test loss = 0.386416
  Training set accuracy = 1.000000, Test set accuracy = 0.900300
 epoch 95/200. Took 0.057779 seconds. 
  Full-batch training loss = 0.025604, test loss = 0.387006
  Training set accuracy = 1.000000, Test set accuracy = 0.900400
 epoch 96/200. Took 0.071809 seconds. 
  Full-batch training loss = 0.024999, test loss = 0.388036
  Training set accuracy = 1.000000, Test set accuracy = 0.899900
 epoch 97/200. Took 0.060884 seconds. 
  Full-batch training loss = 0.024404, test loss = 0.387861
  Training set accuracy = 1.000000, Test set accuracy = 0.900600
 epoch 98/200. Took 0.068883 seconds. 
  Full-batch training loss = 0.024358, test loss = 0.389086
  Training set accuracy = 1.000000, Test set accuracy = 0.900200
 epoch 99/200. Took 0.058137 seconds. 
  Full-batch training loss = 0.023730, test loss = 0.389841
  Training set accuracy = 1.000000, Test set accuracy = 0.900000
 epoch 100/200. Took 0.057592 seconds. 
  Full-batch training loss = 0.023258, test loss = 0.390124
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 101/200. Took 0.05858 seconds. 
  Full-batch training loss = 0.022775, test loss = 0.390047
  Training set accuracy = 1.000000, Test set accuracy = 0.900800
 epoch 102/200. Took 0.060751 seconds. 
  Full-batch training loss = 0.022504, test loss = 0.391390
  Training set accuracy = 1.000000, Test set accuracy = 0.900800
 epoch 103/200. Took 0.0573 seconds. 
  Full-batch training loss = 0.021952, test loss = 0.391501
  Training set accuracy = 1.000000, Test set accuracy = 0.900400
 epoch 104/200. Took 0.058754 seconds. 
  Full-batch training loss = 0.022046, test loss = 0.393173
  Training set accuracy = 1.000000, Test set accuracy = 0.900600
 epoch 105/200. Took 0.067851 seconds. 
  Full-batch training loss = 0.021476, test loss = 0.392994
  Training set accuracy = 1.000000, Test set accuracy = 0.901100
 epoch 106/200. Took 0.05994 seconds. 
  Full-batch training loss = 0.021003, test loss = 0.393346
  Training set accuracy = 1.000000, Test set accuracy = 0.901300
 epoch 107/200. Took 0.061694 seconds. 
  Full-batch training loss = 0.020619, test loss = 0.394232
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 108/200. Took 0.068337 seconds. 
  Full-batch training loss = 0.020260, test loss = 0.394782
  Training set accuracy = 1.000000, Test set accuracy = 0.901300
 epoch 109/200. Took 0.06378 seconds. 
  Full-batch training loss = 0.020069, test loss = 0.395991
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 110/200. Took 0.063038 seconds. 
  Full-batch training loss = 0.019604, test loss = 0.395918
  Training set accuracy = 1.000000, Test set accuracy = 0.901000
 epoch 111/200. Took 0.059558 seconds. 
  Full-batch training loss = 0.019367, test loss = 0.396840
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 112/200. Took 0.064271 seconds. 
  Full-batch training loss = 0.018981, test loss = 0.396722
  Training set accuracy = 1.000000, Test set accuracy = 0.901000
 epoch 113/200. Took 0.068888 seconds. 
  Full-batch training loss = 0.018674, test loss = 0.397188
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 114/200. Took 0.072877 seconds. 
  Full-batch training loss = 0.018476, test loss = 0.397332
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 115/200. Took 0.067782 seconds. 
  Full-batch training loss = 0.018324, test loss = 0.398894
  Training set accuracy = 1.000000, Test set accuracy = 0.901100
 epoch 116/200. Took 0.063853 seconds. 
  Full-batch training loss = 0.018247, test loss = 0.399577
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 117/200. Took 0.059544 seconds. 
  Full-batch training loss = 0.017815, test loss = 0.399418
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 118/200. Took 0.060896 seconds. 
  Full-batch training loss = 0.017496, test loss = 0.400112
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 119/200. Took 0.057107 seconds. 
  Full-batch training loss = 0.017119, test loss = 0.399913
  Training set accuracy = 1.000000, Test set accuracy = 0.900800
 epoch 120/200. Took 0.068619 seconds. 
  Full-batch training loss = 0.016864, test loss = 0.400304
  Training set accuracy = 1.000000, Test set accuracy = 0.901100
 epoch 121/200. Took 0.05805 seconds. 
  Full-batch training loss = 0.016677, test loss = 0.400978
  Training set accuracy = 1.000000, Test set accuracy = 0.900800
 epoch 122/200. Took 0.057479 seconds. 
  Full-batch training loss = 0.016587, test loss = 0.401933
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 123/200. Took 0.059548 seconds. 
  Full-batch training loss = 0.016179, test loss = 0.402851
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 124/200. Took 0.059763 seconds. 
  Full-batch training loss = 0.015962, test loss = 0.402702
  Training set accuracy = 1.000000, Test set accuracy = 0.901100
 epoch 125/200. Took 0.071045 seconds. 
  Full-batch training loss = 0.015875, test loss = 0.403511
  Training set accuracy = 1.000000, Test set accuracy = 0.901300
 epoch 126/200. Took 0.071137 seconds. 
  Full-batch training loss = 0.015527, test loss = 0.403155
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 127/200. Took 0.063317 seconds. 
  Full-batch training loss = 0.015408, test loss = 0.404460
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 128/200. Took 0.064079 seconds. 
  Full-batch training loss = 0.015164, test loss = 0.403772
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 129/200. Took 0.064181 seconds. 
  Full-batch training loss = 0.015076, test loss = 0.405860
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 130/200. Took 0.065515 seconds. 
  Full-batch training loss = 0.014809, test loss = 0.405189
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 131/200. Took 0.06792 seconds. 
  Full-batch training loss = 0.014595, test loss = 0.406706
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 132/200. Took 0.061668 seconds. 
  Full-batch training loss = 0.014378, test loss = 0.406296
  Training set accuracy = 1.000000, Test set accuracy = 0.901200
 epoch 133/200. Took 0.069783 seconds. 
  Full-batch training loss = 0.014545, test loss = 0.407735
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 134/200. Took 0.069515 seconds. 
  Full-batch training loss = 0.014067, test loss = 0.407197
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 135/200. Took 0.067553 seconds. 
  Full-batch training loss = 0.013865, test loss = 0.407514
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 136/200. Took 0.058838 seconds. 
  Full-batch training loss = 0.013665, test loss = 0.408203
  Training set accuracy = 1.000000, Test set accuracy = 0.901100
 epoch 137/200. Took 0.059979 seconds. 
  Full-batch training loss = 0.013633, test loss = 0.408612
  Training set accuracy = 1.000000, Test set accuracy = 0.900700
 epoch 138/200. Took 0.059685 seconds. 
  Full-batch training loss = 0.013343, test loss = 0.408450
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 139/200. Took 0.060936 seconds. 
  Full-batch training loss = 0.013235, test loss = 0.409457
  Training set accuracy = 1.000000, Test set accuracy = 0.901000
 epoch 140/200. Took 0.069287 seconds. 
  Full-batch training loss = 0.013111, test loss = 0.410462
  Training set accuracy = 1.000000, Test set accuracy = 0.900900
 epoch 141/200. Took 0.059494 seconds. 
  Full-batch training loss = 0.012903, test loss = 0.410517
  Training set accuracy = 1.000000, Test set accuracy = 0.901300
 epoch 142/200. Took 0.069063 seconds. 
  Full-batch training loss = 0.012752, test loss = 0.411031
  Training set accuracy = 1.000000, Test set accuracy = 0.901000
 epoch 143/200. Took 0.074583 seconds. 
  Full-batch training loss = 0.012632, test loss = 0.411874
  Training set accuracy = 1.000000, Test set accuracy = 0.901200
 epoch 144/200. Took 0.071151 seconds. 
  Full-batch training loss = 0.012471, test loss = 0.411265
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 145/200. Took 0.069681 seconds. 
  Full-batch training loss = 0.012324, test loss = 0.412530
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 146/200. Took 0.069389 seconds. 
  Full-batch training loss = 0.012196, test loss = 0.412268
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 147/200. Took 0.067873 seconds. 
  Full-batch training loss = 0.012038, test loss = 0.412728
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 148/200. Took 0.068027 seconds. 
  Full-batch training loss = 0.012007, test loss = 0.413341
  Training set accuracy = 1.000000, Test set accuracy = 0.901200
 epoch 149/200. Took 0.05973 seconds. 
  Full-batch training loss = 0.011796, test loss = 0.414077
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 150/200. Took 0.069256 seconds. 
  Full-batch training loss = 0.011660, test loss = 0.413530
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 151/200. Took 0.062992 seconds. 
  Full-batch training loss = 0.011584, test loss = 0.414181
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 152/200. Took 0.063178 seconds. 
  Full-batch training loss = 0.011540, test loss = 0.415503
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 153/200. Took 0.06489 seconds. 
  Full-batch training loss = 0.011388, test loss = 0.415469
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 154/200. Took 0.063078 seconds. 
  Full-batch training loss = 0.011195, test loss = 0.415715
  Training set accuracy = 1.000000, Test set accuracy = 0.901000
 epoch 155/200. Took 0.071848 seconds. 
  Full-batch training loss = 0.011167, test loss = 0.416318
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 156/200. Took 0.06388 seconds. 
  Full-batch training loss = 0.010975, test loss = 0.416175
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 157/200. Took 0.059551 seconds. 
  Full-batch training loss = 0.010863, test loss = 0.417079
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 158/200. Took 0.058262 seconds. 
  Full-batch training loss = 0.010791, test loss = 0.417546
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 159/200. Took 0.061604 seconds. 
  Full-batch training loss = 0.010618, test loss = 0.417586
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 160/200. Took 0.05849 seconds. 
  Full-batch training loss = 0.010531, test loss = 0.417757
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 161/200. Took 0.059958 seconds. 
  Full-batch training loss = 0.010534, test loss = 0.418766
  Training set accuracy = 1.000000, Test set accuracy = 0.901200
 epoch 162/200. Took 0.06737 seconds. 
  Full-batch training loss = 0.010434, test loss = 0.418641
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 163/200. Took 0.066318 seconds. 
  Full-batch training loss = 0.010206, test loss = 0.419346
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 164/200. Took 0.068159 seconds. 
  Full-batch training loss = 0.010127, test loss = 0.419245
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 165/200. Took 0.069803 seconds. 
  Full-batch training loss = 0.010074, test loss = 0.419645
  Training set accuracy = 1.000000, Test set accuracy = 0.902100
 epoch 166/200. Took 0.059614 seconds. 
  Full-batch training loss = 0.009919, test loss = 0.419877
  Training set accuracy = 1.000000, Test set accuracy = 0.902200
 epoch 167/200. Took 0.068931 seconds. 
  Full-batch training loss = 0.009840, test loss = 0.420170
  Training set accuracy = 1.000000, Test set accuracy = 0.902200
 epoch 168/200. Took 0.072162 seconds. 
  Full-batch training loss = 0.009767, test loss = 0.420906
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 169/200. Took 0.0606 seconds. 
  Full-batch training loss = 0.009638, test loss = 0.421808
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 170/200. Took 0.060725 seconds. 
  Full-batch training loss = 0.009567, test loss = 0.421724
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 171/200. Took 0.061748 seconds. 
  Full-batch training loss = 0.009457, test loss = 0.421902
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 172/200. Took 0.069213 seconds. 
  Full-batch training loss = 0.009380, test loss = 0.422610
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 173/200. Took 0.068915 seconds. 
  Full-batch training loss = 0.009294, test loss = 0.422615
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 174/200. Took 0.065945 seconds. 
  Full-batch training loss = 0.009208, test loss = 0.422807
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 175/200. Took 0.068619 seconds. 
  Full-batch training loss = 0.009164, test loss = 0.423300
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 176/200. Took 0.069882 seconds. 
  Full-batch training loss = 0.009066, test loss = 0.423613
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 177/200. Took 0.071289 seconds. 
  Full-batch training loss = 0.008977, test loss = 0.423825
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 178/200. Took 0.074436 seconds. 
  Full-batch training loss = 0.008927, test loss = 0.424359
  Training set accuracy = 1.000000, Test set accuracy = 0.902600
 epoch 179/200. Took 0.068568 seconds. 
  Full-batch training loss = 0.008814, test loss = 0.424782
  Training set accuracy = 1.000000, Test set accuracy = 0.902100
 epoch 180/200. Took 0.060008 seconds. 
  Full-batch training loss = 0.008733, test loss = 0.424723
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 181/200. Took 0.058947 seconds. 
  Full-batch training loss = 0.008654, test loss = 0.425385
  Training set accuracy = 1.000000, Test set accuracy = 0.901400
 epoch 182/200. Took 0.059864 seconds. 
  Full-batch training loss = 0.008581, test loss = 0.425862
  Training set accuracy = 1.000000, Test set accuracy = 0.901500
 epoch 183/200. Took 0.060804 seconds. 
  Full-batch training loss = 0.008532, test loss = 0.425862
  Training set accuracy = 1.000000, Test set accuracy = 0.902000
 epoch 184/200. Took 0.061003 seconds. 
  Full-batch training loss = 0.008456, test loss = 0.426167
  Training set accuracy = 1.000000, Test set accuracy = 0.902100
 epoch 185/200. Took 0.071527 seconds. 
  Full-batch training loss = 0.008370, test loss = 0.426278
  Training set accuracy = 1.000000, Test set accuracy = 0.902300
 epoch 186/200. Took 0.068948 seconds. 
  Full-batch training loss = 0.008300, test loss = 0.426866
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 187/200. Took 0.060175 seconds. 
  Full-batch training loss = 0.008234, test loss = 0.426966
  Training set accuracy = 1.000000, Test set accuracy = 0.901800
 epoch 188/200. Took 0.058543 seconds. 
  Full-batch training loss = 0.008163, test loss = 0.427397
  Training set accuracy = 1.000000, Test set accuracy = 0.901700
 epoch 189/200. Took 0.071425 seconds. 
  Full-batch training loss = 0.008100, test loss = 0.427788
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 190/200. Took 0.068686 seconds. 
  Full-batch training loss = 0.008037, test loss = 0.428116
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 191/200. Took 0.070559 seconds. 
  Full-batch training loss = 0.007970, test loss = 0.428540
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 192/200. Took 0.072545 seconds. 
  Full-batch training loss = 0.007902, test loss = 0.428560
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 193/200. Took 0.059668 seconds. 
  Full-batch training loss = 0.007850, test loss = 0.429145
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 194/200. Took 0.068716 seconds. 
  Full-batch training loss = 0.007791, test loss = 0.429124
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 195/200. Took 0.068736 seconds. 
  Full-batch training loss = 0.007771, test loss = 0.429787
  Training set accuracy = 1.000000, Test set accuracy = 0.902500
 epoch 196/200. Took 0.067651 seconds. 
  Full-batch training loss = 0.007673, test loss = 0.429921
  Training set accuracy = 1.000000, Test set accuracy = 0.901600
 epoch 197/200. Took 0.065856 seconds. 
  Full-batch training loss = 0.007614, test loss = 0.430553
  Training set accuracy = 1.000000, Test set accuracy = 0.902400
 epoch 198/200. Took 0.071194 seconds. 
  Full-batch training loss = 0.007552, test loss = 0.430691
  Training set accuracy = 1.000000, Test set accuracy = 0.901900
 epoch 199/200. Took 0.072889 seconds. 
  Full-batch training loss = 0.007491, test loss = 0.430568
  Training set accuracy = 1.000000, Test set accuracy = 0.902200
 epoch 200/200. Took 0.071492 seconds. 
  Full-batch training loss = 0.007433, test loss = 0.431008
  Training set accuracy = 1.000000, Test set accuracy = 0.902200
Elapsed time is 56.414790 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (200)
Training NN  (784  200   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.072588 seconds. 
  Full-batch training loss = 2.253749, test loss = 2.259516
  Training set accuracy = 0.186500, Test set accuracy = 0.177300
 epoch 2/200. Took 0.060235 seconds. 
  Full-batch training loss = 2.173380, test loss = 2.174087
  Training set accuracy = 0.444000, Test set accuracy = 0.436400
 epoch 3/200. Took 0.068921 seconds. 
  Full-batch training loss = 2.094208, test loss = 2.095785
  Training set accuracy = 0.504000, Test set accuracy = 0.495900
 epoch 4/200. Took 0.0721 seconds. 
  Full-batch training loss = 2.015826, test loss = 2.020015
  Training set accuracy = 0.523000, Test set accuracy = 0.512400
 epoch 5/200. Took 0.069864 seconds. 
  Full-batch training loss = 1.932420, test loss = 1.935855
  Training set accuracy = 0.595500, Test set accuracy = 0.581100
 epoch 6/200. Took 0.066285 seconds. 
  Full-batch training loss = 1.846649, test loss = 1.849073
  Training set accuracy = 0.612500, Test set accuracy = 0.605400
 epoch 7/200. Took 0.06583 seconds. 
  Full-batch training loss = 1.761671, test loss = 1.760126
  Training set accuracy = 0.670500, Test set accuracy = 0.662400
 epoch 8/200. Took 0.070453 seconds. 
  Full-batch training loss = 1.676217, test loss = 1.678847
  Training set accuracy = 0.700500, Test set accuracy = 0.686700
 epoch 9/200. Took 0.057736 seconds. 
  Full-batch training loss = 1.589642, test loss = 1.590142
  Training set accuracy = 0.686500, Test set accuracy = 0.685800
 epoch 10/200. Took 0.056438 seconds. 
  Full-batch training loss = 1.509089, test loss = 1.510355
  Training set accuracy = 0.720000, Test set accuracy = 0.710100
 epoch 11/200. Took 0.061787 seconds. 
  Full-batch training loss = 1.429460, test loss = 1.432470
  Training set accuracy = 0.723000, Test set accuracy = 0.718600
 epoch 12/200. Took 0.057799 seconds. 
  Full-batch training loss = 1.357857, test loss = 1.359671
  Training set accuracy = 0.747500, Test set accuracy = 0.734200
 epoch 13/200. Took 0.058238 seconds. 
  Full-batch training loss = 1.287064, test loss = 1.284734
  Training set accuracy = 0.778000, Test set accuracy = 0.774600
 epoch 14/200. Took 0.065177 seconds. 
  Full-batch training loss = 1.221927, test loss = 1.223052
  Training set accuracy = 0.753500, Test set accuracy = 0.753300
 epoch 15/200. Took 0.055594 seconds. 
  Full-batch training loss = 1.166422, test loss = 1.168962
  Training set accuracy = 0.774000, Test set accuracy = 0.770500
 epoch 16/200. Took 0.067611 seconds. 
  Full-batch training loss = 1.109920, test loss = 1.112317
  Training set accuracy = 0.770000, Test set accuracy = 0.767400
 epoch 17/200. Took 0.058636 seconds. 
  Full-batch training loss = 1.062327, test loss = 1.064583
  Training set accuracy = 0.774000, Test set accuracy = 0.767600
 epoch 18/200. Took 0.063475 seconds. 
  Full-batch training loss = 1.016888, test loss = 1.017108
  Training set accuracy = 0.807500, Test set accuracy = 0.803600
 epoch 19/200. Took 0.062946 seconds. 
  Full-batch training loss = 0.976293, test loss = 0.978240
  Training set accuracy = 0.809500, Test set accuracy = 0.801300
 epoch 20/200. Took 0.056854 seconds. 
  Full-batch training loss = 0.938459, test loss = 0.940992
  Training set accuracy = 0.814500, Test set accuracy = 0.805400
 epoch 21/200. Took 0.066926 seconds. 
  Full-batch training loss = 0.904880, test loss = 0.906686
  Training set accuracy = 0.826500, Test set accuracy = 0.819700
 epoch 22/200. Took 0.058695 seconds. 
  Full-batch training loss = 0.873406, test loss = 0.876856
  Training set accuracy = 0.828500, Test set accuracy = 0.820700
 epoch 23/200. Took 0.063422 seconds. 
  Full-batch training loss = 0.843786, test loss = 0.848588
  Training set accuracy = 0.832000, Test set accuracy = 0.820000
 epoch 24/200. Took 0.058398 seconds. 
  Full-batch training loss = 0.818787, test loss = 0.823839
  Training set accuracy = 0.827500, Test set accuracy = 0.825800
 epoch 25/200. Took 0.059474 seconds. 
  Full-batch training loss = 0.793009, test loss = 0.797580
  Training set accuracy = 0.842500, Test set accuracy = 0.831500
 epoch 26/200. Took 0.070048 seconds. 
  Full-batch training loss = 0.770182, test loss = 0.775634
  Training set accuracy = 0.843500, Test set accuracy = 0.833400
 epoch 27/200. Took 0.063863 seconds. 
  Full-batch training loss = 0.748286, test loss = 0.753963
  Training set accuracy = 0.845000, Test set accuracy = 0.836900
 epoch 28/200. Took 0.059088 seconds. 
  Full-batch training loss = 0.728099, test loss = 0.735684
  Training set accuracy = 0.852500, Test set accuracy = 0.843200
 epoch 29/200. Took 0.068009 seconds. 
  Full-batch training loss = 0.709209, test loss = 0.715746
  Training set accuracy = 0.853000, Test set accuracy = 0.849100
 epoch 30/200. Took 0.058386 seconds. 
  Full-batch training loss = 0.691879, test loss = 0.701169
  Training set accuracy = 0.853500, Test set accuracy = 0.844200
 epoch 31/200. Took 0.068453 seconds. 
  Full-batch training loss = 0.675485, test loss = 0.683643
  Training set accuracy = 0.855000, Test set accuracy = 0.852600
 epoch 32/200. Took 0.06176 seconds. 
  Full-batch training loss = 0.660503, test loss = 0.670978
  Training set accuracy = 0.855000, Test set accuracy = 0.852100
 epoch 33/200. Took 0.058853 seconds. 
  Full-batch training loss = 0.645544, test loss = 0.656928
  Training set accuracy = 0.860500, Test set accuracy = 0.853000
 epoch 34/200. Took 0.06691 seconds. 
  Full-batch training loss = 0.631947, test loss = 0.643661
  Training set accuracy = 0.862000, Test set accuracy = 0.853800
 epoch 35/200. Took 0.06205 seconds. 
  Full-batch training loss = 0.619181, test loss = 0.630703
  Training set accuracy = 0.864000, Test set accuracy = 0.858100
 epoch 36/200. Took 0.059055 seconds. 
  Full-batch training loss = 0.606976, test loss = 0.619532
  Training set accuracy = 0.866000, Test set accuracy = 0.859400
 epoch 37/200. Took 0.068579 seconds. 
  Full-batch training loss = 0.595307, test loss = 0.609507
  Training set accuracy = 0.869500, Test set accuracy = 0.862800
 epoch 38/200. Took 0.061965 seconds. 
  Full-batch training loss = 0.584325, test loss = 0.599290
  Training set accuracy = 0.871500, Test set accuracy = 0.862700
 epoch 39/200. Took 0.067683 seconds. 
  Full-batch training loss = 0.574325, test loss = 0.590558
  Training set accuracy = 0.873500, Test set accuracy = 0.864200
 epoch 40/200. Took 0.072486 seconds. 
  Full-batch training loss = 0.564653, test loss = 0.580406
  Training set accuracy = 0.871000, Test set accuracy = 0.864400
 epoch 41/200. Took 0.07201 seconds. 
  Full-batch training loss = 0.555616, test loss = 0.571806
  Training set accuracy = 0.876500, Test set accuracy = 0.868600
 epoch 42/200. Took 0.060578 seconds. 
  Full-batch training loss = 0.546114, test loss = 0.564929
  Training set accuracy = 0.875500, Test set accuracy = 0.865300
 epoch 43/200. Took 0.065966 seconds. 
  Full-batch training loss = 0.537159, test loss = 0.556222
  Training set accuracy = 0.878000, Test set accuracy = 0.870000
 epoch 44/200. Took 0.05883 seconds. 
  Full-batch training loss = 0.528944, test loss = 0.549181
  Training set accuracy = 0.878000, Test set accuracy = 0.869700
 epoch 45/200. Took 0.059003 seconds. 
  Full-batch training loss = 0.521141, test loss = 0.542574
  Training set accuracy = 0.878500, Test set accuracy = 0.869200
 epoch 46/200. Took 0.058323 seconds. 
  Full-batch training loss = 0.513546, test loss = 0.534830
  Training set accuracy = 0.880000, Test set accuracy = 0.872700
 epoch 47/200. Took 0.058925 seconds. 
  Full-batch training loss = 0.506474, test loss = 0.529125
  Training set accuracy = 0.881500, Test set accuracy = 0.871200
 epoch 48/200. Took 0.060168 seconds. 
  Full-batch training loss = 0.501292, test loss = 0.524138
  Training set accuracy = 0.878500, Test set accuracy = 0.872300
 epoch 49/200. Took 0.069977 seconds. 
  Full-batch training loss = 0.492648, test loss = 0.517103
  Training set accuracy = 0.884000, Test set accuracy = 0.874500
 epoch 50/200. Took 0.065765 seconds. 
  Full-batch training loss = 0.486538, test loss = 0.511758
  Training set accuracy = 0.883000, Test set accuracy = 0.873500
 epoch 51/200. Took 0.058686 seconds. 
  Full-batch training loss = 0.480204, test loss = 0.506325
  Training set accuracy = 0.884500, Test set accuracy = 0.874700
 epoch 52/200. Took 0.059619 seconds. 
  Full-batch training loss = 0.474228, test loss = 0.500757
  Training set accuracy = 0.886000, Test set accuracy = 0.875500
 epoch 53/200. Took 0.058857 seconds. 
  Full-batch training loss = 0.468796, test loss = 0.496409
  Training set accuracy = 0.887500, Test set accuracy = 0.877000
 epoch 54/200. Took 0.058361 seconds. 
  Full-batch training loss = 0.463026, test loss = 0.491724
  Training set accuracy = 0.888000, Test set accuracy = 0.876100
 epoch 55/200. Took 0.0679 seconds. 
  Full-batch training loss = 0.458270, test loss = 0.487499
  Training set accuracy = 0.887500, Test set accuracy = 0.877200
 epoch 56/200. Took 0.058596 seconds. 
  Full-batch training loss = 0.452664, test loss = 0.482570
  Training set accuracy = 0.890500, Test set accuracy = 0.878800
 epoch 57/200. Took 0.06797 seconds. 
  Full-batch training loss = 0.447491, test loss = 0.478914
  Training set accuracy = 0.890000, Test set accuracy = 0.879000
 epoch 58/200. Took 0.068861 seconds. 
  Full-batch training loss = 0.442958, test loss = 0.475042
  Training set accuracy = 0.890000, Test set accuracy = 0.879100
 epoch 59/200. Took 0.071284 seconds. 
  Full-batch training loss = 0.437887, test loss = 0.470964
  Training set accuracy = 0.892000, Test set accuracy = 0.879500
 epoch 60/200. Took 0.069093 seconds. 
  Full-batch training loss = 0.433808, test loss = 0.466956
  Training set accuracy = 0.893000, Test set accuracy = 0.881700
 epoch 61/200. Took 0.069553 seconds. 
  Full-batch training loss = 0.429366, test loss = 0.463022
  Training set accuracy = 0.896000, Test set accuracy = 0.881700
 epoch 62/200. Took 0.068076 seconds. 
  Full-batch training loss = 0.425245, test loss = 0.460697
  Training set accuracy = 0.893000, Test set accuracy = 0.881100
 epoch 63/200. Took 0.058124 seconds. 
  Full-batch training loss = 0.420826, test loss = 0.457166
  Training set accuracy = 0.897000, Test set accuracy = 0.882200
 epoch 64/200. Took 0.05851 seconds. 
  Full-batch training loss = 0.416678, test loss = 0.454063
  Training set accuracy = 0.898000, Test set accuracy = 0.882600
 epoch 65/200. Took 0.060228 seconds. 
  Full-batch training loss = 0.412944, test loss = 0.451201
  Training set accuracy = 0.897500, Test set accuracy = 0.882900
 epoch 66/200. Took 0.068255 seconds. 
  Full-batch training loss = 0.409298, test loss = 0.448192
  Training set accuracy = 0.896500, Test set accuracy = 0.882600
 epoch 67/200. Took 0.062859 seconds. 
  Full-batch training loss = 0.405785, test loss = 0.445501
  Training set accuracy = 0.896000, Test set accuracy = 0.883100
 epoch 68/200. Took 0.062149 seconds. 
  Full-batch training loss = 0.401793, test loss = 0.441645
  Training set accuracy = 0.899500, Test set accuracy = 0.884300
 epoch 69/200. Took 0.060274 seconds. 
  Full-batch training loss = 0.398491, test loss = 0.439400
  Training set accuracy = 0.901000, Test set accuracy = 0.884600
 epoch 70/200. Took 0.057587 seconds. 
  Full-batch training loss = 0.395212, test loss = 0.437880
  Training set accuracy = 0.901500, Test set accuracy = 0.884800
 epoch 71/200. Took 0.059963 seconds. 
  Full-batch training loss = 0.391640, test loss = 0.434001
  Training set accuracy = 0.900500, Test set accuracy = 0.885000
 epoch 72/200. Took 0.058503 seconds. 
  Full-batch training loss = 0.388431, test loss = 0.432641
  Training set accuracy = 0.901500, Test set accuracy = 0.885200
 epoch 73/200. Took 0.059402 seconds. 
  Full-batch training loss = 0.385376, test loss = 0.430227
  Training set accuracy = 0.901000, Test set accuracy = 0.884900
 epoch 74/200. Took 0.060624 seconds. 
  Full-batch training loss = 0.382112, test loss = 0.428403
  Training set accuracy = 0.904000, Test set accuracy = 0.885800
 epoch 75/200. Took 0.060356 seconds. 
  Full-batch training loss = 0.379291, test loss = 0.425864
  Training set accuracy = 0.903500, Test set accuracy = 0.886600
 epoch 76/200. Took 0.059791 seconds. 
  Full-batch training loss = 0.376371, test loss = 0.422677
  Training set accuracy = 0.903000, Test set accuracy = 0.888000
 epoch 77/200. Took 0.067416 seconds. 
  Full-batch training loss = 0.373601, test loss = 0.421206
  Training set accuracy = 0.904500, Test set accuracy = 0.887000
 epoch 78/200. Took 0.068958 seconds. 
  Full-batch training loss = 0.370751, test loss = 0.419353
  Training set accuracy = 0.905000, Test set accuracy = 0.887500
 epoch 79/200. Took 0.065202 seconds. 
  Full-batch training loss = 0.367829, test loss = 0.417005
  Training set accuracy = 0.906500, Test set accuracy = 0.888000
 epoch 80/200. Took 0.066616 seconds. 
  Full-batch training loss = 0.365243, test loss = 0.415912
  Training set accuracy = 0.906500, Test set accuracy = 0.887800
 epoch 81/200. Took 0.069148 seconds. 
  Full-batch training loss = 0.362508, test loss = 0.413415
  Training set accuracy = 0.906000, Test set accuracy = 0.888600
 epoch 82/200. Took 0.065304 seconds. 
  Full-batch training loss = 0.360134, test loss = 0.411952
  Training set accuracy = 0.905500, Test set accuracy = 0.888500
 epoch 83/200. Took 0.068075 seconds. 
  Full-batch training loss = 0.357461, test loss = 0.409729
  Training set accuracy = 0.906500, Test set accuracy = 0.888900
 epoch 84/200. Took 0.057901 seconds. 
  Full-batch training loss = 0.354948, test loss = 0.408480
  Training set accuracy = 0.909000, Test set accuracy = 0.889300
 epoch 85/200. Took 0.059017 seconds. 
  Full-batch training loss = 0.352483, test loss = 0.407302
  Training set accuracy = 0.909500, Test set accuracy = 0.889200
 epoch 86/200. Took 0.057953 seconds. 
  Full-batch training loss = 0.350110, test loss = 0.405420
  Training set accuracy = 0.908000, Test set accuracy = 0.889400
 epoch 87/200. Took 0.059017 seconds. 
  Full-batch training loss = 0.347743, test loss = 0.404187
  Training set accuracy = 0.910500, Test set accuracy = 0.889500
 epoch 88/200. Took 0.068604 seconds. 
  Full-batch training loss = 0.345527, test loss = 0.402786
  Training set accuracy = 0.910000, Test set accuracy = 0.889300
 epoch 89/200. Took 0.068845 seconds. 
  Full-batch training loss = 0.343227, test loss = 0.400810
  Training set accuracy = 0.911500, Test set accuracy = 0.889800
 epoch 90/200. Took 0.058796 seconds. 
  Full-batch training loss = 0.341010, test loss = 0.399602
  Training set accuracy = 0.911000, Test set accuracy = 0.890300
 epoch 91/200. Took 0.059142 seconds. 
  Full-batch training loss = 0.338974, test loss = 0.398229
  Training set accuracy = 0.913000, Test set accuracy = 0.890100
 epoch 92/200. Took 0.05934 seconds. 
  Full-batch training loss = 0.337270, test loss = 0.396222
  Training set accuracy = 0.914500, Test set accuracy = 0.890100
 epoch 93/200. Took 0.063454 seconds. 
  Full-batch training loss = 0.334769, test loss = 0.395727
  Training set accuracy = 0.914000, Test set accuracy = 0.890900
 epoch 94/200. Took 0.060791 seconds. 
  Full-batch training loss = 0.332848, test loss = 0.395140
  Training set accuracy = 0.913500, Test set accuracy = 0.889400
 epoch 95/200. Took 0.068562 seconds. 
  Full-batch training loss = 0.330928, test loss = 0.392884
  Training set accuracy = 0.914500, Test set accuracy = 0.891300
 epoch 96/200. Took 0.060664 seconds. 
  Full-batch training loss = 0.328745, test loss = 0.391663
  Training set accuracy = 0.914000, Test set accuracy = 0.891300
 epoch 97/200. Took 0.064427 seconds. 
  Full-batch training loss = 0.326709, test loss = 0.390449
  Training set accuracy = 0.916500, Test set accuracy = 0.891500
 epoch 98/200. Took 0.062748 seconds. 
  Full-batch training loss = 0.324809, test loss = 0.389532
  Training set accuracy = 0.915000, Test set accuracy = 0.891900
 epoch 99/200. Took 0.067548 seconds. 
  Full-batch training loss = 0.323003, test loss = 0.388604
  Training set accuracy = 0.916500, Test set accuracy = 0.892100
 epoch 100/200. Took 0.06992 seconds. 
  Full-batch training loss = 0.321109, test loss = 0.387246
  Training set accuracy = 0.916500, Test set accuracy = 0.891800
 epoch 101/200. Took 0.068046 seconds. 
  Full-batch training loss = 0.319170, test loss = 0.385899
  Training set accuracy = 0.918000, Test set accuracy = 0.891800
 epoch 102/200. Took 0.071021 seconds. 
  Full-batch training loss = 0.317513, test loss = 0.385697
  Training set accuracy = 0.917000, Test set accuracy = 0.892400
 epoch 103/200. Took 0.071541 seconds. 
  Full-batch training loss = 0.315649, test loss = 0.383663
  Training set accuracy = 0.917500, Test set accuracy = 0.891700
 epoch 104/200. Took 0.060417 seconds. 
  Full-batch training loss = 0.313928, test loss = 0.382867
  Training set accuracy = 0.916000, Test set accuracy = 0.892600
 epoch 105/200. Took 0.069373 seconds. 
  Full-batch training loss = 0.312232, test loss = 0.382156
  Training set accuracy = 0.919500, Test set accuracy = 0.891700
 epoch 106/200. Took 0.059465 seconds. 
  Full-batch training loss = 0.310544, test loss = 0.380902
  Training set accuracy = 0.918000, Test set accuracy = 0.892300
 epoch 107/200. Took 0.069574 seconds. 
  Full-batch training loss = 0.308859, test loss = 0.380120
  Training set accuracy = 0.918500, Test set accuracy = 0.891500
 epoch 108/200. Took 0.059244 seconds. 
  Full-batch training loss = 0.307157, test loss = 0.378883
  Training set accuracy = 0.920500, Test set accuracy = 0.892300
 epoch 109/200. Took 0.06794 seconds. 
  Full-batch training loss = 0.305597, test loss = 0.378686
  Training set accuracy = 0.919500, Test set accuracy = 0.891900
 epoch 110/200. Took 0.067681 seconds. 
  Full-batch training loss = 0.303957, test loss = 0.377724
  Training set accuracy = 0.921000, Test set accuracy = 0.892600
 epoch 111/200. Took 0.065492 seconds. 
  Full-batch training loss = 0.302474, test loss = 0.377354
  Training set accuracy = 0.920000, Test set accuracy = 0.892800
 epoch 112/200. Took 0.059034 seconds. 
  Full-batch training loss = 0.300823, test loss = 0.376084
  Training set accuracy = 0.920500, Test set accuracy = 0.893000
 epoch 113/200. Took 0.05703 seconds. 
  Full-batch training loss = 0.299366, test loss = 0.375100
  Training set accuracy = 0.920500, Test set accuracy = 0.892300
 epoch 114/200. Took 0.065125 seconds. 
  Full-batch training loss = 0.297764, test loss = 0.374647
  Training set accuracy = 0.919500, Test set accuracy = 0.892600
 epoch 115/200. Took 0.064073 seconds. 
  Full-batch training loss = 0.296183, test loss = 0.373341
  Training set accuracy = 0.921000, Test set accuracy = 0.893200
 epoch 116/200. Took 0.068497 seconds. 
  Full-batch training loss = 0.294752, test loss = 0.372733
  Training set accuracy = 0.921000, Test set accuracy = 0.892900
 epoch 117/200. Took 0.067695 seconds. 
  Full-batch training loss = 0.293532, test loss = 0.371942
  Training set accuracy = 0.922500, Test set accuracy = 0.892900
 epoch 118/200. Took 0.062964 seconds. 
  Full-batch training loss = 0.291858, test loss = 0.371097
  Training set accuracy = 0.923000, Test set accuracy = 0.893400
 epoch 119/200. Took 0.068376 seconds. 
  Full-batch training loss = 0.290427, test loss = 0.370264
  Training set accuracy = 0.923000, Test set accuracy = 0.893500
 epoch 120/200. Took 0.06893 seconds. 
  Full-batch training loss = 0.289128, test loss = 0.369401
  Training set accuracy = 0.924500, Test set accuracy = 0.893700
 epoch 121/200. Took 0.063099 seconds. 
  Full-batch training loss = 0.287841, test loss = 0.370161
  Training set accuracy = 0.923000, Test set accuracy = 0.893000
 epoch 122/200. Took 0.067981 seconds. 
  Full-batch training loss = 0.286283, test loss = 0.368028
  Training set accuracy = 0.923000, Test set accuracy = 0.893700
 epoch 123/200. Took 0.072093 seconds. 
  Full-batch training loss = 0.285034, test loss = 0.367536
  Training set accuracy = 0.925500, Test set accuracy = 0.893800
 epoch 124/200. Took 0.067657 seconds. 
  Full-batch training loss = 0.283550, test loss = 0.367338
  Training set accuracy = 0.924500, Test set accuracy = 0.893900
 epoch 125/200. Took 0.059843 seconds. 
  Full-batch training loss = 0.282267, test loss = 0.366187
  Training set accuracy = 0.925500, Test set accuracy = 0.893900
 epoch 126/200. Took 0.067698 seconds. 
  Full-batch training loss = 0.280887, test loss = 0.365975
  Training set accuracy = 0.925000, Test set accuracy = 0.894000
 epoch 127/200. Took 0.06084 seconds. 
  Full-batch training loss = 0.279582, test loss = 0.364976
  Training set accuracy = 0.926000, Test set accuracy = 0.894200
 epoch 128/200. Took 0.067533 seconds. 
  Full-batch training loss = 0.278301, test loss = 0.364845
  Training set accuracy = 0.926000, Test set accuracy = 0.893900
 epoch 129/200. Took 0.069853 seconds. 
  Full-batch training loss = 0.277047, test loss = 0.364448
  Training set accuracy = 0.928000, Test set accuracy = 0.894700
 epoch 130/200. Took 0.057694 seconds. 
  Full-batch training loss = 0.275799, test loss = 0.363588
  Training set accuracy = 0.927000, Test set accuracy = 0.894100
 epoch 131/200. Took 0.068618 seconds. 
  Full-batch training loss = 0.274582, test loss = 0.363230
  Training set accuracy = 0.926500, Test set accuracy = 0.895200
 epoch 132/200. Took 0.067431 seconds. 
  Full-batch training loss = 0.273303, test loss = 0.361960
  Training set accuracy = 0.927500, Test set accuracy = 0.894600
 epoch 133/200. Took 0.068853 seconds. 
  Full-batch training loss = 0.272252, test loss = 0.361387
  Training set accuracy = 0.928500, Test set accuracy = 0.894700
 epoch 134/200. Took 0.060195 seconds. 
  Full-batch training loss = 0.270864, test loss = 0.360895
  Training set accuracy = 0.929000, Test set accuracy = 0.894700
 epoch 135/200. Took 0.060058 seconds. 
  Full-batch training loss = 0.269712, test loss = 0.361109
  Training set accuracy = 0.929500, Test set accuracy = 0.894800
 epoch 136/200. Took 0.059934 seconds. 
  Full-batch training loss = 0.268608, test loss = 0.360980
  Training set accuracy = 0.929500, Test set accuracy = 0.895100
 epoch 137/200. Took 0.065398 seconds. 
  Full-batch training loss = 0.267332, test loss = 0.359649
  Training set accuracy = 0.930000, Test set accuracy = 0.895000
 epoch 138/200. Took 0.067217 seconds. 
  Full-batch training loss = 0.266371, test loss = 0.360292
  Training set accuracy = 0.929500, Test set accuracy = 0.894600
 epoch 139/200. Took 0.064236 seconds. 
  Full-batch training loss = 0.264982, test loss = 0.358661
  Training set accuracy = 0.931000, Test set accuracy = 0.895700
 epoch 140/200. Took 0.067567 seconds. 
  Full-batch training loss = 0.263871, test loss = 0.358133
  Training set accuracy = 0.932000, Test set accuracy = 0.896100
 epoch 141/200. Took 0.058454 seconds. 
  Full-batch training loss = 0.262733, test loss = 0.357956
  Training set accuracy = 0.930000, Test set accuracy = 0.896200
 epoch 142/200. Took 0.059632 seconds. 
  Full-batch training loss = 0.261741, test loss = 0.357660
  Training set accuracy = 0.933500, Test set accuracy = 0.895300
 epoch 143/200. Took 0.058565 seconds. 
  Full-batch training loss = 0.260712, test loss = 0.358125
  Training set accuracy = 0.931500, Test set accuracy = 0.895100
 epoch 144/200. Took 0.06848 seconds. 
  Full-batch training loss = 0.259472, test loss = 0.357007
  Training set accuracy = 0.932500, Test set accuracy = 0.896100
 epoch 145/200. Took 0.059641 seconds. 
  Full-batch training loss = 0.258403, test loss = 0.356389
  Training set accuracy = 0.931500, Test set accuracy = 0.896100
 epoch 146/200. Took 0.058717 seconds. 
  Full-batch training loss = 0.257365, test loss = 0.356400
  Training set accuracy = 0.933500, Test set accuracy = 0.894900
 epoch 147/200. Took 0.071917 seconds. 
  Full-batch training loss = 0.256211, test loss = 0.354965
  Training set accuracy = 0.933500, Test set accuracy = 0.895900
 epoch 148/200. Took 0.06705 seconds. 
  Full-batch training loss = 0.255169, test loss = 0.355210
  Training set accuracy = 0.934000, Test set accuracy = 0.895900
 epoch 149/200. Took 0.066747 seconds. 
  Full-batch training loss = 0.254108, test loss = 0.354300
  Training set accuracy = 0.933000, Test set accuracy = 0.895800
 epoch 150/200. Took 0.058984 seconds. 
  Full-batch training loss = 0.253341, test loss = 0.353791
  Training set accuracy = 0.935500, Test set accuracy = 0.895600
 epoch 151/200. Took 0.068139 seconds. 
  Full-batch training loss = 0.252006, test loss = 0.353506
  Training set accuracy = 0.936000, Test set accuracy = 0.896400
 epoch 152/200. Took 0.056449 seconds. 
  Full-batch training loss = 0.251137, test loss = 0.354130
  Training set accuracy = 0.934000, Test set accuracy = 0.895900
 epoch 153/200. Took 0.061297 seconds. 
  Full-batch training loss = 0.249986, test loss = 0.352786
  Training set accuracy = 0.934500, Test set accuracy = 0.896500
 epoch 154/200. Took 0.096339 seconds. 
  Full-batch training loss = 0.249072, test loss = 0.352139
  Training set accuracy = 0.938000, Test set accuracy = 0.896800
 epoch 155/200. Took 0.059499 seconds. 
  Full-batch training loss = 0.248084, test loss = 0.352223
  Training set accuracy = 0.937000, Test set accuracy = 0.896100
 epoch 156/200. Took 0.061764 seconds. 
  Full-batch training loss = 0.247032, test loss = 0.352247
  Training set accuracy = 0.937500, Test set accuracy = 0.896400
 epoch 157/200. Took 0.068048 seconds. 
  Full-batch training loss = 0.246027, test loss = 0.351522
  Training set accuracy = 0.937500, Test set accuracy = 0.895700
 epoch 158/200. Took 0.058189 seconds. 
  Full-batch training loss = 0.245058, test loss = 0.351497
  Training set accuracy = 0.939000, Test set accuracy = 0.896500
 epoch 159/200. Took 0.067279 seconds. 
  Full-batch training loss = 0.244147, test loss = 0.350747
  Training set accuracy = 0.940000, Test set accuracy = 0.896600
 epoch 160/200. Took 0.057479 seconds. 
  Full-batch training loss = 0.243134, test loss = 0.350237
  Training set accuracy = 0.939000, Test set accuracy = 0.896500
 epoch 161/200. Took 0.06642 seconds. 
  Full-batch training loss = 0.242179, test loss = 0.350091
  Training set accuracy = 0.939500, Test set accuracy = 0.896800
 epoch 162/200. Took 0.067692 seconds. 
  Full-batch training loss = 0.241323, test loss = 0.349690
  Training set accuracy = 0.939000, Test set accuracy = 0.896700
 epoch 163/200. Took 0.068761 seconds. 
  Full-batch training loss = 0.240490, test loss = 0.349199
  Training set accuracy = 0.941000, Test set accuracy = 0.897200
 epoch 164/200. Took 0.063662 seconds. 
  Full-batch training loss = 0.239470, test loss = 0.349653
  Training set accuracy = 0.939500, Test set accuracy = 0.897200
 epoch 165/200. Took 0.060161 seconds. 
  Full-batch training loss = 0.238519, test loss = 0.348509
  Training set accuracy = 0.941000, Test set accuracy = 0.896900
 epoch 166/200. Took 0.06075 seconds. 
  Full-batch training loss = 0.237582, test loss = 0.348434
  Training set accuracy = 0.939500, Test set accuracy = 0.897200
 epoch 167/200. Took 0.065242 seconds. 
  Full-batch training loss = 0.236713, test loss = 0.348794
  Training set accuracy = 0.940500, Test set accuracy = 0.896800
 epoch 168/200. Took 0.069259 seconds. 
  Full-batch training loss = 0.235787, test loss = 0.348165
  Training set accuracy = 0.942000, Test set accuracy = 0.896900
 epoch 169/200. Took 0.06393 seconds. 
  Full-batch training loss = 0.234930, test loss = 0.348073
  Training set accuracy = 0.941000, Test set accuracy = 0.897100
 epoch 170/200. Took 0.067372 seconds. 
  Full-batch training loss = 0.234090, test loss = 0.347165
  Training set accuracy = 0.941500, Test set accuracy = 0.897300
 epoch 171/200. Took 0.067965 seconds. 
  Full-batch training loss = 0.233114, test loss = 0.347518
  Training set accuracy = 0.941000, Test set accuracy = 0.897300
 epoch 172/200. Took 0.059808 seconds. 
  Full-batch training loss = 0.232265, test loss = 0.347338
  Training set accuracy = 0.941000, Test set accuracy = 0.897100
 epoch 173/200. Took 0.070614 seconds. 
  Full-batch training loss = 0.231454, test loss = 0.346468
  Training set accuracy = 0.943500, Test set accuracy = 0.897600
 epoch 174/200. Took 0.068054 seconds. 
  Full-batch training loss = 0.230507, test loss = 0.346444
  Training set accuracy = 0.944000, Test set accuracy = 0.897400
 epoch 175/200. Took 0.057776 seconds. 
  Full-batch training loss = 0.229676, test loss = 0.346596
  Training set accuracy = 0.944500, Test set accuracy = 0.897300
 epoch 176/200. Took 0.056499 seconds. 
  Full-batch training loss = 0.228974, test loss = 0.346115
  Training set accuracy = 0.941500, Test set accuracy = 0.897200
 epoch 177/200. Took 0.057085 seconds. 
  Full-batch training loss = 0.228021, test loss = 0.346088
  Training set accuracy = 0.946000, Test set accuracy = 0.897800
 epoch 178/200. Took 0.065507 seconds. 
  Full-batch training loss = 0.227207, test loss = 0.345629
  Training set accuracy = 0.946000, Test set accuracy = 0.897700
 epoch 179/200. Took 0.059957 seconds. 
  Full-batch training loss = 0.226355, test loss = 0.345208
  Training set accuracy = 0.944000, Test set accuracy = 0.897500
 epoch 180/200. Took 0.064821 seconds. 
  Full-batch training loss = 0.225467, test loss = 0.345162
  Training set accuracy = 0.944500, Test set accuracy = 0.897700
 epoch 181/200. Took 0.059127 seconds. 
  Full-batch training loss = 0.224711, test loss = 0.345202
  Training set accuracy = 0.945500, Test set accuracy = 0.898000
 epoch 182/200. Took 0.064748 seconds. 
  Full-batch training loss = 0.223938, test loss = 0.344571
  Training set accuracy = 0.946000, Test set accuracy = 0.897900
 epoch 183/200. Took 0.072898 seconds. 
  Full-batch training loss = 0.223220, test loss = 0.344856
  Training set accuracy = 0.943500, Test set accuracy = 0.896500
 epoch 184/200. Took 0.060003 seconds. 
  Full-batch training loss = 0.222258, test loss = 0.344478
  Training set accuracy = 0.946000, Test set accuracy = 0.897600
 epoch 185/200. Took 0.059564 seconds. 
  Full-batch training loss = 0.221493, test loss = 0.343794
  Training set accuracy = 0.948000, Test set accuracy = 0.897500
 epoch 186/200. Took 0.059812 seconds. 
  Full-batch training loss = 0.220687, test loss = 0.343991
  Training set accuracy = 0.947500, Test set accuracy = 0.897600
 epoch 187/200. Took 0.059584 seconds. 
  Full-batch training loss = 0.219883, test loss = 0.343694
  Training set accuracy = 0.947500, Test set accuracy = 0.897100
 epoch 188/200. Took 0.063423 seconds. 
  Full-batch training loss = 0.219089, test loss = 0.343167
  Training set accuracy = 0.947500, Test set accuracy = 0.897300
 epoch 189/200. Took 0.060265 seconds. 
  Full-batch training loss = 0.218360, test loss = 0.342859
  Training set accuracy = 0.947500, Test set accuracy = 0.897800
 epoch 190/200. Took 0.06849 seconds. 
  Full-batch training loss = 0.217633, test loss = 0.343081
  Training set accuracy = 0.948000, Test set accuracy = 0.896800
 epoch 191/200. Took 0.068587 seconds. 
  Full-batch training loss = 0.216795, test loss = 0.343267
  Training set accuracy = 0.949500, Test set accuracy = 0.897700
 epoch 192/200. Took 0.070615 seconds. 
  Full-batch training loss = 0.216080, test loss = 0.342692
  Training set accuracy = 0.948000, Test set accuracy = 0.898000
 epoch 193/200. Took 0.059022 seconds. 
  Full-batch training loss = 0.215439, test loss = 0.342738
  Training set accuracy = 0.946500, Test set accuracy = 0.897600
 epoch 194/200. Took 0.067201 seconds. 
  Full-batch training loss = 0.214470, test loss = 0.342428
  Training set accuracy = 0.949000, Test set accuracy = 0.897600
 epoch 195/200. Took 0.068364 seconds. 
  Full-batch training loss = 0.213826, test loss = 0.342075
  Training set accuracy = 0.948000, Test set accuracy = 0.897300
 epoch 196/200. Took 0.067912 seconds. 
  Full-batch training loss = 0.213254, test loss = 0.342219
  Training set accuracy = 0.949000, Test set accuracy = 0.897300
 epoch 197/200. Took 0.05987 seconds. 
  Full-batch training loss = 0.212477, test loss = 0.341315
  Training set accuracy = 0.949500, Test set accuracy = 0.898900
 epoch 198/200. Took 0.058729 seconds. 
  Full-batch training loss = 0.211543, test loss = 0.341889
  Training set accuracy = 0.949000, Test set accuracy = 0.897700
 epoch 199/200. Took 0.066819 seconds. 
  Full-batch training loss = 0.210872, test loss = 0.341658
  Training set accuracy = 0.948000, Test set accuracy = 0.897200
 epoch 200/200. Took 0.061686 seconds. 
  Full-batch training loss = 0.210179, test loss = 0.341929
  Training set accuracy = 0.949500, Test set accuracy = 0.896700
Elapsed time is 54.878119 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 200	learningRateBP: 0.001
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (200)
Training NN  (784  200   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.067767 seconds. 
  Full-batch training loss = 2.325304, test loss = 2.319023
  Training set accuracy = 0.165500, Test set accuracy = 0.181000
 epoch 2/200. Took 0.068492 seconds. 
  Full-batch training loss = 2.288552, test loss = 2.286161
  Training set accuracy = 0.190500, Test set accuracy = 0.209100
 epoch 3/200. Took 0.058691 seconds. 
  Full-batch training loss = 2.271824, test loss = 2.271145
  Training set accuracy = 0.228500, Test set accuracy = 0.251900
 epoch 4/200. Took 0.058481 seconds. 
  Full-batch training loss = 2.260504, test loss = 2.261313
  Training set accuracy = 0.241000, Test set accuracy = 0.248800
 epoch 5/200. Took 0.069923 seconds. 
  Full-batch training loss = 2.251579, test loss = 2.252982
  Training set accuracy = 0.258000, Test set accuracy = 0.261800
 epoch 6/200. Took 0.069299 seconds. 
  Full-batch training loss = 2.243300, test loss = 2.244923
  Training set accuracy = 0.290000, Test set accuracy = 0.290100
 epoch 7/200. Took 0.071138 seconds. 
  Full-batch training loss = 2.235203, test loss = 2.236688
  Training set accuracy = 0.309500, Test set accuracy = 0.310400
 epoch 8/200. Took 0.058675 seconds. 
  Full-batch training loss = 2.227071, test loss = 2.228679
  Training set accuracy = 0.321500, Test set accuracy = 0.323400
 epoch 9/200. Took 0.069721 seconds. 
  Full-batch training loss = 2.219074, test loss = 2.220751
  Training set accuracy = 0.333000, Test set accuracy = 0.334800
 epoch 10/200. Took 0.069471 seconds. 
  Full-batch training loss = 2.211015, test loss = 2.212441
  Training set accuracy = 0.385500, Test set accuracy = 0.381700
 epoch 11/200. Took 0.068662 seconds. 
  Full-batch training loss = 2.203030, test loss = 2.204136
  Training set accuracy = 0.416500, Test set accuracy = 0.415500
 epoch 12/200. Took 0.060423 seconds. 
  Full-batch training loss = 2.194992, test loss = 2.196328
  Training set accuracy = 0.428500, Test set accuracy = 0.423700
 epoch 13/200. Took 0.059373 seconds. 
  Full-batch training loss = 2.187023, test loss = 2.188086
  Training set accuracy = 0.439000, Test set accuracy = 0.439500
 epoch 14/200. Took 0.057306 seconds. 
  Full-batch training loss = 2.179057, test loss = 2.180241
  Training set accuracy = 0.452000, Test set accuracy = 0.454100
 epoch 15/200. Took 0.072317 seconds. 
  Full-batch training loss = 2.171086, test loss = 2.172030
  Training set accuracy = 0.493000, Test set accuracy = 0.487900
 epoch 16/200. Took 0.057549 seconds. 
  Full-batch training loss = 2.163121, test loss = 2.163998
  Training set accuracy = 0.504500, Test set accuracy = 0.497600
 epoch 17/200. Took 0.059205 seconds. 
  Full-batch training loss = 2.155087, test loss = 2.155992
  Training set accuracy = 0.513000, Test set accuracy = 0.505700
 epoch 18/200. Took 0.060173 seconds. 
  Full-batch training loss = 2.147115, test loss = 2.147770
  Training set accuracy = 0.518000, Test set accuracy = 0.509600
 epoch 19/200. Took 0.059568 seconds. 
  Full-batch training loss = 2.139158, test loss = 2.139581
  Training set accuracy = 0.553000, Test set accuracy = 0.542400
 epoch 20/200. Took 0.062093 seconds. 
  Full-batch training loss = 2.131118, test loss = 2.131552
  Training set accuracy = 0.543000, Test set accuracy = 0.541500
 epoch 21/200. Took 0.069522 seconds. 
  Full-batch training loss = 2.123127, test loss = 2.123737
  Training set accuracy = 0.559500, Test set accuracy = 0.550500
 epoch 22/200. Took 0.067441 seconds. 
  Full-batch training loss = 2.115166, test loss = 2.115433
  Training set accuracy = 0.563000, Test set accuracy = 0.557700
 epoch 23/200. Took 0.059479 seconds. 
  Full-batch training loss = 2.107125, test loss = 2.107344
  Training set accuracy = 0.576500, Test set accuracy = 0.570900
 epoch 24/200. Took 0.056211 seconds. 
  Full-batch training loss = 2.099094, test loss = 2.099218
  Training set accuracy = 0.584500, Test set accuracy = 0.573300
 epoch 25/200. Took 0.066513 seconds. 
  Full-batch training loss = 2.091106, test loss = 2.091372
  Training set accuracy = 0.590000, Test set accuracy = 0.577100
 epoch 26/200. Took 0.064698 seconds. 
  Full-batch training loss = 2.082978, test loss = 2.082970
  Training set accuracy = 0.599000, Test set accuracy = 0.586300
 epoch 27/200. Took 0.066879 seconds. 
  Full-batch training loss = 2.074906, test loss = 2.074863
  Training set accuracy = 0.603000, Test set accuracy = 0.590600
 epoch 28/200. Took 0.058327 seconds. 
  Full-batch training loss = 2.066861, test loss = 2.066676
  Training set accuracy = 0.616000, Test set accuracy = 0.602000
 epoch 29/200. Took 0.058106 seconds. 
  Full-batch training loss = 2.058796, test loss = 2.058673
  Training set accuracy = 0.617500, Test set accuracy = 0.605200
 epoch 30/200. Took 0.068317 seconds. 
  Full-batch training loss = 2.050629, test loss = 2.050118
  Training set accuracy = 0.626500, Test set accuracy = 0.614400
 epoch 31/200. Took 0.065264 seconds. 
  Full-batch training loss = 2.042514, test loss = 2.042111
  Training set accuracy = 0.627000, Test set accuracy = 0.614300
 epoch 32/200. Took 0.067004 seconds. 
  Full-batch training loss = 2.034381, test loss = 2.034045
  Training set accuracy = 0.627500, Test set accuracy = 0.616000
 epoch 33/200. Took 0.059621 seconds. 
  Full-batch training loss = 2.026202, test loss = 2.025496
  Training set accuracy = 0.634000, Test set accuracy = 0.621600
 epoch 34/200. Took 0.058393 seconds. 
  Full-batch training loss = 2.018056, test loss = 2.017171
  Training set accuracy = 0.646500, Test set accuracy = 0.638400
 epoch 35/200. Took 0.066637 seconds. 
  Full-batch training loss = 2.009792, test loss = 2.009167
  Training set accuracy = 0.644000, Test set accuracy = 0.629200
 epoch 36/200. Took 0.062646 seconds. 
  Full-batch training loss = 2.001604, test loss = 2.000538
  Training set accuracy = 0.650000, Test set accuracy = 0.641700
 epoch 37/200. Took 0.058829 seconds. 
  Full-batch training loss = 1.993362, test loss = 1.992571
  Training set accuracy = 0.647000, Test set accuracy = 0.640100
 epoch 38/200. Took 0.067557 seconds. 
  Full-batch training loss = 1.985116, test loss = 1.984129
  Training set accuracy = 0.654000, Test set accuracy = 0.646200
 epoch 39/200. Took 0.059555 seconds. 
  Full-batch training loss = 1.976819, test loss = 1.975697
  Training set accuracy = 0.657000, Test set accuracy = 0.648500
 epoch 40/200. Took 0.063179 seconds. 
  Full-batch training loss = 1.968520, test loss = 1.967360
  Training set accuracy = 0.660500, Test set accuracy = 0.651600
 epoch 41/200. Took 0.060712 seconds. 
  Full-batch training loss = 1.960205, test loss = 1.959105
  Training set accuracy = 0.667000, Test set accuracy = 0.656700
 epoch 42/200. Took 0.067351 seconds. 
  Full-batch training loss = 1.951832, test loss = 1.950484
  Training set accuracy = 0.664000, Test set accuracy = 0.654900
 epoch 43/200. Took 0.068159 seconds. 
  Full-batch training loss = 1.943503, test loss = 1.942241
  Training set accuracy = 0.668000, Test set accuracy = 0.659600
 epoch 44/200. Took 0.058951 seconds. 
  Full-batch training loss = 1.935153, test loss = 1.933886
  Training set accuracy = 0.672500, Test set accuracy = 0.663600
 epoch 45/200. Took 0.05851 seconds. 
  Full-batch training loss = 1.926694, test loss = 1.925058
  Training set accuracy = 0.667000, Test set accuracy = 0.664300
 epoch 46/200. Took 0.068927 seconds. 
  Full-batch training loss = 1.918281, test loss = 1.916624
  Training set accuracy = 0.684000, Test set accuracy = 0.668200
 epoch 47/200. Took 0.05832 seconds. 
  Full-batch training loss = 1.909872, test loss = 1.908216
  Training set accuracy = 0.679000, Test set accuracy = 0.669700
 epoch 48/200. Took 0.058472 seconds. 
  Full-batch training loss = 1.901441, test loss = 1.899818
  Training set accuracy = 0.679000, Test set accuracy = 0.667900
 epoch 49/200. Took 0.056651 seconds. 
  Full-batch training loss = 1.892894, test loss = 1.890949
  Training set accuracy = 0.685000, Test set accuracy = 0.672300
 epoch 50/200. Took 0.068586 seconds. 
  Full-batch training loss = 1.884424, test loss = 1.882573
  Training set accuracy = 0.685500, Test set accuracy = 0.675000
 epoch 51/200. Took 0.059433 seconds. 
  Full-batch training loss = 1.875988, test loss = 1.874040
  Training set accuracy = 0.696000, Test set accuracy = 0.685500
 epoch 52/200. Took 0.064215 seconds. 
  Full-batch training loss = 1.867440, test loss = 1.865277
  Training set accuracy = 0.699000, Test set accuracy = 0.684100
 epoch 53/200. Took 0.065352 seconds. 
  Full-batch training loss = 1.858883, test loss = 1.856642
  Training set accuracy = 0.693000, Test set accuracy = 0.683300
 epoch 54/200. Took 0.057973 seconds. 
  Full-batch training loss = 1.850342, test loss = 1.848022
  Training set accuracy = 0.694500, Test set accuracy = 0.683600
 epoch 55/200. Took 0.068429 seconds. 
  Full-batch training loss = 1.841751, test loss = 1.839558
  Training set accuracy = 0.698000, Test set accuracy = 0.685200
 epoch 56/200. Took 0.068699 seconds. 
  Full-batch training loss = 1.833170, test loss = 1.830572
  Training set accuracy = 0.695500, Test set accuracy = 0.683500
 epoch 57/200. Took 0.068278 seconds. 
  Full-batch training loss = 1.824585, test loss = 1.822467
  Training set accuracy = 0.696500, Test set accuracy = 0.684900
 epoch 58/200. Took 0.06973 seconds. 
  Full-batch training loss = 1.816005, test loss = 1.813588
  Training set accuracy = 0.703000, Test set accuracy = 0.693100
 epoch 59/200. Took 0.060597 seconds. 
  Full-batch training loss = 1.807420, test loss = 1.804791
  Training set accuracy = 0.707500, Test set accuracy = 0.698500
 epoch 60/200. Took 0.067452 seconds. 
  Full-batch training loss = 1.798854, test loss = 1.796461
  Training set accuracy = 0.699000, Test set accuracy = 0.692900
 epoch 61/200. Took 0.066439 seconds. 
  Full-batch training loss = 1.790157, test loss = 1.787492
  Training set accuracy = 0.706000, Test set accuracy = 0.698200
 epoch 62/200. Took 0.058508 seconds. 
  Full-batch training loss = 1.781588, test loss = 1.778840
  Training set accuracy = 0.707000, Test set accuracy = 0.700100
 epoch 63/200. Took 0.073694 seconds. 
  Full-batch training loss = 1.772961, test loss = 1.770321
  Training set accuracy = 0.706000, Test set accuracy = 0.700000
 epoch 64/200. Took 0.067099 seconds. 
  Full-batch training loss = 1.764302, test loss = 1.761367
  Training set accuracy = 0.707500, Test set accuracy = 0.700500
 epoch 65/200. Took 0.068412 seconds. 
  Full-batch training loss = 1.755685, test loss = 1.752847
  Training set accuracy = 0.709500, Test set accuracy = 0.704700
 epoch 66/200. Took 0.067241 seconds. 
  Full-batch training loss = 1.747055, test loss = 1.744003
  Training set accuracy = 0.718500, Test set accuracy = 0.708400
 epoch 67/200. Took 0.06705 seconds. 
  Full-batch training loss = 1.738372, test loss = 1.735583
  Training set accuracy = 0.708000, Test set accuracy = 0.701600
 epoch 68/200. Took 0.06739 seconds. 
  Full-batch training loss = 1.729757, test loss = 1.726708
  Training set accuracy = 0.714000, Test set accuracy = 0.707700
 epoch 69/200. Took 0.068175 seconds. 
  Full-batch training loss = 1.721118, test loss = 1.718146
  Training set accuracy = 0.717500, Test set accuracy = 0.711400
 epoch 70/200. Took 0.074871 seconds. 
  Full-batch training loss = 1.712518, test loss = 1.709310
  Training set accuracy = 0.721500, Test set accuracy = 0.712700
 epoch 71/200. Took 0.066849 seconds. 
  Full-batch training loss = 1.703826, test loss = 1.700600
  Training set accuracy = 0.721500, Test set accuracy = 0.711300
 epoch 72/200. Took 0.058588 seconds. 
  Full-batch training loss = 1.695247, test loss = 1.692185
  Training set accuracy = 0.719000, Test set accuracy = 0.713200
 epoch 73/200. Took 0.063261 seconds. 
  Full-batch training loss = 1.686608, test loss = 1.683046
  Training set accuracy = 0.724000, Test set accuracy = 0.716200
 epoch 74/200. Took 0.058939 seconds. 
  Full-batch training loss = 1.678014, test loss = 1.674967
  Training set accuracy = 0.721500, Test set accuracy = 0.715600
 epoch 75/200. Took 0.06085 seconds. 
  Full-batch training loss = 1.669415, test loss = 1.665847
  Training set accuracy = 0.726500, Test set accuracy = 0.721200
 epoch 76/200. Took 0.058497 seconds. 
  Full-batch training loss = 1.660814, test loss = 1.657437
  Training set accuracy = 0.727500, Test set accuracy = 0.718800
 epoch 77/200. Took 0.058008 seconds. 
  Full-batch training loss = 1.652271, test loss = 1.648896
  Training set accuracy = 0.727500, Test set accuracy = 0.720400
 epoch 78/200. Took 0.059729 seconds. 
  Full-batch training loss = 1.643705, test loss = 1.640121
  Training set accuracy = 0.729500, Test set accuracy = 0.722400
 epoch 79/200. Took 0.057754 seconds. 
  Full-batch training loss = 1.635146, test loss = 1.631579
  Training set accuracy = 0.730500, Test set accuracy = 0.722500
 epoch 80/200. Took 0.056207 seconds. 
  Full-batch training loss = 1.626634, test loss = 1.623301
  Training set accuracy = 0.730000, Test set accuracy = 0.723400
 epoch 81/200. Took 0.058175 seconds. 
  Full-batch training loss = 1.618121, test loss = 1.614498
  Training set accuracy = 0.733500, Test set accuracy = 0.726400
 epoch 82/200. Took 0.056644 seconds. 
  Full-batch training loss = 1.609609, test loss = 1.606052
  Training set accuracy = 0.739000, Test set accuracy = 0.728200
 epoch 83/200. Took 0.062395 seconds. 
  Full-batch training loss = 1.601158, test loss = 1.597684
  Training set accuracy = 0.734000, Test set accuracy = 0.729600
 epoch 84/200. Took 0.065184 seconds. 
  Full-batch training loss = 1.592709, test loss = 1.589155
  Training set accuracy = 0.737000, Test set accuracy = 0.728200
 epoch 85/200. Took 0.068078 seconds. 
  Full-batch training loss = 1.584308, test loss = 1.580705
  Training set accuracy = 0.741500, Test set accuracy = 0.731200
 epoch 86/200. Took 0.066476 seconds. 
  Full-batch training loss = 1.575915, test loss = 1.572275
  Training set accuracy = 0.742000, Test set accuracy = 0.729900
 epoch 87/200. Took 0.066049 seconds. 
  Full-batch training loss = 1.567540, test loss = 1.563937
  Training set accuracy = 0.745000, Test set accuracy = 0.736500
 epoch 88/200. Took 0.068164 seconds. 
  Full-batch training loss = 1.559168, test loss = 1.555491
  Training set accuracy = 0.740500, Test set accuracy = 0.730900
 epoch 89/200. Took 0.058952 seconds. 
  Full-batch training loss = 1.550855, test loss = 1.547141
  Training set accuracy = 0.744500, Test set accuracy = 0.735800
 epoch 90/200. Took 0.067158 seconds. 
  Full-batch training loss = 1.542587, test loss = 1.539088
  Training set accuracy = 0.743000, Test set accuracy = 0.736700
 epoch 91/200. Took 0.058829 seconds. 
  Full-batch training loss = 1.534312, test loss = 1.530713
  Training set accuracy = 0.745000, Test set accuracy = 0.737400
 epoch 92/200. Took 0.058832 seconds. 
  Full-batch training loss = 1.526116, test loss = 1.522597
  Training set accuracy = 0.747500, Test set accuracy = 0.738400
 epoch 93/200. Took 0.061947 seconds. 
  Full-batch training loss = 1.517940, test loss = 1.513943
  Training set accuracy = 0.752000, Test set accuracy = 0.743400
 epoch 94/200. Took 0.067924 seconds. 
  Full-batch training loss = 1.509741, test loss = 1.506132
  Training set accuracy = 0.748000, Test set accuracy = 0.740700
 epoch 95/200. Took 0.070157 seconds. 
  Full-batch training loss = 1.501634, test loss = 1.498099
  Training set accuracy = 0.747000, Test set accuracy = 0.741300
 epoch 96/200. Took 0.058816 seconds. 
  Full-batch training loss = 1.493519, test loss = 1.489863
  Training set accuracy = 0.752500, Test set accuracy = 0.743800
 epoch 97/200. Took 0.05841 seconds. 
  Full-batch training loss = 1.485483, test loss = 1.481742
  Training set accuracy = 0.751000, Test set accuracy = 0.746500
 epoch 98/200. Took 0.067433 seconds. 
  Full-batch training loss = 1.477463, test loss = 1.473738
  Training set accuracy = 0.754000, Test set accuracy = 0.746700
 epoch 99/200. Took 0.067663 seconds. 
  Full-batch training loss = 1.469501, test loss = 1.465867
  Training set accuracy = 0.748500, Test set accuracy = 0.744200
 epoch 100/200. Took 0.065199 seconds. 
  Full-batch training loss = 1.461575, test loss = 1.457971
  Training set accuracy = 0.755500, Test set accuracy = 0.750600
 epoch 101/200. Took 0.059132 seconds. 
  Full-batch training loss = 1.453674, test loss = 1.449927
  Training set accuracy = 0.754500, Test set accuracy = 0.751900
 epoch 102/200. Took 0.057019 seconds. 
  Full-batch training loss = 1.445776, test loss = 1.442372
  Training set accuracy = 0.755500, Test set accuracy = 0.749400
 epoch 103/200. Took 0.057884 seconds. 
  Full-batch training loss = 1.437960, test loss = 1.434438
  Training set accuracy = 0.756000, Test set accuracy = 0.751500
 epoch 104/200. Took 0.059538 seconds. 
  Full-batch training loss = 1.430187, test loss = 1.426611
  Training set accuracy = 0.756500, Test set accuracy = 0.753400
 epoch 105/200. Took 0.071732 seconds. 
  Full-batch training loss = 1.422462, test loss = 1.419061
  Training set accuracy = 0.757000, Test set accuracy = 0.752700
 epoch 106/200. Took 0.069203 seconds. 
  Full-batch training loss = 1.414802, test loss = 1.411220
  Training set accuracy = 0.757500, Test set accuracy = 0.755900
 epoch 107/200. Took 0.068213 seconds. 
  Full-batch training loss = 1.407127, test loss = 1.403594
  Training set accuracy = 0.762000, Test set accuracy = 0.757500
 epoch 108/200. Took 0.056255 seconds. 
  Full-batch training loss = 1.399537, test loss = 1.395919
  Training set accuracy = 0.763000, Test set accuracy = 0.759000
 epoch 109/200. Took 0.069165 seconds. 
  Full-batch training loss = 1.392037, test loss = 1.388754
  Training set accuracy = 0.763500, Test set accuracy = 0.759700
 epoch 110/200. Took 0.059038 seconds. 
  Full-batch training loss = 1.384482, test loss = 1.381064
  Training set accuracy = 0.764500, Test set accuracy = 0.759400
 epoch 111/200. Took 0.065065 seconds. 
  Full-batch training loss = 1.377055, test loss = 1.373794
  Training set accuracy = 0.764000, Test set accuracy = 0.760600
 epoch 112/200. Took 0.058366 seconds. 
  Full-batch training loss = 1.369616, test loss = 1.366330
  Training set accuracy = 0.765000, Test set accuracy = 0.761600
 epoch 113/200. Took 0.058814 seconds. 
  Full-batch training loss = 1.362270, test loss = 1.358910
  Training set accuracy = 0.769000, Test set accuracy = 0.763300
 epoch 114/200. Took 0.05795 seconds. 
  Full-batch training loss = 1.354965, test loss = 1.351690
  Training set accuracy = 0.769500, Test set accuracy = 0.763700
 epoch 115/200. Took 0.072054 seconds. 
  Full-batch training loss = 1.347704, test loss = 1.344436
  Training set accuracy = 0.773000, Test set accuracy = 0.764200
 epoch 116/200. Took 0.060496 seconds. 
  Full-batch training loss = 1.340491, test loss = 1.337260
  Training set accuracy = 0.775500, Test set accuracy = 0.765300
 epoch 117/200. Took 0.057128 seconds. 
  Full-batch training loss = 1.333344, test loss = 1.330149
  Training set accuracy = 0.774500, Test set accuracy = 0.767200
 epoch 118/200. Took 0.05779 seconds. 
  Full-batch training loss = 1.326182, test loss = 1.322884
  Training set accuracy = 0.774000, Test set accuracy = 0.766300
 epoch 119/200. Took 0.060662 seconds. 
  Full-batch training loss = 1.319144, test loss = 1.316043
  Training set accuracy = 0.774500, Test set accuracy = 0.767200
 epoch 120/200. Took 0.070006 seconds. 
  Full-batch training loss = 1.312120, test loss = 1.309019
  Training set accuracy = 0.776500, Test set accuracy = 0.767500
 epoch 121/200. Took 0.056762 seconds. 
  Full-batch training loss = 1.305174, test loss = 1.302170
  Training set accuracy = 0.781500, Test set accuracy = 0.769100
 epoch 122/200. Took 0.06588 seconds. 
  Full-batch training loss = 1.298221, test loss = 1.295339
  Training set accuracy = 0.779500, Test set accuracy = 0.768700
 epoch 123/200. Took 0.057331 seconds. 
  Full-batch training loss = 1.291352, test loss = 1.288390
  Training set accuracy = 0.779500, Test set accuracy = 0.769900
 epoch 124/200. Took 0.066448 seconds. 
  Full-batch training loss = 1.284590, test loss = 1.281815
  Training set accuracy = 0.780500, Test set accuracy = 0.771400
 epoch 125/200. Took 0.057434 seconds. 
  Full-batch training loss = 1.277827, test loss = 1.274998
  Training set accuracy = 0.780000, Test set accuracy = 0.769600
 epoch 126/200. Took 0.064 seconds. 
  Full-batch training loss = 1.271099, test loss = 1.268203
  Training set accuracy = 0.786500, Test set accuracy = 0.774800
 epoch 127/200. Took 0.061925 seconds. 
  Full-batch training loss = 1.264444, test loss = 1.261760
  Training set accuracy = 0.787000, Test set accuracy = 0.775100
 epoch 128/200. Took 0.059347 seconds. 
  Full-batch training loss = 1.257842, test loss = 1.255335
  Training set accuracy = 0.786500, Test set accuracy = 0.774500
 epoch 129/200. Took 0.059764 seconds. 
  Full-batch training loss = 1.251316, test loss = 1.248701
  Training set accuracy = 0.791000, Test set accuracy = 0.775800
 epoch 130/200. Took 0.058448 seconds. 
  Full-batch training loss = 1.244788, test loss = 1.241970
  Training set accuracy = 0.789500, Test set accuracy = 0.776100
 epoch 131/200. Took 0.05814 seconds. 
  Full-batch training loss = 1.238345, test loss = 1.235954
  Training set accuracy = 0.791500, Test set accuracy = 0.776100
 epoch 132/200. Took 0.067259 seconds. 
  Full-batch training loss = 1.231950, test loss = 1.229597
  Training set accuracy = 0.791500, Test set accuracy = 0.777800
 epoch 133/200. Took 0.065111 seconds. 
  Full-batch training loss = 1.225622, test loss = 1.223161
  Training set accuracy = 0.792500, Test set accuracy = 0.778100
 epoch 134/200. Took 0.058998 seconds. 
  Full-batch training loss = 1.219320, test loss = 1.216953
  Training set accuracy = 0.794500, Test set accuracy = 0.778000
 epoch 135/200. Took 0.068075 seconds. 
  Full-batch training loss = 1.213064, test loss = 1.210892
  Training set accuracy = 0.793000, Test set accuracy = 0.778500
 epoch 136/200. Took 0.065034 seconds. 
  Full-batch training loss = 1.206888, test loss = 1.204878
  Training set accuracy = 0.791500, Test set accuracy = 0.779500
 epoch 137/200. Took 0.070264 seconds. 
  Full-batch training loss = 1.200747, test loss = 1.198684
  Training set accuracy = 0.795500, Test set accuracy = 0.782000
 epoch 138/200. Took 0.065402 seconds. 
  Full-batch training loss = 1.194663, test loss = 1.192684
  Training set accuracy = 0.798500, Test set accuracy = 0.780700
 epoch 139/200. Took 0.060359 seconds. 
  Full-batch training loss = 1.188606, test loss = 1.186851
  Training set accuracy = 0.795500, Test set accuracy = 0.781500
 epoch 140/200. Took 0.067532 seconds. 
  Full-batch training loss = 1.182668, test loss = 1.180717
  Training set accuracy = 0.796500, Test set accuracy = 0.783100
 epoch 141/200. Took 0.06685 seconds. 
  Full-batch training loss = 1.176715, test loss = 1.174818
  Training set accuracy = 0.798500, Test set accuracy = 0.783500
 epoch 142/200. Took 0.062549 seconds. 
  Full-batch training loss = 1.170805, test loss = 1.169106
  Training set accuracy = 0.798000, Test set accuracy = 0.783200
 epoch 143/200. Took 0.065753 seconds. 
  Full-batch training loss = 1.164990, test loss = 1.163242
  Training set accuracy = 0.800500, Test set accuracy = 0.785100
 epoch 144/200. Took 0.070285 seconds. 
  Full-batch training loss = 1.159208, test loss = 1.157688
  Training set accuracy = 0.799000, Test set accuracy = 0.783900
 epoch 145/200. Took 0.058113 seconds. 
  Full-batch training loss = 1.153460, test loss = 1.151948
  Training set accuracy = 0.801500, Test set accuracy = 0.786000
 epoch 146/200. Took 0.058546 seconds. 
  Full-batch training loss = 1.147785, test loss = 1.146346
  Training set accuracy = 0.798500, Test set accuracy = 0.785900
 epoch 147/200. Took 0.059153 seconds. 
  Full-batch training loss = 1.142163, test loss = 1.140919
  Training set accuracy = 0.798500, Test set accuracy = 0.785500
 epoch 148/200. Took 0.05963 seconds. 
  Full-batch training loss = 1.136566, test loss = 1.135125
  Training set accuracy = 0.801500, Test set accuracy = 0.787900
 epoch 149/200. Took 0.062907 seconds. 
  Full-batch training loss = 1.131037, test loss = 1.129849
  Training set accuracy = 0.801500, Test set accuracy = 0.789100
 epoch 150/200. Took 0.059088 seconds. 
  Full-batch training loss = 1.125529, test loss = 1.124433
  Training set accuracy = 0.801000, Test set accuracy = 0.787100
 epoch 151/200. Took 0.063255 seconds. 
  Full-batch training loss = 1.120121, test loss = 1.119259
  Training set accuracy = 0.804000, Test set accuracy = 0.789100
 epoch 152/200. Took 0.067738 seconds. 
  Full-batch training loss = 1.114709, test loss = 1.113874
  Training set accuracy = 0.801500, Test set accuracy = 0.789300
 epoch 153/200. Took 0.061229 seconds. 
  Full-batch training loss = 1.109364, test loss = 1.108457
  Training set accuracy = 0.803500, Test set accuracy = 0.789900
 epoch 154/200. Took 0.06915 seconds. 
  Full-batch training loss = 1.104084, test loss = 1.103241
  Training set accuracy = 0.804500, Test set accuracy = 0.790300
 epoch 155/200. Took 0.073402 seconds. 
  Full-batch training loss = 1.098842, test loss = 1.098148
  Training set accuracy = 0.804500, Test set accuracy = 0.790400
 epoch 156/200. Took 0.068995 seconds. 
  Full-batch training loss = 1.093645, test loss = 1.093131
  Training set accuracy = 0.805000, Test set accuracy = 0.791800
 epoch 157/200. Took 0.063585 seconds. 
  Full-batch training loss = 1.088492, test loss = 1.088065
  Training set accuracy = 0.805500, Test set accuracy = 0.793000
 epoch 158/200. Took 0.067505 seconds. 
  Full-batch training loss = 1.083360, test loss = 1.082942
  Training set accuracy = 0.808500, Test set accuracy = 0.793500
 epoch 159/200. Took 0.058466 seconds. 
  Full-batch training loss = 1.078332, test loss = 1.077928
  Training set accuracy = 0.808000, Test set accuracy = 0.795800
 epoch 160/200. Took 0.058471 seconds. 
  Full-batch training loss = 1.073301, test loss = 1.073104
  Training set accuracy = 0.810000, Test set accuracy = 0.794900
 epoch 161/200. Took 0.058947 seconds. 
  Full-batch training loss = 1.068348, test loss = 1.068354
  Training set accuracy = 0.810000, Test set accuracy = 0.795700
 epoch 162/200. Took 0.066446 seconds. 
  Full-batch training loss = 1.063416, test loss = 1.063461
  Training set accuracy = 0.809500, Test set accuracy = 0.796700
 epoch 163/200. Took 0.062196 seconds. 
  Full-batch training loss = 1.058551, test loss = 1.058524
  Training set accuracy = 0.810000, Test set accuracy = 0.797000
 epoch 164/200. Took 0.065055 seconds. 
  Full-batch training loss = 1.053697, test loss = 1.053742
  Training set accuracy = 0.812000, Test set accuracy = 0.796800
 epoch 165/200. Took 0.070882 seconds. 
  Full-batch training loss = 1.048920, test loss = 1.049270
  Training set accuracy = 0.811000, Test set accuracy = 0.798700
 epoch 166/200. Took 0.076144 seconds. 
  Full-batch training loss = 1.044163, test loss = 1.044681
  Training set accuracy = 0.812000, Test set accuracy = 0.798100
 epoch 167/200. Took 0.062161 seconds. 
  Full-batch training loss = 1.039462, test loss = 1.039859
  Training set accuracy = 0.813000, Test set accuracy = 0.799300
 epoch 168/200. Took 0.068354 seconds. 
  Full-batch training loss = 1.034790, test loss = 1.035156
  Training set accuracy = 0.814000, Test set accuracy = 0.799100
 epoch 169/200. Took 0.058579 seconds. 
  Full-batch training loss = 1.030185, test loss = 1.030882
  Training set accuracy = 0.814500, Test set accuracy = 0.801000
 epoch 170/200. Took 0.069515 seconds. 
  Full-batch training loss = 1.025616, test loss = 1.026353
  Training set accuracy = 0.814500, Test set accuracy = 0.800000
 epoch 171/200. Took 0.069733 seconds. 
  Full-batch training loss = 1.021070, test loss = 1.021903
  Training set accuracy = 0.814500, Test set accuracy = 0.800500
 epoch 172/200. Took 0.069051 seconds. 
  Full-batch training loss = 1.016589, test loss = 1.017406
  Training set accuracy = 0.814000, Test set accuracy = 0.800800
 epoch 173/200. Took 0.062948 seconds. 
  Full-batch training loss = 1.012130, test loss = 1.013151
  Training set accuracy = 0.815500, Test set accuracy = 0.801600
 epoch 174/200. Took 0.058457 seconds. 
  Full-batch training loss = 1.007719, test loss = 1.008767
  Training set accuracy = 0.816000, Test set accuracy = 0.802100
 epoch 175/200. Took 0.057928 seconds. 
  Full-batch training loss = 1.003365, test loss = 1.004634
  Training set accuracy = 0.816000, Test set accuracy = 0.802200
 epoch 176/200. Took 0.067662 seconds. 
  Full-batch training loss = 0.999028, test loss = 1.000301
  Training set accuracy = 0.815000, Test set accuracy = 0.803200
 epoch 177/200. Took 0.057661 seconds. 
  Full-batch training loss = 0.994716, test loss = 0.996095
  Training set accuracy = 0.815500, Test set accuracy = 0.803000
 epoch 178/200. Took 0.065109 seconds. 
  Full-batch training loss = 0.990486, test loss = 0.991972
  Training set accuracy = 0.816000, Test set accuracy = 0.803000
 epoch 179/200. Took 0.058929 seconds. 
  Full-batch training loss = 0.986262, test loss = 0.987847
  Training set accuracy = 0.815500, Test set accuracy = 0.804400
 epoch 180/200. Took 0.059282 seconds. 
  Full-batch training loss = 0.982077, test loss = 0.983771
  Training set accuracy = 0.814500, Test set accuracy = 0.804300
 epoch 181/200. Took 0.058993 seconds. 
  Full-batch training loss = 0.977960, test loss = 0.979634
  Training set accuracy = 0.815000, Test set accuracy = 0.804900
 epoch 182/200. Took 0.058745 seconds. 
  Full-batch training loss = 0.973859, test loss = 0.975828
  Training set accuracy = 0.816500, Test set accuracy = 0.805400
 epoch 183/200. Took 0.06793 seconds. 
  Full-batch training loss = 0.969807, test loss = 0.971791
  Training set accuracy = 0.816500, Test set accuracy = 0.806000
 epoch 184/200. Took 0.059646 seconds. 
  Full-batch training loss = 0.965753, test loss = 0.967988
  Training set accuracy = 0.816000, Test set accuracy = 0.805800
 epoch 185/200. Took 0.059628 seconds. 
  Full-batch training loss = 0.961792, test loss = 0.964078
  Training set accuracy = 0.816000, Test set accuracy = 0.805600
 epoch 186/200. Took 0.067495 seconds. 
  Full-batch training loss = 0.957861, test loss = 0.960128
  Training set accuracy = 0.814500, Test set accuracy = 0.806700
 epoch 187/200. Took 0.067902 seconds. 
  Full-batch training loss = 0.953926, test loss = 0.956486
  Training set accuracy = 0.816500, Test set accuracy = 0.807100
 epoch 188/200. Took 0.072439 seconds. 
  Full-batch training loss = 0.950037, test loss = 0.952459
  Training set accuracy = 0.815000, Test set accuracy = 0.807900
 epoch 189/200. Took 0.066495 seconds. 
  Full-batch training loss = 0.946186, test loss = 0.948653
  Training set accuracy = 0.817000, Test set accuracy = 0.809400
 epoch 190/200. Took 0.065671 seconds. 
  Full-batch training loss = 0.942388, test loss = 0.945229
  Training set accuracy = 0.817500, Test set accuracy = 0.808200
 epoch 191/200. Took 0.067979 seconds. 
  Full-batch training loss = 0.938624, test loss = 0.941307
  Training set accuracy = 0.816000, Test set accuracy = 0.810700
 epoch 192/200. Took 0.058809 seconds. 
  Full-batch training loss = 0.934865, test loss = 0.937795
  Training set accuracy = 0.817500, Test set accuracy = 0.810900
 epoch 193/200. Took 0.063898 seconds. 
  Full-batch training loss = 0.931170, test loss = 0.934350
  Training set accuracy = 0.818500, Test set accuracy = 0.810300
 epoch 194/200. Took 0.069674 seconds. 
  Full-batch training loss = 0.927504, test loss = 0.930721
  Training set accuracy = 0.817500, Test set accuracy = 0.810800
 epoch 195/200. Took 0.064184 seconds. 
  Full-batch training loss = 0.923845, test loss = 0.927118
  Training set accuracy = 0.819500, Test set accuracy = 0.811300
 epoch 196/200. Took 0.068441 seconds. 
  Full-batch training loss = 0.920253, test loss = 0.923821
  Training set accuracy = 0.817000, Test set accuracy = 0.811700
 epoch 197/200. Took 0.06656 seconds. 
  Full-batch training loss = 0.916651, test loss = 0.920062
  Training set accuracy = 0.820500, Test set accuracy = 0.813100
 epoch 198/200. Took 0.064024 seconds. 
  Full-batch training loss = 0.913110, test loss = 0.916697
  Training set accuracy = 0.820000, Test set accuracy = 0.812300
 epoch 199/200. Took 0.057116 seconds. 
  Full-batch training loss = 0.909597, test loss = 0.913253
  Training set accuracy = 0.822000, Test set accuracy = 0.814400
 epoch 200/200. Took 0.061369 seconds. 
  Full-batch training loss = 0.906124, test loss = 0.909789
  Training set accuracy = 0.822000, Test set accuracy = 0.814600
Elapsed time is 54.242689 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (500)
Training NN  (784  500   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.13917 seconds. 
  Full-batch training loss = 1.723332, test loss = 1.723081
  Training set accuracy = 0.441500, Test set accuracy = 0.455600
 epoch 2/200. Took 0.13133 seconds. 
  Full-batch training loss = 0.967883, test loss = 0.982613
  Training set accuracy = 0.660500, Test set accuracy = 0.648300
 epoch 3/200. Took 0.13168 seconds. 
  Full-batch training loss = 0.707024, test loss = 0.735887
  Training set accuracy = 0.783500, Test set accuracy = 0.775000
 epoch 4/200. Took 0.11234 seconds. 
  Full-batch training loss = 0.521076, test loss = 0.549073
  Training set accuracy = 0.867500, Test set accuracy = 0.851100
 epoch 5/200. Took 0.11757 seconds. 
  Full-batch training loss = 0.448590, test loss = 0.491255
  Training set accuracy = 0.889000, Test set accuracy = 0.867000
 epoch 6/200. Took 0.11399 seconds. 
  Full-batch training loss = 0.463651, test loss = 0.519780
  Training set accuracy = 0.860500, Test set accuracy = 0.834800
 epoch 7/200. Took 0.11314 seconds. 
  Full-batch training loss = 0.381560, test loss = 0.442215
  Training set accuracy = 0.894500, Test set accuracy = 0.868200
 epoch 8/200. Took 0.11459 seconds. 
  Full-batch training loss = 0.357059, test loss = 0.422508
  Training set accuracy = 0.900500, Test set accuracy = 0.869300
 epoch 9/200. Took 0.11716 seconds. 
  Full-batch training loss = 0.319178, test loss = 0.397518
  Training set accuracy = 0.908500, Test set accuracy = 0.878400
 epoch 10/200. Took 0.11451 seconds. 
  Full-batch training loss = 0.307090, test loss = 0.389469
  Training set accuracy = 0.918000, Test set accuracy = 0.884500
 epoch 11/200. Took 0.11342 seconds. 
  Full-batch training loss = 0.338226, test loss = 0.432105
  Training set accuracy = 0.898000, Test set accuracy = 0.868100
 epoch 12/200. Took 0.11295 seconds. 
  Full-batch training loss = 0.293567, test loss = 0.392925
  Training set accuracy = 0.915000, Test set accuracy = 0.877500
 epoch 13/200. Took 0.11349 seconds. 
  Full-batch training loss = 0.303832, test loss = 0.412338
  Training set accuracy = 0.906500, Test set accuracy = 0.874500
 epoch 14/200. Took 0.12843 seconds. 
  Full-batch training loss = 0.273673, test loss = 0.391009
  Training set accuracy = 0.923000, Test set accuracy = 0.883700
 epoch 15/200. Took 0.11505 seconds. 
  Full-batch training loss = 0.246717, test loss = 0.370740
  Training set accuracy = 0.937000, Test set accuracy = 0.887600
 epoch 16/200. Took 0.13686 seconds. 
  Full-batch training loss = 0.242815, test loss = 0.377275
  Training set accuracy = 0.933500, Test set accuracy = 0.884500
 epoch 17/200. Took 0.11358 seconds. 
  Full-batch training loss = 0.228682, test loss = 0.364489
  Training set accuracy = 0.940000, Test set accuracy = 0.888600
 epoch 18/200. Took 0.11401 seconds. 
  Full-batch training loss = 0.232049, test loss = 0.377472
  Training set accuracy = 0.935000, Test set accuracy = 0.883300
 epoch 19/200. Took 0.13806 seconds. 
  Full-batch training loss = 0.222317, test loss = 0.367809
  Training set accuracy = 0.940500, Test set accuracy = 0.885300
 epoch 20/200. Took 0.1118 seconds. 
  Full-batch training loss = 0.210758, test loss = 0.366673
  Training set accuracy = 0.940500, Test set accuracy = 0.888700
 epoch 21/200. Took 0.11206 seconds. 
  Full-batch training loss = 0.197546, test loss = 0.360713
  Training set accuracy = 0.950500, Test set accuracy = 0.891700
 epoch 22/200. Took 0.11324 seconds. 
  Full-batch training loss = 0.196145, test loss = 0.360784
  Training set accuracy = 0.949500, Test set accuracy = 0.890600
 epoch 23/200. Took 0.15025 seconds. 
  Full-batch training loss = 0.189040, test loss = 0.361143
  Training set accuracy = 0.948500, Test set accuracy = 0.887500
 epoch 24/200. Took 0.1199 seconds. 
  Full-batch training loss = 0.182564, test loss = 0.361021
  Training set accuracy = 0.951500, Test set accuracy = 0.890100
 epoch 25/200. Took 0.11983 seconds. 
  Full-batch training loss = 0.185971, test loss = 0.371282
  Training set accuracy = 0.950500, Test set accuracy = 0.886800
 epoch 26/200. Took 0.11395 seconds. 
  Full-batch training loss = 0.173606, test loss = 0.360076
  Training set accuracy = 0.957000, Test set accuracy = 0.892100
 epoch 27/200. Took 0.11426 seconds. 
  Full-batch training loss = 0.168098, test loss = 0.361507
  Training set accuracy = 0.958000, Test set accuracy = 0.889600
 epoch 28/200. Took 0.14948 seconds. 
  Full-batch training loss = 0.175040, test loss = 0.379946
  Training set accuracy = 0.957000, Test set accuracy = 0.886300
 epoch 29/200. Took 0.11935 seconds. 
  Full-batch training loss = 0.159079, test loss = 0.365820
  Training set accuracy = 0.961500, Test set accuracy = 0.893000
 epoch 30/200. Took 0.1146 seconds. 
  Full-batch training loss = 0.161096, test loss = 0.372275
  Training set accuracy = 0.958000, Test set accuracy = 0.884800
 epoch 31/200. Took 0.13586 seconds. 
  Full-batch training loss = 0.149252, test loss = 0.364614
  Training set accuracy = 0.968000, Test set accuracy = 0.891500
 epoch 32/200. Took 0.1285 seconds. 
  Full-batch training loss = 0.149828, test loss = 0.371344
  Training set accuracy = 0.964500, Test set accuracy = 0.890900
 epoch 33/200. Took 0.12638 seconds. 
  Full-batch training loss = 0.144337, test loss = 0.366333
  Training set accuracy = 0.960500, Test set accuracy = 0.891200
 epoch 34/200. Took 0.13035 seconds. 
  Full-batch training loss = 0.140554, test loss = 0.366303
  Training set accuracy = 0.966000, Test set accuracy = 0.892500
 epoch 35/200. Took 0.11268 seconds. 
  Full-batch training loss = 0.134631, test loss = 0.367611
  Training set accuracy = 0.968500, Test set accuracy = 0.889700
 epoch 36/200. Took 0.11284 seconds. 
  Full-batch training loss = 0.135020, test loss = 0.375160
  Training set accuracy = 0.968500, Test set accuracy = 0.891700
 epoch 37/200. Took 0.12392 seconds. 
  Full-batch training loss = 0.125109, test loss = 0.368323
  Training set accuracy = 0.972500, Test set accuracy = 0.891800
 epoch 38/200. Took 0.13856 seconds. 
  Full-batch training loss = 0.120802, test loss = 0.369156
  Training set accuracy = 0.975500, Test set accuracy = 0.892100
 epoch 39/200. Took 0.13969 seconds. 
  Full-batch training loss = 0.122934, test loss = 0.375920
  Training set accuracy = 0.970500, Test set accuracy = 0.890100
 epoch 40/200. Took 0.11248 seconds. 
  Full-batch training loss = 0.117710, test loss = 0.372407
  Training set accuracy = 0.976500, Test set accuracy = 0.893900
 epoch 41/200. Took 0.13505 seconds. 
  Full-batch training loss = 0.118230, test loss = 0.376613
  Training set accuracy = 0.973000, Test set accuracy = 0.892200
 epoch 42/200. Took 0.11189 seconds. 
  Full-batch training loss = 0.109438, test loss = 0.372944
  Training set accuracy = 0.975500, Test set accuracy = 0.891200
 epoch 43/200. Took 0.13734 seconds. 
  Full-batch training loss = 0.114251, test loss = 0.377779
  Training set accuracy = 0.973500, Test set accuracy = 0.887400
 epoch 44/200. Took 0.11318 seconds. 
  Full-batch training loss = 0.109481, test loss = 0.381647
  Training set accuracy = 0.972000, Test set accuracy = 0.889500
 epoch 45/200. Took 0.13481 seconds. 
  Full-batch training loss = 0.109186, test loss = 0.387430
  Training set accuracy = 0.974500, Test set accuracy = 0.888700
 epoch 46/200. Took 0.11511 seconds. 
  Full-batch training loss = 0.098667, test loss = 0.378456
  Training set accuracy = 0.978500, Test set accuracy = 0.891900
 epoch 47/200. Took 0.1352 seconds. 
  Full-batch training loss = 0.100051, test loss = 0.388850
  Training set accuracy = 0.980500, Test set accuracy = 0.887600
 epoch 48/200. Took 0.11314 seconds. 
  Full-batch training loss = 0.095796, test loss = 0.386947
  Training set accuracy = 0.980500, Test set accuracy = 0.888600
 epoch 49/200. Took 0.1265 seconds. 
  Full-batch training loss = 0.094685, test loss = 0.384172
  Training set accuracy = 0.984000, Test set accuracy = 0.891000
 epoch 50/200. Took 0.11274 seconds. 
  Full-batch training loss = 0.097370, test loss = 0.398362
  Training set accuracy = 0.974500, Test set accuracy = 0.885700
 epoch 51/200. Took 0.13682 seconds. 
  Full-batch training loss = 0.090908, test loss = 0.396347
  Training set accuracy = 0.981500, Test set accuracy = 0.887700
 epoch 52/200. Took 0.11397 seconds. 
  Full-batch training loss = 0.084116, test loss = 0.390865
  Training set accuracy = 0.985000, Test set accuracy = 0.888600
 epoch 53/200. Took 0.11824 seconds. 
  Full-batch training loss = 0.088541, test loss = 0.403311
  Training set accuracy = 0.982000, Test set accuracy = 0.885900
 epoch 54/200. Took 0.12434 seconds. 
  Full-batch training loss = 0.080502, test loss = 0.392684
  Training set accuracy = 0.986500, Test set accuracy = 0.888300
 epoch 55/200. Took 0.11191 seconds. 
  Full-batch training loss = 0.077569, test loss = 0.388184
  Training set accuracy = 0.988500, Test set accuracy = 0.889900
 epoch 56/200. Took 0.13976 seconds. 
  Full-batch training loss = 0.076213, test loss = 0.393405
  Training set accuracy = 0.987500, Test set accuracy = 0.888700
 epoch 57/200. Took 0.11562 seconds. 
  Full-batch training loss = 0.073069, test loss = 0.392065
  Training set accuracy = 0.990000, Test set accuracy = 0.891200
 epoch 58/200. Took 0.1311 seconds. 
  Full-batch training loss = 0.072104, test loss = 0.395359
  Training set accuracy = 0.989000, Test set accuracy = 0.889600
 epoch 59/200. Took 0.11393 seconds. 
  Full-batch training loss = 0.073872, test loss = 0.406332
  Training set accuracy = 0.987500, Test set accuracy = 0.887100
 epoch 60/200. Took 0.11472 seconds. 
  Full-batch training loss = 0.068661, test loss = 0.402204
  Training set accuracy = 0.990000, Test set accuracy = 0.888900
 epoch 61/200. Took 0.13251 seconds. 
  Full-batch training loss = 0.067071, test loss = 0.402479
  Training set accuracy = 0.992000, Test set accuracy = 0.887100
 epoch 62/200. Took 0.12497 seconds. 
  Full-batch training loss = 0.064698, test loss = 0.405164
  Training set accuracy = 0.991000, Test set accuracy = 0.885700
 epoch 63/200. Took 0.11918 seconds. 
  Full-batch training loss = 0.064270, test loss = 0.404533
  Training set accuracy = 0.989500, Test set accuracy = 0.887800
 epoch 64/200. Took 0.11486 seconds. 
  Full-batch training loss = 0.064497, test loss = 0.409324
  Training set accuracy = 0.991500, Test set accuracy = 0.887500
 epoch 65/200. Took 0.11346 seconds. 
  Full-batch training loss = 0.060370, test loss = 0.408014
  Training set accuracy = 0.993500, Test set accuracy = 0.891000
 epoch 66/200. Took 0.1352 seconds. 
  Full-batch training loss = 0.058956, test loss = 0.409266
  Training set accuracy = 0.994000, Test set accuracy = 0.889900
 epoch 67/200. Took 0.13403 seconds. 
  Full-batch training loss = 0.055242, test loss = 0.404880
  Training set accuracy = 0.995000, Test set accuracy = 0.889300
 epoch 68/200. Took 0.12171 seconds. 
  Full-batch training loss = 0.056181, test loss = 0.409040
  Training set accuracy = 0.996500, Test set accuracy = 0.886100
 epoch 69/200. Took 0.11372 seconds. 
  Full-batch training loss = 0.053448, test loss = 0.409276
  Training set accuracy = 0.996500, Test set accuracy = 0.889400
 epoch 70/200. Took 0.13546 seconds. 
  Full-batch training loss = 0.054298, test loss = 0.413115
  Training set accuracy = 0.995000, Test set accuracy = 0.887000
 epoch 71/200. Took 0.12448 seconds. 
  Full-batch training loss = 0.050660, test loss = 0.409485
  Training set accuracy = 0.997000, Test set accuracy = 0.888500
 epoch 72/200. Took 0.12192 seconds. 
  Full-batch training loss = 0.054250, test loss = 0.416590
  Training set accuracy = 0.995500, Test set accuracy = 0.886300
 epoch 73/200. Took 0.13745 seconds. 
  Full-batch training loss = 0.048060, test loss = 0.415022
  Training set accuracy = 0.996000, Test set accuracy = 0.888100
 epoch 74/200. Took 0.11264 seconds. 
  Full-batch training loss = 0.046201, test loss = 0.413295
  Training set accuracy = 0.997500, Test set accuracy = 0.888600
 epoch 75/200. Took 0.13537 seconds. 
  Full-batch training loss = 0.045198, test loss = 0.413334
  Training set accuracy = 0.997500, Test set accuracy = 0.890100
 epoch 76/200. Took 0.11331 seconds. 
  Full-batch training loss = 0.044305, test loss = 0.417185
  Training set accuracy = 0.998000, Test set accuracy = 0.887600
 epoch 77/200. Took 0.11781 seconds. 
  Full-batch training loss = 0.044304, test loss = 0.419921
  Training set accuracy = 0.997500, Test set accuracy = 0.887900
 epoch 78/200. Took 0.13461 seconds. 
  Full-batch training loss = 0.041964, test loss = 0.419429
  Training set accuracy = 0.997500, Test set accuracy = 0.888200
 epoch 79/200. Took 0.11029 seconds. 
  Full-batch training loss = 0.042017, test loss = 0.420373
  Training set accuracy = 0.998000, Test set accuracy = 0.890000
 epoch 80/200. Took 0.13762 seconds. 
  Full-batch training loss = 0.039862, test loss = 0.422321
  Training set accuracy = 0.998500, Test set accuracy = 0.889000
 epoch 81/200. Took 0.11363 seconds. 
  Full-batch training loss = 0.039556, test loss = 0.423349
  Training set accuracy = 0.999000, Test set accuracy = 0.889400
 epoch 82/200. Took 0.11841 seconds. 
  Full-batch training loss = 0.040832, test loss = 0.424170
  Training set accuracy = 0.996500, Test set accuracy = 0.887300
 epoch 83/200. Took 0.11318 seconds. 
  Full-batch training loss = 0.038587, test loss = 0.424827
  Training set accuracy = 0.998500, Test set accuracy = 0.887700
 epoch 84/200. Took 0.12967 seconds. 
  Full-batch training loss = 0.036748, test loss = 0.427763
  Training set accuracy = 1.000000, Test set accuracy = 0.889700
 epoch 85/200. Took 0.11357 seconds. 
  Full-batch training loss = 0.036289, test loss = 0.429740
  Training set accuracy = 0.999500, Test set accuracy = 0.887500
 epoch 86/200. Took 0.1358 seconds. 
  Full-batch training loss = 0.035971, test loss = 0.427388
  Training set accuracy = 0.999000, Test set accuracy = 0.888900
 epoch 87/200. Took 0.14087 seconds. 
  Full-batch training loss = 0.037322, test loss = 0.432913
  Training set accuracy = 0.998000, Test set accuracy = 0.888100
 epoch 88/200. Took 0.1141 seconds. 
  Full-batch training loss = 0.034152, test loss = 0.433936
  Training set accuracy = 1.000000, Test set accuracy = 0.886900
 epoch 89/200. Took 0.11162 seconds. 
  Full-batch training loss = 0.033005, test loss = 0.431071
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 90/200. Took 0.11884 seconds. 
  Full-batch training loss = 0.032878, test loss = 0.430231
  Training set accuracy = 0.999500, Test set accuracy = 0.888400
 epoch 91/200. Took 0.13816 seconds. 
  Full-batch training loss = 0.032383, test loss = 0.435563
  Training set accuracy = 1.000000, Test set accuracy = 0.889500
 epoch 92/200. Took 0.13825 seconds. 
  Full-batch training loss = 0.031694, test loss = 0.434663
  Training set accuracy = 0.999500, Test set accuracy = 0.889400
 epoch 93/200. Took 0.14524 seconds. 
  Full-batch training loss = 0.031669, test loss = 0.438622
  Training set accuracy = 1.000000, Test set accuracy = 0.887600
 epoch 94/200. Took 0.11345 seconds. 
  Full-batch training loss = 0.030218, test loss = 0.437664
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 95/200. Took 0.11292 seconds. 
  Full-batch training loss = 0.030440, test loss = 0.439679
  Training set accuracy = 0.999500, Test set accuracy = 0.887600
 epoch 96/200. Took 0.11158 seconds. 
  Full-batch training loss = 0.029208, test loss = 0.439319
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 97/200. Took 0.12009 seconds. 
  Full-batch training loss = 0.028714, test loss = 0.440089
  Training set accuracy = 1.000000, Test set accuracy = 0.889600
 epoch 98/200. Took 0.12793 seconds. 
  Full-batch training loss = 0.028011, test loss = 0.439791
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 99/200. Took 0.13478 seconds. 
  Full-batch training loss = 0.027988, test loss = 0.447141
  Training set accuracy = 1.000000, Test set accuracy = 0.887800
 epoch 100/200. Took 0.11139 seconds. 
  Full-batch training loss = 0.027150, test loss = 0.443768
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 101/200. Took 0.1138 seconds. 
  Full-batch training loss = 0.026039, test loss = 0.446185
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 102/200. Took 0.13867 seconds. 
  Full-batch training loss = 0.026943, test loss = 0.448741
  Training set accuracy = 1.000000, Test set accuracy = 0.887200
 epoch 103/200. Took 0.13889 seconds. 
  Full-batch training loss = 0.025999, test loss = 0.448333
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 104/200. Took 0.11365 seconds. 
  Full-batch training loss = 0.024772, test loss = 0.449311
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 105/200. Took 0.11887 seconds. 
  Full-batch training loss = 0.024876, test loss = 0.451111
  Training set accuracy = 1.000000, Test set accuracy = 0.890200
 epoch 106/200. Took 0.1329 seconds. 
  Full-batch training loss = 0.024785, test loss = 0.449516
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 107/200. Took 0.13203 seconds. 
  Full-batch training loss = 0.023530, test loss = 0.449065
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 108/200. Took 0.1141 seconds. 
  Full-batch training loss = 0.023248, test loss = 0.452041
  Training set accuracy = 1.000000, Test set accuracy = 0.888100
 epoch 109/200. Took 0.12669 seconds. 
  Full-batch training loss = 0.022692, test loss = 0.453198
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 110/200. Took 0.11392 seconds. 
  Full-batch training loss = 0.022428, test loss = 0.454651
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 111/200. Took 0.11242 seconds. 
  Full-batch training loss = 0.022381, test loss = 0.455468
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 112/200. Took 0.11367 seconds. 
  Full-batch training loss = 0.021932, test loss = 0.456374
  Training set accuracy = 1.000000, Test set accuracy = 0.889200
 epoch 113/200. Took 0.13449 seconds. 
  Full-batch training loss = 0.021767, test loss = 0.457126
  Training set accuracy = 1.000000, Test set accuracy = 0.889200
 epoch 114/200. Took 0.13578 seconds. 
  Full-batch training loss = 0.021926, test loss = 0.461289
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 115/200. Took 0.13599 seconds. 
  Full-batch training loss = 0.020786, test loss = 0.456169
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 116/200. Took 0.11534 seconds. 
  Full-batch training loss = 0.020391, test loss = 0.459915
  Training set accuracy = 1.000000, Test set accuracy = 0.889200
 epoch 117/200. Took 0.11597 seconds. 
  Full-batch training loss = 0.020196, test loss = 0.460317
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 118/200. Took 0.11482 seconds. 
  Full-batch training loss = 0.019975, test loss = 0.462789
  Training set accuracy = 1.000000, Test set accuracy = 0.888100
 epoch 119/200. Took 0.11372 seconds. 
  Full-batch training loss = 0.019458, test loss = 0.460225
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 120/200. Took 0.11282 seconds. 
  Full-batch training loss = 0.019677, test loss = 0.465709
  Training set accuracy = 1.000000, Test set accuracy = 0.887600
 epoch 121/200. Took 0.13584 seconds. 
  Full-batch training loss = 0.019080, test loss = 0.464891
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 122/200. Took 0.12013 seconds. 
  Full-batch training loss = 0.019194, test loss = 0.465739
  Training set accuracy = 1.000000, Test set accuracy = 0.887600
 epoch 123/200. Took 0.11659 seconds. 
  Full-batch training loss = 0.018542, test loss = 0.466308
  Training set accuracy = 1.000000, Test set accuracy = 0.887800
 epoch 124/200. Took 0.12608 seconds. 
  Full-batch training loss = 0.018763, test loss = 0.467242
  Training set accuracy = 1.000000, Test set accuracy = 0.887700
 epoch 125/200. Took 0.11456 seconds. 
  Full-batch training loss = 0.018522, test loss = 0.469286
  Training set accuracy = 1.000000, Test set accuracy = 0.887900
 epoch 126/200. Took 0.13009 seconds. 
  Full-batch training loss = 0.017628, test loss = 0.467170
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 127/200. Took 0.11193 seconds. 
  Full-batch training loss = 0.017614, test loss = 0.467922
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 128/200. Took 0.11366 seconds. 
  Full-batch training loss = 0.017182, test loss = 0.468822
  Training set accuracy = 1.000000, Test set accuracy = 0.887100
 epoch 129/200. Took 0.13645 seconds. 
  Full-batch training loss = 0.017419, test loss = 0.472725
  Training set accuracy = 1.000000, Test set accuracy = 0.889800
 epoch 130/200. Took 0.13786 seconds. 
  Full-batch training loss = 0.016739, test loss = 0.469728
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 131/200. Took 0.12523 seconds. 
  Full-batch training loss = 0.016898, test loss = 0.472706
  Training set accuracy = 1.000000, Test set accuracy = 0.888800
 epoch 132/200. Took 0.13676 seconds. 
  Full-batch training loss = 0.016205, test loss = 0.471730
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 133/200. Took 0.11845 seconds. 
  Full-batch training loss = 0.016029, test loss = 0.472226
  Training set accuracy = 1.000000, Test set accuracy = 0.887600
 epoch 134/200. Took 0.13749 seconds. 
  Full-batch training loss = 0.016160, test loss = 0.474406
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 135/200. Took 0.1136 seconds. 
  Full-batch training loss = 0.015846, test loss = 0.476339
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 136/200. Took 0.11664 seconds. 
  Full-batch training loss = 0.015475, test loss = 0.474715
  Training set accuracy = 1.000000, Test set accuracy = 0.887300
 epoch 137/200. Took 0.11244 seconds. 
  Full-batch training loss = 0.015456, test loss = 0.477740
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 138/200. Took 0.13493 seconds. 
  Full-batch training loss = 0.015209, test loss = 0.476200
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 139/200. Took 0.12546 seconds. 
  Full-batch training loss = 0.014901, test loss = 0.478298
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 140/200. Took 0.12451 seconds. 
  Full-batch training loss = 0.014596, test loss = 0.478223
  Training set accuracy = 1.000000, Test set accuracy = 0.888700
 epoch 141/200. Took 0.11955 seconds. 
  Full-batch training loss = 0.014563, test loss = 0.477782
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 142/200. Took 0.11422 seconds. 
  Full-batch training loss = 0.014306, test loss = 0.479565
  Training set accuracy = 1.000000, Test set accuracy = 0.888100
 epoch 143/200. Took 0.1377 seconds. 
  Full-batch training loss = 0.014151, test loss = 0.480154
  Training set accuracy = 1.000000, Test set accuracy = 0.887900
 epoch 144/200. Took 0.11944 seconds. 
  Full-batch training loss = 0.013974, test loss = 0.479875
  Training set accuracy = 1.000000, Test set accuracy = 0.889400
 epoch 145/200. Took 0.13687 seconds. 
  Full-batch training loss = 0.013905, test loss = 0.481198
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 146/200. Took 0.14029 seconds. 
  Full-batch training loss = 0.013899, test loss = 0.484634
  Training set accuracy = 1.000000, Test set accuracy = 0.889000
 epoch 147/200. Took 0.11472 seconds. 
  Full-batch training loss = 0.013770, test loss = 0.483225
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 148/200. Took 0.12823 seconds. 
  Full-batch training loss = 0.013290, test loss = 0.483683
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 149/200. Took 0.1149 seconds. 
  Full-batch training loss = 0.013208, test loss = 0.484499
  Training set accuracy = 1.000000, Test set accuracy = 0.887800
 epoch 150/200. Took 0.11355 seconds. 
  Full-batch training loss = 0.013193, test loss = 0.486993
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 151/200. Took 0.13518 seconds. 
  Full-batch training loss = 0.012890, test loss = 0.484697
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 152/200. Took 0.11252 seconds. 
  Full-batch training loss = 0.012728, test loss = 0.486622
  Training set accuracy = 1.000000, Test set accuracy = 0.888800
 epoch 153/200. Took 0.13471 seconds. 
  Full-batch training loss = 0.012634, test loss = 0.487008
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 154/200. Took 0.13759 seconds. 
  Full-batch training loss = 0.012434, test loss = 0.487217
  Training set accuracy = 1.000000, Test set accuracy = 0.889500
 epoch 155/200. Took 0.11122 seconds. 
  Full-batch training loss = 0.012338, test loss = 0.486942
  Training set accuracy = 1.000000, Test set accuracy = 0.887600
 epoch 156/200. Took 0.1329 seconds. 
  Full-batch training loss = 0.012246, test loss = 0.488299
  Training set accuracy = 1.000000, Test set accuracy = 0.888000
 epoch 157/200. Took 0.13495 seconds. 
  Full-batch training loss = 0.012060, test loss = 0.488784
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 158/200. Took 0.13505 seconds. 
  Full-batch training loss = 0.012134, test loss = 0.491177
  Training set accuracy = 1.000000, Test set accuracy = 0.888800
 epoch 159/200. Took 0.13872 seconds. 
  Full-batch training loss = 0.012032, test loss = 0.489606
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 160/200. Took 0.12018 seconds. 
  Full-batch training loss = 0.011803, test loss = 0.492286
  Training set accuracy = 1.000000, Test set accuracy = 0.888800
 epoch 161/200. Took 0.14016 seconds. 
  Full-batch training loss = 0.011551, test loss = 0.491596
  Training set accuracy = 1.000000, Test set accuracy = 0.887900
 epoch 162/200. Took 0.12364 seconds. 
  Full-batch training loss = 0.011475, test loss = 0.492049
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 163/200. Took 0.11011 seconds. 
  Full-batch training loss = 0.011356, test loss = 0.492199
  Training set accuracy = 1.000000, Test set accuracy = 0.888800
 epoch 164/200. Took 0.11351 seconds. 
  Full-batch training loss = 0.011220, test loss = 0.493884
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 165/200. Took 0.11788 seconds. 
  Full-batch training loss = 0.011130, test loss = 0.493176
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 166/200. Took 0.11408 seconds. 
  Full-batch training loss = 0.010962, test loss = 0.494361
  Training set accuracy = 1.000000, Test set accuracy = 0.888700
 epoch 167/200. Took 0.13482 seconds. 
  Full-batch training loss = 0.010969, test loss = 0.494746
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 168/200. Took 0.11313 seconds. 
  Full-batch training loss = 0.010859, test loss = 0.496362
  Training set accuracy = 1.000000, Test set accuracy = 0.889200
 epoch 169/200. Took 0.13017 seconds. 
  Full-batch training loss = 0.010709, test loss = 0.496582
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 170/200. Took 0.12856 seconds. 
  Full-batch training loss = 0.010641, test loss = 0.496465
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 171/200. Took 0.13466 seconds. 
  Full-batch training loss = 0.010513, test loss = 0.497716
  Training set accuracy = 1.000000, Test set accuracy = 0.889100
 epoch 172/200. Took 0.1271 seconds. 
  Full-batch training loss = 0.010425, test loss = 0.498209
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 173/200. Took 0.11146 seconds. 
  Full-batch training loss = 0.010272, test loss = 0.498396
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 174/200. Took 0.12095 seconds. 
  Full-batch training loss = 0.010222, test loss = 0.500710
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 175/200. Took 0.14084 seconds. 
  Full-batch training loss = 0.010099, test loss = 0.499811
  Training set accuracy = 1.000000, Test set accuracy = 0.889100
 epoch 176/200. Took 0.13576 seconds. 
  Full-batch training loss = 0.010047, test loss = 0.499909
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 177/200. Took 0.14057 seconds. 
  Full-batch training loss = 0.009945, test loss = 0.501711
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 178/200. Took 0.13738 seconds. 
  Full-batch training loss = 0.009998, test loss = 0.502874
  Training set accuracy = 1.000000, Test set accuracy = 0.888100
 epoch 179/200. Took 0.11436 seconds. 
  Full-batch training loss = 0.009813, test loss = 0.501810
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 180/200. Took 0.11221 seconds. 
  Full-batch training loss = 0.009628, test loss = 0.501958
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 181/200. Took 0.12479 seconds. 
  Full-batch training loss = 0.009593, test loss = 0.503287
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 182/200. Took 0.12751 seconds. 
  Full-batch training loss = 0.009559, test loss = 0.504046
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 183/200. Took 0.11306 seconds. 
  Full-batch training loss = 0.009391, test loss = 0.503345
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 184/200. Took 0.11653 seconds. 
  Full-batch training loss = 0.009383, test loss = 0.504990
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 185/200. Took 0.12271 seconds. 
  Full-batch training loss = 0.009206, test loss = 0.505072
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 186/200. Took 0.12141 seconds. 
  Full-batch training loss = 0.009167, test loss = 0.505516
  Training set accuracy = 1.000000, Test set accuracy = 0.888700
 epoch 187/200. Took 0.11156 seconds. 
  Full-batch training loss = 0.009199, test loss = 0.507486
  Training set accuracy = 1.000000, Test set accuracy = 0.888500
 epoch 188/200. Took 0.13453 seconds. 
  Full-batch training loss = 0.009025, test loss = 0.506386
  Training set accuracy = 1.000000, Test set accuracy = 0.889100
 epoch 189/200. Took 0.11536 seconds. 
  Full-batch training loss = 0.008922, test loss = 0.506859
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 190/200. Took 0.13987 seconds. 
  Full-batch training loss = 0.008900, test loss = 0.508454
  Training set accuracy = 1.000000, Test set accuracy = 0.888700
 epoch 191/200. Took 0.11055 seconds. 
  Full-batch training loss = 0.008745, test loss = 0.508085
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 192/200. Took 0.11135 seconds. 
  Full-batch training loss = 0.008700, test loss = 0.509282
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 193/200. Took 0.13596 seconds. 
  Full-batch training loss = 0.008637, test loss = 0.509287
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
 epoch 194/200. Took 0.11472 seconds. 
  Full-batch training loss = 0.008557, test loss = 0.510127
  Training set accuracy = 1.000000, Test set accuracy = 0.888700
 epoch 195/200. Took 0.12864 seconds. 
  Full-batch training loss = 0.008468, test loss = 0.509523
  Training set accuracy = 1.000000, Test set accuracy = 0.888400
 epoch 196/200. Took 0.11319 seconds. 
  Full-batch training loss = 0.008444, test loss = 0.510987
  Training set accuracy = 1.000000, Test set accuracy = 0.888200
 epoch 197/200. Took 0.11286 seconds. 
  Full-batch training loss = 0.008343, test loss = 0.510887
  Training set accuracy = 1.000000, Test set accuracy = 0.888300
 epoch 198/200. Took 0.11122 seconds. 
  Full-batch training loss = 0.008348, test loss = 0.512437
  Training set accuracy = 1.000000, Test set accuracy = 0.888900
 epoch 199/200. Took 0.11771 seconds. 
  Full-batch training loss = 0.008238, test loss = 0.511745
  Training set accuracy = 1.000000, Test set accuracy = 0.888100
 epoch 200/200. Took 0.13476 seconds. 
  Full-batch training loss = 0.008146, test loss = 0.512298
  Training set accuracy = 1.000000, Test set accuracy = 0.888600
Elapsed time is 105.764798 seconds.
End Training
$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 500	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (500)
Training NN  (784  500   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.12569 seconds. 
  Full-batch training loss = 2.234421, test loss = 2.236213
  Training set accuracy = 0.219500, Test set accuracy = 0.217100
 epoch 2/200. Took 0.12522 seconds. 
  Full-batch training loss = 2.133910, test loss = 2.131429
  Training set accuracy = 0.405000, Test set accuracy = 0.411700
 epoch 3/200. Took 0.11077 seconds. 
  Full-batch training loss = 2.030675, test loss = 2.030359
  Training set accuracy = 0.454500, Test set accuracy = 0.467000
 epoch 4/200. Took 0.13258 seconds. 
  Full-batch training loss = 1.926205, test loss = 1.923307
  Training set accuracy = 0.668000, Test set accuracy = 0.669500
 epoch 5/200. Took 0.11193 seconds. 
  Full-batch training loss = 1.823886, test loss = 1.823608
  Training set accuracy = 0.622000, Test set accuracy = 0.608900
 epoch 6/200. Took 0.11585 seconds. 
  Full-batch training loss = 1.723329, test loss = 1.724815
  Training set accuracy = 0.684000, Test set accuracy = 0.674100
 epoch 7/200. Took 0.13429 seconds. 
  Full-batch training loss = 1.634294, test loss = 1.630658
  Training set accuracy = 0.698000, Test set accuracy = 0.691700
 epoch 8/200. Took 0.11229 seconds. 
  Full-batch training loss = 1.535598, test loss = 1.541143
  Training set accuracy = 0.692500, Test set accuracy = 0.675500
 epoch 9/200. Took 0.11164 seconds. 
  Full-batch training loss = 1.436756, test loss = 1.432492
  Training set accuracy = 0.771500, Test set accuracy = 0.767000
 epoch 10/200. Took 0.12436 seconds. 
  Full-batch training loss = 1.353926, test loss = 1.354287
  Training set accuracy = 0.758500, Test set accuracy = 0.749300
 epoch 11/200. Took 0.11195 seconds. 
  Full-batch training loss = 1.270070, test loss = 1.267734
  Training set accuracy = 0.788500, Test set accuracy = 0.779000
 epoch 12/200. Took 0.11589 seconds. 
  Full-batch training loss = 1.206393, test loss = 1.199247
  Training set accuracy = 0.778000, Test set accuracy = 0.766900
 epoch 13/200. Took 0.11178 seconds. 
  Full-batch training loss = 1.135692, test loss = 1.136344
  Training set accuracy = 0.798500, Test set accuracy = 0.784900
 epoch 14/200. Took 0.1392 seconds. 
  Full-batch training loss = 1.075504, test loss = 1.076461
  Training set accuracy = 0.814500, Test set accuracy = 0.801000
 epoch 15/200. Took 0.12115 seconds. 
  Full-batch training loss = 1.018018, test loss = 1.020981
  Training set accuracy = 0.824500, Test set accuracy = 0.817300
 epoch 16/200. Took 0.13689 seconds. 
  Full-batch training loss = 0.973921, test loss = 0.973696
  Training set accuracy = 0.830000, Test set accuracy = 0.820400
 epoch 17/200. Took 0.12425 seconds. 
  Full-batch training loss = 0.930224, test loss = 0.935384
  Training set accuracy = 0.803000, Test set accuracy = 0.799600
 epoch 18/200. Took 0.11298 seconds. 
  Full-batch training loss = 0.889341, test loss = 0.896686
  Training set accuracy = 0.822000, Test set accuracy = 0.814100
 epoch 19/200. Took 0.12656 seconds. 
  Full-batch training loss = 0.851161, test loss = 0.855976
  Training set accuracy = 0.835500, Test set accuracy = 0.824300
 epoch 20/200. Took 0.11171 seconds. 
  Full-batch training loss = 0.824918, test loss = 0.833442
  Training set accuracy = 0.815500, Test set accuracy = 0.808000
 epoch 21/200. Took 0.11297 seconds. 
  Full-batch training loss = 0.789178, test loss = 0.800674
  Training set accuracy = 0.836000, Test set accuracy = 0.828800
 epoch 22/200. Took 0.11118 seconds. 
  Full-batch training loss = 0.768210, test loss = 0.778489
  Training set accuracy = 0.842000, Test set accuracy = 0.830200
 epoch 23/200. Took 0.11595 seconds. 
  Full-batch training loss = 0.741435, test loss = 0.748635
  Training set accuracy = 0.849500, Test set accuracy = 0.842200
 epoch 24/200. Took 0.11197 seconds. 
  Full-batch training loss = 0.713262, test loss = 0.725021
  Training set accuracy = 0.857500, Test set accuracy = 0.842000
 epoch 25/200. Took 0.11472 seconds. 
  Full-batch training loss = 0.694465, test loss = 0.705179
  Training set accuracy = 0.857000, Test set accuracy = 0.846100
 epoch 26/200. Took 0.13729 seconds. 
  Full-batch training loss = 0.674764, test loss = 0.687307
  Training set accuracy = 0.856000, Test set accuracy = 0.850100
 epoch 27/200. Took 0.13944 seconds. 
  Full-batch training loss = 0.659837, test loss = 0.677808
  Training set accuracy = 0.849000, Test set accuracy = 0.843300
 epoch 28/200. Took 0.13962 seconds. 
  Full-batch training loss = 0.642131, test loss = 0.657775
  Training set accuracy = 0.856500, Test set accuracy = 0.845000
 epoch 29/200. Took 0.11275 seconds. 
  Full-batch training loss = 0.623256, test loss = 0.638290
  Training set accuracy = 0.873000, Test set accuracy = 0.855200
 epoch 30/200. Took 0.11355 seconds. 
  Full-batch training loss = 0.609796, test loss = 0.628649
  Training set accuracy = 0.867000, Test set accuracy = 0.851900
 epoch 31/200. Took 0.11423 seconds. 
  Full-batch training loss = 0.596973, test loss = 0.615732
  Training set accuracy = 0.870000, Test set accuracy = 0.855400
 epoch 32/200. Took 0.12274 seconds. 
  Full-batch training loss = 0.585895, test loss = 0.603644
  Training set accuracy = 0.872000, Test set accuracy = 0.856800
 epoch 33/200. Took 0.13034 seconds. 
  Full-batch training loss = 0.574557, test loss = 0.594586
  Training set accuracy = 0.876000, Test set accuracy = 0.858500
 epoch 34/200. Took 0.11375 seconds. 
  Full-batch training loss = 0.561332, test loss = 0.582701
  Training set accuracy = 0.875000, Test set accuracy = 0.857600
 epoch 35/200. Took 0.13614 seconds. 
  Full-batch training loss = 0.550706, test loss = 0.571081
  Training set accuracy = 0.880500, Test set accuracy = 0.863900
 epoch 36/200. Took 0.13525 seconds. 
  Full-batch training loss = 0.541198, test loss = 0.563244
  Training set accuracy = 0.878500, Test set accuracy = 0.866400
 epoch 37/200. Took 0.11727 seconds. 
  Full-batch training loss = 0.532633, test loss = 0.556252
  Training set accuracy = 0.877000, Test set accuracy = 0.866500
 epoch 38/200. Took 0.11333 seconds. 
  Full-batch training loss = 0.523797, test loss = 0.551064
  Training set accuracy = 0.883500, Test set accuracy = 0.862200
 epoch 39/200. Took 0.11336 seconds. 
  Full-batch training loss = 0.515690, test loss = 0.544177
  Training set accuracy = 0.879500, Test set accuracy = 0.864700
 epoch 40/200. Took 0.11242 seconds. 
  Full-batch training loss = 0.511735, test loss = 0.541582
  Training set accuracy = 0.883500, Test set accuracy = 0.857800
 epoch 41/200. Took 0.12576 seconds. 
  Full-batch training loss = 0.498887, test loss = 0.531604
  Training set accuracy = 0.883000, Test set accuracy = 0.863000
 epoch 42/200. Took 0.1107 seconds. 
  Full-batch training loss = 0.490458, test loss = 0.519846
  Training set accuracy = 0.888000, Test set accuracy = 0.868800
 epoch 43/200. Took 0.11028 seconds. 
  Full-batch training loss = 0.485827, test loss = 0.515481
  Training set accuracy = 0.888000, Test set accuracy = 0.870500
 epoch 44/200. Took 0.11223 seconds. 
  Full-batch training loss = 0.476508, test loss = 0.511271
  Training set accuracy = 0.890000, Test set accuracy = 0.870700
 epoch 45/200. Took 0.1163 seconds. 
  Full-batch training loss = 0.470033, test loss = 0.501638
  Training set accuracy = 0.891000, Test set accuracy = 0.872100
 epoch 46/200. Took 0.13431 seconds. 
  Full-batch training loss = 0.463967, test loss = 0.498360
  Training set accuracy = 0.889000, Test set accuracy = 0.871500
 epoch 47/200. Took 0.11262 seconds. 
  Full-batch training loss = 0.457951, test loss = 0.494512
  Training set accuracy = 0.889500, Test set accuracy = 0.873700
 epoch 48/200. Took 0.13467 seconds. 
  Full-batch training loss = 0.452932, test loss = 0.490120
  Training set accuracy = 0.893000, Test set accuracy = 0.871800
 epoch 49/200. Took 0.11209 seconds. 
  Full-batch training loss = 0.448992, test loss = 0.484862
  Training set accuracy = 0.893500, Test set accuracy = 0.875000
 epoch 50/200. Took 0.12443 seconds. 
  Full-batch training loss = 0.442401, test loss = 0.482365
  Training set accuracy = 0.896500, Test set accuracy = 0.872200
 epoch 51/200. Took 0.11275 seconds. 
  Full-batch training loss = 0.437081, test loss = 0.473978
  Training set accuracy = 0.899000, Test set accuracy = 0.877000
 epoch 52/200. Took 0.11353 seconds. 
  Full-batch training loss = 0.432917, test loss = 0.471780
  Training set accuracy = 0.896500, Test set accuracy = 0.878500
 epoch 53/200. Took 0.11331 seconds. 
  Full-batch training loss = 0.426550, test loss = 0.466782
  Training set accuracy = 0.897000, Test set accuracy = 0.877400
 epoch 54/200. Took 0.12919 seconds. 
  Full-batch training loss = 0.422255, test loss = 0.464815
  Training set accuracy = 0.900500, Test set accuracy = 0.878400
 epoch 55/200. Took 0.11748 seconds. 
  Full-batch training loss = 0.418909, test loss = 0.460183
  Training set accuracy = 0.900000, Test set accuracy = 0.878100
 epoch 56/200. Took 0.11099 seconds. 
  Full-batch training loss = 0.414314, test loss = 0.460725
  Training set accuracy = 0.900500, Test set accuracy = 0.876500
 epoch 57/200. Took 0.13016 seconds. 
  Full-batch training loss = 0.409662, test loss = 0.455258
  Training set accuracy = 0.901500, Test set accuracy = 0.878200
 epoch 58/200. Took 0.13716 seconds. 
  Full-batch training loss = 0.406128, test loss = 0.449290
  Training set accuracy = 0.901000, Test set accuracy = 0.881000
 epoch 59/200. Took 0.12856 seconds. 
  Full-batch training loss = 0.403238, test loss = 0.451457
  Training set accuracy = 0.903500, Test set accuracy = 0.878100
 epoch 60/200. Took 0.11294 seconds. 
  Full-batch training loss = 0.398013, test loss = 0.447633
  Training set accuracy = 0.904000, Test set accuracy = 0.878700
 epoch 61/200. Took 0.11305 seconds. 
  Full-batch training loss = 0.394702, test loss = 0.443945
  Training set accuracy = 0.902000, Test set accuracy = 0.878300
 epoch 62/200. Took 0.118 seconds. 
  Full-batch training loss = 0.389849, test loss = 0.439099
  Training set accuracy = 0.905000, Test set accuracy = 0.881400
 epoch 63/200. Took 0.12147 seconds. 
  Full-batch training loss = 0.386986, test loss = 0.438210
  Training set accuracy = 0.905000, Test set accuracy = 0.880100
 epoch 64/200. Took 0.11167 seconds. 
  Full-batch training loss = 0.384433, test loss = 0.436137
  Training set accuracy = 0.905500, Test set accuracy = 0.880100
 epoch 65/200. Took 0.11961 seconds. 
  Full-batch training loss = 0.381685, test loss = 0.435032
  Training set accuracy = 0.909000, Test set accuracy = 0.880600
 epoch 66/200. Took 0.11325 seconds. 
  Full-batch training loss = 0.377131, test loss = 0.430494
  Training set accuracy = 0.908000, Test set accuracy = 0.881600
 epoch 67/200. Took 0.12112 seconds. 
  Full-batch training loss = 0.375065, test loss = 0.426544
  Training set accuracy = 0.906000, Test set accuracy = 0.883200
 epoch 68/200. Took 0.11319 seconds. 
  Full-batch training loss = 0.373693, test loss = 0.427754
  Training set accuracy = 0.908500, Test set accuracy = 0.882400
 epoch 69/200. Took 0.13475 seconds. 
  Full-batch training loss = 0.369248, test loss = 0.427643
  Training set accuracy = 0.905500, Test set accuracy = 0.881100
 epoch 70/200. Took 0.11233 seconds. 
  Full-batch training loss = 0.366374, test loss = 0.421865
  Training set accuracy = 0.909000, Test set accuracy = 0.882700
 epoch 71/200. Took 0.11577 seconds. 
  Full-batch training loss = 0.362406, test loss = 0.421469
  Training set accuracy = 0.911500, Test set accuracy = 0.882900
 epoch 72/200. Took 0.13861 seconds. 
  Full-batch training loss = 0.362172, test loss = 0.417790
  Training set accuracy = 0.912500, Test set accuracy = 0.884000
 epoch 73/200. Took 0.11314 seconds. 
  Full-batch training loss = 0.358979, test loss = 0.418633
  Training set accuracy = 0.909500, Test set accuracy = 0.882500
 epoch 74/200. Took 0.11249 seconds. 
  Full-batch training loss = 0.354683, test loss = 0.414914
  Training set accuracy = 0.912000, Test set accuracy = 0.884000
 epoch 75/200. Took 0.11247 seconds. 
  Full-batch training loss = 0.354323, test loss = 0.412997
  Training set accuracy = 0.912500, Test set accuracy = 0.884100
 epoch 76/200. Took 0.11328 seconds. 
  Full-batch training loss = 0.351123, test loss = 0.414546
  Training set accuracy = 0.908500, Test set accuracy = 0.883300
 epoch 77/200. Took 0.13531 seconds. 
  Full-batch training loss = 0.348162, test loss = 0.410384
  Training set accuracy = 0.912000, Test set accuracy = 0.885300
 epoch 78/200. Took 0.11293 seconds. 
  Full-batch training loss = 0.348788, test loss = 0.409734
  Training set accuracy = 0.913500, Test set accuracy = 0.882800
 epoch 79/200. Took 0.1128 seconds. 
  Full-batch training loss = 0.343097, test loss = 0.405621
  Training set accuracy = 0.912500, Test set accuracy = 0.884800
 epoch 80/200. Took 0.1284 seconds. 
  Full-batch training loss = 0.341776, test loss = 0.410306
  Training set accuracy = 0.911500, Test set accuracy = 0.881700
 epoch 81/200. Took 0.13351 seconds. 
  Full-batch training loss = 0.338730, test loss = 0.403993
  Training set accuracy = 0.911000, Test set accuracy = 0.886000
 epoch 82/200. Took 0.14102 seconds. 
  Full-batch training loss = 0.337460, test loss = 0.403906
  Training set accuracy = 0.912000, Test set accuracy = 0.886000
 epoch 83/200. Took 0.12543 seconds. 
  Full-batch training loss = 0.335717, test loss = 0.402966
  Training set accuracy = 0.916500, Test set accuracy = 0.886200
 epoch 84/200. Took 0.11195 seconds. 
  Full-batch training loss = 0.332677, test loss = 0.402216
  Training set accuracy = 0.911000, Test set accuracy = 0.883800
 epoch 85/200. Took 0.11528 seconds. 
  Full-batch training loss = 0.330309, test loss = 0.400384
  Training set accuracy = 0.914500, Test set accuracy = 0.884400
 epoch 86/200. Took 0.14054 seconds. 
  Full-batch training loss = 0.328624, test loss = 0.399700
  Training set accuracy = 0.911500, Test set accuracy = 0.885300
 epoch 87/200. Took 0.11304 seconds. 
  Full-batch training loss = 0.327350, test loss = 0.397757
  Training set accuracy = 0.912000, Test set accuracy = 0.886200
 epoch 88/200. Took 0.11155 seconds. 
  Full-batch training loss = 0.324880, test loss = 0.399445
  Training set accuracy = 0.914500, Test set accuracy = 0.884500
 epoch 89/200. Took 0.12712 seconds. 
  Full-batch training loss = 0.322077, test loss = 0.395734
  Training set accuracy = 0.915000, Test set accuracy = 0.885100
 epoch 90/200. Took 0.12385 seconds. 
  Full-batch training loss = 0.321084, test loss = 0.395085
  Training set accuracy = 0.917000, Test set accuracy = 0.885100
 epoch 91/200. Took 0.1333 seconds. 
  Full-batch training loss = 0.318158, test loss = 0.392148
  Training set accuracy = 0.914000, Test set accuracy = 0.886600
 epoch 92/200. Took 0.11897 seconds. 
  Full-batch training loss = 0.318493, test loss = 0.393440
  Training set accuracy = 0.917000, Test set accuracy = 0.887700
 epoch 93/200. Took 0.14448 seconds. 
  Full-batch training loss = 0.315380, test loss = 0.391126
  Training set accuracy = 0.914500, Test set accuracy = 0.887100
 epoch 94/200. Took 0.1126 seconds. 
  Full-batch training loss = 0.313954, test loss = 0.393399
  Training set accuracy = 0.918500, Test set accuracy = 0.885800
 epoch 95/200. Took 0.12254 seconds. 
  Full-batch training loss = 0.311013, test loss = 0.388062
  Training set accuracy = 0.917000, Test set accuracy = 0.887200
 epoch 96/200. Took 0.13639 seconds. 
  Full-batch training loss = 0.310672, test loss = 0.391199
  Training set accuracy = 0.916500, Test set accuracy = 0.887400
 epoch 97/200. Took 0.15928 seconds. 
  Full-batch training loss = 0.308305, test loss = 0.388381
  Training set accuracy = 0.916500, Test set accuracy = 0.886200
 epoch 98/200. Took 0.16897 seconds. 
  Full-batch training loss = 0.306304, test loss = 0.386697
  Training set accuracy = 0.919000, Test set accuracy = 0.886300
 epoch 99/200. Took 0.11638 seconds. 
  Full-batch training loss = 0.304580, test loss = 0.383669
  Training set accuracy = 0.919000, Test set accuracy = 0.888400
 epoch 100/200. Took 0.14097 seconds. 
  Full-batch training loss = 0.302805, test loss = 0.384374
  Training set accuracy = 0.920000, Test set accuracy = 0.886500
 epoch 101/200. Took 0.12581 seconds. 
  Full-batch training loss = 0.301580, test loss = 0.385587
  Training set accuracy = 0.919000, Test set accuracy = 0.887600
 epoch 102/200. Took 0.10867 seconds. 
  Full-batch training loss = 0.300587, test loss = 0.383414
  Training set accuracy = 0.919500, Test set accuracy = 0.887700
 epoch 103/200. Took 0.1341 seconds. 
  Full-batch training loss = 0.299869, test loss = 0.382500
  Training set accuracy = 0.920500, Test set accuracy = 0.887600
 epoch 104/200. Took 0.1359 seconds. 
  Full-batch training loss = 0.296986, test loss = 0.380671
  Training set accuracy = 0.918500, Test set accuracy = 0.888300
 epoch 105/200. Took 0.11626 seconds. 
  Full-batch training loss = 0.297347, test loss = 0.380783
  Training set accuracy = 0.920000, Test set accuracy = 0.888600
 epoch 106/200. Took 0.13608 seconds. 
  Full-batch training loss = 0.293963, test loss = 0.380346
  Training set accuracy = 0.920500, Test set accuracy = 0.888300
 epoch 107/200. Took 0.12267 seconds. 
  Full-batch training loss = 0.292158, test loss = 0.378473
  Training set accuracy = 0.921000, Test set accuracy = 0.888500
 epoch 108/200. Took 0.13537 seconds. 
  Full-batch training loss = 0.292318, test loss = 0.380685
  Training set accuracy = 0.919500, Test set accuracy = 0.887400
 epoch 109/200. Took 0.12641 seconds. 
  Full-batch training loss = 0.291483, test loss = 0.382267
  Training set accuracy = 0.922500, Test set accuracy = 0.888400
 epoch 110/200. Took 0.13581 seconds. 
  Full-batch training loss = 0.288756, test loss = 0.377000
  Training set accuracy = 0.921000, Test set accuracy = 0.889300
 epoch 111/200. Took 0.11241 seconds. 
  Full-batch training loss = 0.288656, test loss = 0.379306
  Training set accuracy = 0.921000, Test set accuracy = 0.888400
 epoch 112/200. Took 0.13895 seconds. 
  Full-batch training loss = 0.286324, test loss = 0.377952
  Training set accuracy = 0.923000, Test set accuracy = 0.889100
 epoch 113/200. Took 0.12339 seconds. 
  Full-batch training loss = 0.284252, test loss = 0.374697
  Training set accuracy = 0.922000, Test set accuracy = 0.889400
 epoch 114/200. Took 0.13843 seconds. 
  Full-batch training loss = 0.284043, test loss = 0.376794
  Training set accuracy = 0.922500, Test set accuracy = 0.888000
 epoch 115/200. Took 0.13626 seconds. 
  Full-batch training loss = 0.281983, test loss = 0.375256
  Training set accuracy = 0.923000, Test set accuracy = 0.888000
 epoch 116/200. Took 0.13867 seconds. 
  Full-batch training loss = 0.281553, test loss = 0.374120
  Training set accuracy = 0.923500, Test set accuracy = 0.890300
 epoch 117/200. Took 0.11926 seconds. 
  Full-batch training loss = 0.279188, test loss = 0.372440
  Training set accuracy = 0.923500, Test set accuracy = 0.889000
 epoch 118/200. Took 0.13447 seconds. 
  Full-batch training loss = 0.279388, test loss = 0.373574
  Training set accuracy = 0.922500, Test set accuracy = 0.890200
 epoch 119/200. Took 0.1107 seconds. 
  Full-batch training loss = 0.276924, test loss = 0.373864
  Training set accuracy = 0.923000, Test set accuracy = 0.889100
 epoch 120/200. Took 0.16323 seconds. 
  Full-batch training loss = 0.276125, test loss = 0.370969
  Training set accuracy = 0.924000, Test set accuracy = 0.890400
 epoch 121/200. Took 0.11868 seconds. 
  Full-batch training loss = 0.274648, test loss = 0.372058
  Training set accuracy = 0.926000, Test set accuracy = 0.889700
 epoch 122/200. Took 0.13418 seconds. 
  Full-batch training loss = 0.273187, test loss = 0.372307
  Training set accuracy = 0.925500, Test set accuracy = 0.890300
 epoch 123/200. Took 0.13696 seconds. 
  Full-batch training loss = 0.272510, test loss = 0.369565
  Training set accuracy = 0.926500, Test set accuracy = 0.889800
 epoch 124/200. Took 0.14136 seconds. 
  Full-batch training loss = 0.271251, test loss = 0.368700
  Training set accuracy = 0.926500, Test set accuracy = 0.890700
 epoch 125/200. Took 0.1562 seconds. 
  Full-batch training loss = 0.270332, test loss = 0.367984
  Training set accuracy = 0.926000, Test set accuracy = 0.890800
 epoch 126/200. Took 0.12732 seconds. 
  Full-batch training loss = 0.269318, test loss = 0.370224
  Training set accuracy = 0.923500, Test set accuracy = 0.890300
 epoch 127/200. Took 0.13771 seconds. 
  Full-batch training loss = 0.267738, test loss = 0.370166
  Training set accuracy = 0.926000, Test set accuracy = 0.889500
 epoch 128/200. Took 0.14495 seconds. 
  Full-batch training loss = 0.266706, test loss = 0.367991
  Training set accuracy = 0.927500, Test set accuracy = 0.890700
 epoch 129/200. Took 0.11425 seconds. 
  Full-batch training loss = 0.265892, test loss = 0.367481
  Training set accuracy = 0.928000, Test set accuracy = 0.890200
 epoch 130/200. Took 0.14081 seconds. 
  Full-batch training loss = 0.263444, test loss = 0.367025
  Training set accuracy = 0.926500, Test set accuracy = 0.891800
 epoch 131/200. Took 0.11532 seconds. 
  Full-batch training loss = 0.262709, test loss = 0.365622
  Training set accuracy = 0.928500, Test set accuracy = 0.890600
 epoch 132/200. Took 0.14112 seconds. 
  Full-batch training loss = 0.261804, test loss = 0.365936
  Training set accuracy = 0.928500, Test set accuracy = 0.890300
 epoch 133/200. Took 0.12601 seconds. 
  Full-batch training loss = 0.261476, test loss = 0.366232
  Training set accuracy = 0.928500, Test set accuracy = 0.891000
 epoch 134/200. Took 0.13594 seconds. 
  Full-batch training loss = 0.259584, test loss = 0.367843
  Training set accuracy = 0.928500, Test set accuracy = 0.890400
 epoch 135/200. Took 0.14413 seconds. 
  Full-batch training loss = 0.259563, test loss = 0.366506
  Training set accuracy = 0.928500, Test set accuracy = 0.890200
 epoch 136/200. Took 0.1201 seconds. 
  Full-batch training loss = 0.257213, test loss = 0.365224
  Training set accuracy = 0.931500, Test set accuracy = 0.890100
 epoch 137/200. Took 0.14084 seconds. 
  Full-batch training loss = 0.256195, test loss = 0.364958
  Training set accuracy = 0.930000, Test set accuracy = 0.891800
 epoch 138/200. Took 0.11851 seconds. 
  Full-batch training loss = 0.255134, test loss = 0.364423
  Training set accuracy = 0.930500, Test set accuracy = 0.891000
 epoch 139/200. Took 0.1339 seconds. 
  Full-batch training loss = 0.254573, test loss = 0.364634
  Training set accuracy = 0.930500, Test set accuracy = 0.890500
 epoch 140/200. Took 0.12071 seconds. 
  Full-batch training loss = 0.253090, test loss = 0.362345
  Training set accuracy = 0.932000, Test set accuracy = 0.892700
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST

learningRateRBM =

    0.1000

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.071316 seconds. Average reconstruction error is: 69.3383
 epoch 2/20. Took 0.047126 seconds. Average reconstruction error is: 41.6117
 epoch 3/20. Took 0.047125 seconds. Average reconstruction error is: 35.413
 epoch 4/20. Took 0.049191 seconds. Average reconstruction error is: 32.3189
 epoch 5/20. Took 0.048076 seconds. Average reconstruction error is: 30.4302
 epoch 6/20. Took 0.053105 seconds. Average reconstruction error is: 28.9167
 epoch 7/20. Took 0.049404 seconds. Average reconstruction error is: 27.9266
 epoch 8/20. Took 0.049996 seconds. Average reconstruction error is: 27.0637
 epoch 9/20. Took 0.046722 seconds. Average reconstruction error is: 26.5034
 epoch 10/20. Took 0.046375 seconds. Average reconstruction error is: 25.9494
 epoch 11/20. Took 0.050974 seconds. Average reconstruction error is: 25.4637
 epoch 12/20. Took 0.052734 seconds. Average reconstruction error is: 25.0305
 epoch 13/20. Took 0.04724 seconds. Average reconstruction error is: 24.7338
 epoch 14/20. Took 0.047067 seconds. Average reconstruction error is: 24.4439
 epoch 15/20. Took 0.047063 seconds. Average reconstruction error is: 24.1476
 epoch 16/20. Took 0.054429 seconds. Average reconstruction error is: 23.9119
 epoch 17/20. Took 0.053363 seconds. Average reconstruction error is: 23.7054
 epoch 18/20. Took 0.052063 seconds. Average reconstruction error is: 23.4103
 epoch 19/20. Took 0.05081 seconds. Average reconstruction error is: 23.2036
 epoch 20/20. Took 0.051197 seconds. Average reconstruction error is: 23.0265
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.068549 seconds. 
  Full-batch training loss = 1.165069, test loss = 1.183596
  Training set accuracy = 0.737000, Test set accuracy = 0.720200
 epoch 2/200. Took 0.030566 seconds. 
  Full-batch training loss = 0.815436, test loss = 0.836967
  Training set accuracy = 0.804500, Test set accuracy = 0.784300
 epoch 3/200. Took 0.030827 seconds. 
  Full-batch training loss = 0.684641, test loss = 0.705119
  Training set accuracy = 0.831500, Test set accuracy = 0.819200
 epoch 4/200. Took 0.031198 seconds. 
  Full-batch training loss = 0.611080, test loss = 0.634297
  Training set accuracy = 0.847000, Test set accuracy = 0.833100
 epoch 5/200. Took 0.049867 seconds. 
  Full-batch training loss = 0.563888, test loss = 0.592423
  Training set accuracy = 0.854500, Test set accuracy = 0.838600
 epoch 6/200. Took 0.051325 seconds. 
  Full-batch training loss = 0.527808, test loss = 0.557496
  Training set accuracy = 0.861000, Test set accuracy = 0.847400
 epoch 7/200. Took 0.051284 seconds. 
  Full-batch training loss = 0.502190, test loss = 0.535976
  Training set accuracy = 0.862500, Test set accuracy = 0.849700
 epoch 8/200. Took 0.045946 seconds. 
  Full-batch training loss = 0.485280, test loss = 0.523989
  Training set accuracy = 0.863000, Test set accuracy = 0.849600
 epoch 9/200. Took 0.052742 seconds. 
  Full-batch training loss = 0.464024, test loss = 0.507548
  Training set accuracy = 0.870000, Test set accuracy = 0.852500
 epoch 10/200. Took 0.048224 seconds. 
  Full-batch training loss = 0.445202, test loss = 0.492092
  Training set accuracy = 0.873500, Test set accuracy = 0.856700
 epoch 11/200. Took 0.048548 seconds. 
  Full-batch training loss = 0.431670, test loss = 0.481990
  Training set accuracy = 0.881000, Test set accuracy = 0.858100
 epoch 12/200. Took 0.048342 seconds. 
  Full-batch training loss = 0.418345, test loss = 0.472319
  Training set accuracy = 0.883000, Test set accuracy = 0.860100
 epoch 13/200. Took 0.053829 seconds. 
  Full-batch training loss = 0.406307, test loss = 0.465479
  Training set accuracy = 0.885500, Test set accuracy = 0.864300
 epoch 14/200. Took 0.069968 seconds. 
  Full-batch training loss = 0.396181, test loss = 0.457396
  Training set accuracy = 0.888000, Test set accuracy = 0.865300
 epoch 15/200. Took 0.050921 seconds. 
  Full-batch training loss = 0.387667, test loss = 0.453777
  Training set accuracy = 0.889500, Test set accuracy = 0.866600
 epoch 16/200. Took 0.049462 seconds. 
  Full-batch training loss = 0.377119, test loss = 0.446464
  Training set accuracy = 0.895000, Test set accuracy = 0.869000
 epoch 17/200. Took 0.044793 seconds. 
  Full-batch training loss = 0.368960, test loss = 0.441757
  Training set accuracy = 0.896500, Test set accuracy = 0.868800
 epoch 18/200. Took 0.030904 seconds. 
  Full-batch training loss = 0.361446, test loss = 0.438052
  Training set accuracy = 0.897000, Test set accuracy = 0.869200
 epoch 19/200. Took 0.034978 seconds. 
  Full-batch training loss = 0.355615, test loss = 0.435087
  Training set accuracy = 0.899500, Test set accuracy = 0.871000
 epoch 20/200. Took 0.030679 seconds. 
  Full-batch training loss = 0.346809, test loss = 0.431229
  Training set accuracy = 0.902000, Test set accuracy = 0.870500
 epoch 21/200. Took 0.040331 seconds. 
  Full-batch training loss = 0.342284, test loss = 0.431207
  Training set accuracy = 0.902000, Test set accuracy = 0.869200
 epoch 22/200. Took 0.02864 seconds. 
  Full-batch training loss = 0.334047, test loss = 0.424810
  Training set accuracy = 0.908000, Test set accuracy = 0.873100
 epoch 23/200. Took 0.032715 seconds. 
  Full-batch training loss = 0.327763, test loss = 0.422829
  Training set accuracy = 0.906500, Test set accuracy = 0.872200
 epoch 24/200. Took 0.028567 seconds. 
  Full-batch training loss = 0.321911, test loss = 0.419883
  Training set accuracy = 0.909000, Test set accuracy = 0.873200
 epoch 25/200. Took 0.03316 seconds. 
  Full-batch training loss = 0.316273, test loss = 0.418074
  Training set accuracy = 0.914000, Test set accuracy = 0.872800
 epoch 26/200. Took 0.036758 seconds. 
  Full-batch training loss = 0.311214, test loss = 0.415451
  Training set accuracy = 0.912000, Test set accuracy = 0.874200
 epoch 27/200. Took 0.034223 seconds. 
  Full-batch training loss = 0.305895, test loss = 0.414018
  Training set accuracy = 0.915500, Test set accuracy = 0.874200
 epoch 28/200. Took 0.028726 seconds. 
  Full-batch training loss = 0.299870, test loss = 0.410190
  Training set accuracy = 0.915500, Test set accuracy = 0.875100
 epoch 29/200. Took 0.031316 seconds. 
  Full-batch training loss = 0.295435, test loss = 0.410874
  Training set accuracy = 0.917500, Test set accuracy = 0.875000
 epoch 30/200. Took 0.031315 seconds. 
  Full-batch training loss = 0.290152, test loss = 0.408257
  Training set accuracy = 0.920000, Test set accuracy = 0.876700
 epoch 31/200. Took 0.03185 seconds. 
  Full-batch training loss = 0.285705, test loss = 0.405913
  Training set accuracy = 0.921000, Test set accuracy = 0.877200
 epoch 32/200. Took 0.031478 seconds. 
  Full-batch training loss = 0.280958, test loss = 0.404880
  Training set accuracy = 0.922000, Test set accuracy = 0.876600
 epoch 33/200. Took 0.039275 seconds. 
  Full-batch training loss = 0.276868, test loss = 0.404125
  Training set accuracy = 0.923500, Test set accuracy = 0.876700
 epoch 34/200. Took 0.031079 seconds. 
  Full-batch training loss = 0.272131, test loss = 0.402872
  Training set accuracy = 0.925500, Test set accuracy = 0.876500
 epoch 35/200. Took 0.03173 seconds. 
  Full-batch training loss = 0.268173, test loss = 0.401798
  Training set accuracy = 0.929000, Test set accuracy = 0.878100
 epoch 36/200. Took 0.028487 seconds. 
  Full-batch training loss = 0.264496, test loss = 0.400633
  Training set accuracy = 0.929500, Test set accuracy = 0.876700
 epoch 37/200. Took 0.02865 seconds. 
  Full-batch training loss = 0.260139, test loss = 0.398943
  Training set accuracy = 0.932500, Test set accuracy = 0.877800
 epoch 38/200. Took 0.030977 seconds. 
  Full-batch training loss = 0.255996, test loss = 0.397920
  Training set accuracy = 0.933000, Test set accuracy = 0.878000
 epoch 39/200. Took 0.030207 seconds. 
  Full-batch training loss = 0.252960, test loss = 0.398113
  Training set accuracy = 0.936000, Test set accuracy = 0.877800
 epoch 40/200. Took 0.031123 seconds. 
  Full-batch training loss = 0.249111, test loss = 0.395923
  Training set accuracy = 0.935500, Test set accuracy = 0.878400
 epoch 41/200. Took 0.047388 seconds. 
  Full-batch training loss = 0.245055, test loss = 0.395454
  Training set accuracy = 0.938500, Test set accuracy = 0.879200
 epoch 42/200. Took 0.053606 seconds. 
  Full-batch training loss = 0.241507, test loss = 0.394765
  Training set accuracy = 0.940500, Test set accuracy = 0.878900
 epoch 43/200. Took 0.055751 seconds. 
  Full-batch training loss = 0.238145, test loss = 0.394421
  Training set accuracy = 0.941000, Test set accuracy = 0.879900
 epoch 44/200. Took 0.045701 seconds. 
  Full-batch training loss = 0.235032, test loss = 0.394382
  Training set accuracy = 0.943000, Test set accuracy = 0.879200
 epoch 45/200. Took 0.050198 seconds. 
  Full-batch training loss = 0.231570, test loss = 0.393134
  Training set accuracy = 0.941500, Test set accuracy = 0.880400
 epoch 46/200. Took 0.048572 seconds. 
  Full-batch training loss = 0.229816, test loss = 0.393228
  Training set accuracy = 0.943000, Test set accuracy = 0.879200
 epoch 47/200. Took 0.042753 seconds. 
  Full-batch training loss = 0.225530, test loss = 0.391936
  Training set accuracy = 0.943500, Test set accuracy = 0.879900
 epoch 48/200. Took 0.047955 seconds. 
  Full-batch training loss = 0.221873, test loss = 0.391415
  Training set accuracy = 0.946500, Test set accuracy = 0.880900
 epoch 49/200. Took 0.05244 seconds. 
  Full-batch training loss = 0.219048, test loss = 0.390795
  Training set accuracy = 0.945500, Test set accuracy = 0.880800
 epoch 50/200. Took 0.053043 seconds. 
  Full-batch training loss = 0.216283, test loss = 0.389206
  Training set accuracy = 0.948000, Test set accuracy = 0.880000
 epoch 51/200. Took 0.053708 seconds. 
  Full-batch training loss = 0.213133, test loss = 0.388952
  Training set accuracy = 0.952500, Test set accuracy = 0.881500
 epoch 52/200. Took 0.052499 seconds. 
  Full-batch training loss = 0.210288, test loss = 0.389199
  Training set accuracy = 0.948500, Test set accuracy = 0.880300
 epoch 53/200. Took 0.044792 seconds. 
  Full-batch training loss = 0.207748, test loss = 0.388619
  Training set accuracy = 0.953000, Test set accuracy = 0.882100
 epoch 54/200. Took 0.033075 seconds. 
  Full-batch training loss = 0.204655, test loss = 0.387635
  Training set accuracy = 0.951500, Test set accuracy = 0.881100
 epoch 55/200. Took 0.03301 seconds. 
  Full-batch training loss = 0.201839, test loss = 0.387982
  Training set accuracy = 0.955000, Test set accuracy = 0.882200
 epoch 56/200. Took 0.031686 seconds. 
  Full-batch training loss = 0.199249, test loss = 0.386863
  Training set accuracy = 0.954000, Test set accuracy = 0.881600
 epoch 57/200. Took 0.03243 seconds. 
  Full-batch training loss = 0.196639, test loss = 0.387283
  Training set accuracy = 0.956000, Test set accuracy = 0.881600
 epoch 58/200. Took 0.027198 seconds. 
  Full-batch training loss = 0.194271, test loss = 0.386438
  Training set accuracy = 0.957000, Test set accuracy = 0.882700
 epoch 59/200. Took 0.029379 seconds. 
  Full-batch training loss = 0.191557, test loss = 0.386847
  Training set accuracy = 0.955500, Test set accuracy = 0.882500
 epoch 60/200. Took 0.029422 seconds. 
  Full-batch training loss = 0.189307, test loss = 0.386403
  Training set accuracy = 0.957500, Test set accuracy = 0.882800
 epoch 61/200. Took 0.039016 seconds. 
  Full-batch training loss = 0.186838, test loss = 0.385783
  Training set accuracy = 0.955500, Test set accuracy = 0.883000
 epoch 62/200. Took 0.027897 seconds. 
  Full-batch training loss = 0.184295, test loss = 0.386346
  Training set accuracy = 0.959500, Test set accuracy = 0.884500
 epoch 63/200. Took 0.028386 seconds. 
  Full-batch training loss = 0.182026, test loss = 0.385395
  Training set accuracy = 0.958500, Test set accuracy = 0.883600
 epoch 64/200. Took 0.034836 seconds. 
  Full-batch training loss = 0.179496, test loss = 0.385934
  Training set accuracy = 0.958500, Test set accuracy = 0.883500
 epoch 65/200. Took 0.034655 seconds. 
  Full-batch training loss = 0.177334, test loss = 0.384546
  Training set accuracy = 0.958000, Test set accuracy = 0.883600
 epoch 66/200. Took 0.033479 seconds. 
  Full-batch training loss = 0.175446, test loss = 0.386138
  Training set accuracy = 0.960500, Test set accuracy = 0.884200
 epoch 67/200. Took 0.038024 seconds. 
  Full-batch training loss = 0.172896, test loss = 0.385048
  Training set accuracy = 0.960500, Test set accuracy = 0.884600
 epoch 68/200. Took 0.044157 seconds. 
  Full-batch training loss = 0.170391, test loss = 0.384598
  Training set accuracy = 0.960500, Test set accuracy = 0.884500
 epoch 69/200. Took 0.048373 seconds. 
  Full-batch training loss = 0.168394, test loss = 0.384395
  Training set accuracy = 0.961500, Test set accuracy = 0.884300
 epoch 70/200. Took 0.047571 seconds. 
  Full-batch training loss = 0.166270, test loss = 0.384436
  Training set accuracy = 0.962500, Test set accuracy = 0.884900
 epoch 71/200. Took 0.054987 seconds. 
  Full-batch training loss = 0.164079, test loss = 0.384265
  Training set accuracy = 0.961500, Test set accuracy = 0.885100
 epoch 72/200. Took 0.048577 seconds. 
  Full-batch training loss = 0.162347, test loss = 0.384669
  Training set accuracy = 0.963000, Test set accuracy = 0.884900
 epoch 73/200. Took 0.050312 seconds. 
  Full-batch training loss = 0.160185, test loss = 0.384574
  Training set accuracy = 0.963000, Test set accuracy = 0.884700
 epoch 74/200. Took 0.047818 seconds. 
  Full-batch training loss = 0.158185, test loss = 0.384108
  Training set accuracy = 0.964000, Test set accuracy = 0.885500
 epoch 75/200. Took 0.045846 seconds. 
  Full-batch training loss = 0.156281, test loss = 0.384195
  Training set accuracy = 0.965500, Test set accuracy = 0.885200
 epoch 76/200. Took 0.051884 seconds. 
  Full-batch training loss = 0.154555, test loss = 0.383694
  Training set accuracy = 0.964500, Test set accuracy = 0.885900
 epoch 77/200. Took 0.051208 seconds. 
  Full-batch training loss = 0.152657, test loss = 0.384242
  Training set accuracy = 0.967500, Test set accuracy = 0.886000
 epoch 78/200. Took 0.051778 seconds. 
  Full-batch training loss = 0.150881, test loss = 0.384410
  Training set accuracy = 0.967000, Test set accuracy = 0.886000
 epoch 79/200. Took 0.047481 seconds. 
  Full-batch training loss = 0.149031, test loss = 0.384931
  Training set accuracy = 0.970000, Test set accuracy = 0.885700
 epoch 80/200. Took 0.043595 seconds. 
  Full-batch training loss = 0.147449, test loss = 0.384496
  Training set accuracy = 0.968500, Test set accuracy = 0.885800
 epoch 81/200. Took 0.049367 seconds. 
  Full-batch training loss = 0.145467, test loss = 0.384218
  Training set accuracy = 0.970000, Test set accuracy = 0.887000
 epoch 82/200. Took 0.052078 seconds. 
  Full-batch training loss = 0.143818, test loss = 0.384562
  Training set accuracy = 0.970500, Test set accuracy = 0.885800
 epoch 83/200. Took 0.050569 seconds. 
  Full-batch training loss = 0.142173, test loss = 0.384304
  Training set accuracy = 0.971500, Test set accuracy = 0.885400
 epoch 84/200. Took 0.04938 seconds. 
  Full-batch training loss = 0.140405, test loss = 0.384466
  Training set accuracy = 0.972000, Test set accuracy = 0.886100
 epoch 85/200. Took 0.044031 seconds. 
  Full-batch training loss = 0.138947, test loss = 0.384669
  Training set accuracy = 0.972500, Test set accuracy = 0.886700
 epoch 86/200. Took 0.027436 seconds. 
  Full-batch training loss = 0.137249, test loss = 0.384750
  Training set accuracy = 0.972500, Test set accuracy = 0.886200
 epoch 87/200. Took 0.027285 seconds. 
  Full-batch training loss = 0.135805, test loss = 0.384861
  Training set accuracy = 0.972500, Test set accuracy = 0.886300
 epoch 88/200. Took 0.030426 seconds. 
  Full-batch training loss = 0.134191, test loss = 0.384907
  Training set accuracy = 0.972000, Test set accuracy = 0.886400
 epoch 89/200. Took 0.027772 seconds. 
  Full-batch training loss = 0.132661, test loss = 0.384978
  Training set accuracy = 0.973000, Test set accuracy = 0.886700
 epoch 90/200. Took 0.029488 seconds. 
  Full-batch training loss = 0.131178, test loss = 0.385350
  Training set accuracy = 0.973500, Test set accuracy = 0.886800
 epoch 91/200. Took 0.028661 seconds. 
  Full-batch training loss = 0.129780, test loss = 0.385599
  Training set accuracy = 0.973500, Test set accuracy = 0.886400
 epoch 92/200. Took 0.029524 seconds. 
  Full-batch training loss = 0.128528, test loss = 0.385063
  Training set accuracy = 0.974000, Test set accuracy = 0.886800
 epoch 93/200. Took 0.02783 seconds. 
  Full-batch training loss = 0.126964, test loss = 0.385977
  Training set accuracy = 0.975000, Test set accuracy = 0.886800
 epoch 94/200. Took 0.032993 seconds. 
  Full-batch training loss = 0.125593, test loss = 0.386130
  Training set accuracy = 0.975000, Test set accuracy = 0.886900
 epoch 95/200. Took 0.027276 seconds. 
  Full-batch training loss = 0.124262, test loss = 0.385254
  Training set accuracy = 0.975500, Test set accuracy = 0.887000
 epoch 96/200. Took 0.028016 seconds. 
  Full-batch training loss = 0.122791, test loss = 0.385896
  Training set accuracy = 0.975000, Test set accuracy = 0.886500
 epoch 97/200. Took 0.027953 seconds. 
  Full-batch training loss = 0.121491, test loss = 0.386818
  Training set accuracy = 0.976000, Test set accuracy = 0.885800
 epoch 98/200. Took 0.029773 seconds. 
  Full-batch training loss = 0.120146, test loss = 0.386484
  Training set accuracy = 0.976500, Test set accuracy = 0.886700
 epoch 99/200. Took 0.028303 seconds. 
  Full-batch training loss = 0.118930, test loss = 0.387481
  Training set accuracy = 0.977500, Test set accuracy = 0.885600
 epoch 100/200. Took 0.028076 seconds. 
  Full-batch training loss = 0.117832, test loss = 0.387060
  Training set accuracy = 0.977000, Test set accuracy = 0.885600
 epoch 101/200. Took 0.03117 seconds. 
  Full-batch training loss = 0.116573, test loss = 0.387425
  Training set accuracy = 0.976500, Test set accuracy = 0.886000
 epoch 102/200. Took 0.044118 seconds. 
  Full-batch training loss = 0.115154, test loss = 0.387306
  Training set accuracy = 0.977000, Test set accuracy = 0.885700
 epoch 103/200. Took 0.054039 seconds. 
  Full-batch training loss = 0.114019, test loss = 0.387118
  Training set accuracy = 0.977500, Test set accuracy = 0.885800
 epoch 104/200. Took 0.050008 seconds. 
  Full-batch training loss = 0.112823, test loss = 0.387700
  Training set accuracy = 0.977500, Test set accuracy = 0.885300
 epoch 105/200. Took 0.050063 seconds. 
  Full-batch training loss = 0.111944, test loss = 0.388742
  Training set accuracy = 0.978500, Test set accuracy = 0.885600
 epoch 106/200. Took 0.050992 seconds. 
  Full-batch training loss = 0.110522, test loss = 0.388035
  Training set accuracy = 0.978000, Test set accuracy = 0.886200
 epoch 107/200. Took 0.050012 seconds. 
  Full-batch training loss = 0.109476, test loss = 0.387795
  Training set accuracy = 0.977500, Test set accuracy = 0.886800
 epoch 108/200. Took 0.051856 seconds. 
  Full-batch training loss = 0.108345, test loss = 0.388327
  Training set accuracy = 0.979000, Test set accuracy = 0.885800
 epoch 109/200. Took 0.048723 seconds. 
  Full-batch training loss = 0.107209, test loss = 0.388866
  Training set accuracy = 0.980000, Test set accuracy = 0.885500
 epoch 110/200. Took 0.047744 seconds. 
  Full-batch training loss = 0.106137, test loss = 0.388786
  Training set accuracy = 0.979500, Test set accuracy = 0.886300
 epoch 111/200. Took 0.053768 seconds. 
  Full-batch training loss = 0.105090, test loss = 0.388704
  Training set accuracy = 0.980000, Test set accuracy = 0.886700
 epoch 112/200. Took 0.050175 seconds. 
  Full-batch training loss = 0.104149, test loss = 0.389340
  Training set accuracy = 0.979000, Test set accuracy = 0.886400
 epoch 113/200. Took 0.045138 seconds. 
  Full-batch training loss = 0.103072, test loss = 0.389619
  Training set accuracy = 0.980500, Test set accuracy = 0.885800
 epoch 114/200. Took 0.043912 seconds. 
  Full-batch training loss = 0.101989, test loss = 0.389760
  Training set accuracy = 0.981000, Test set accuracy = 0.885700
 epoch 115/200. Took 0.028628 seconds. 
  Full-batch training loss = 0.101027, test loss = 0.390629
  Training set accuracy = 0.981000, Test set accuracy = 0.885500
 epoch 116/200. Took 0.028206 seconds. 
  Full-batch training loss = 0.100043, test loss = 0.390750
  Training set accuracy = 0.981000, Test set accuracy = 0.885000
 epoch 117/200. Took 0.035489 seconds. 
  Full-batch training loss = 0.099039, test loss = 0.391055
  Training set accuracy = 0.981000, Test set accuracy = 0.885400
 epoch 118/200. Took 0.027532 seconds. 
  Full-batch training loss = 0.098152, test loss = 0.390624
  Training set accuracy = 0.981000, Test set accuracy = 0.885600
 epoch 119/200. Took 0.031333 seconds. 
  Full-batch training loss = 0.097158, test loss = 0.391336
  Training set accuracy = 0.981000, Test set accuracy = 0.884900
 epoch 120/200. Took 0.028754 seconds. 
  Full-batch training loss = 0.096206, test loss = 0.391308
  Training set accuracy = 0.982000, Test set accuracy = 0.885400
 epoch 121/200. Took 0.032113 seconds. 
  Full-batch training loss = 0.095330, test loss = 0.391588
  Training set accuracy = 0.981500, Test set accuracy = 0.885400
 epoch 122/200. Took 0.030387 seconds. 
  Full-batch training loss = 0.094357, test loss = 0.392016
  Training set accuracy = 0.983000, Test set accuracy = 0.885100
 epoch 123/200. Took 0.031133 seconds. 
  Full-batch training loss = 0.093467, test loss = 0.392597
  Training set accuracy = 0.982500, Test set accuracy = 0.884600
 epoch 124/200. Took 0.03175 seconds. 
  Full-batch training loss = 0.092613, test loss = 0.393137
  Training set accuracy = 0.983500, Test set accuracy = 0.884700
 epoch 125/200. Took 0.032138 seconds. 
  Full-batch training loss = 0.091688, test loss = 0.393289
  Training set accuracy = 0.982500, Test set accuracy = 0.884200
 epoch 126/200. Took 0.031111 seconds. 
  Full-batch training loss = 0.090875, test loss = 0.392753
  Training set accuracy = 0.983000, Test set accuracy = 0.884700
 epoch 127/200. Took 0.029571 seconds. 
  Full-batch training loss = 0.090016, test loss = 0.393570
  Training set accuracy = 0.983500, Test set accuracy = 0.884200
 epoch 128/200. Took 0.028377 seconds. 
  Full-batch training loss = 0.089180, test loss = 0.393391
  Training set accuracy = 0.985000, Test set accuracy = 0.884800
 epoch 129/200. Took 0.028203 seconds. 
  Full-batch training loss = 0.088407, test loss = 0.394276
  Training set accuracy = 0.984500, Test set accuracy = 0.885100
 epoch 130/200. Took 0.043768 seconds. 
  Full-batch training loss = 0.087590, test loss = 0.394481
  Training set accuracy = 0.984500, Test set accuracy = 0.884500
 epoch 131/200. Took 0.048692 seconds. 
  Full-batch training loss = 0.086789, test loss = 0.393896
  Training set accuracy = 0.985000, Test set accuracy = 0.885000
 epoch 132/200. Took 0.04912 seconds. 
  Full-batch training loss = 0.086123, test loss = 0.395069
  Training set accuracy = 0.986000, Test set accuracy = 0.884100
 epoch 133/200. Took 0.047223 seconds. 
  Full-batch training loss = 0.085222, test loss = 0.395089
  Training set accuracy = 0.985000, Test set accuracy = 0.884300
 epoch 134/200. Took 0.048886 seconds. 
  Full-batch training loss = 0.084458, test loss = 0.395164
  Training set accuracy = 0.985000, Test set accuracy = 0.884700
 epoch 135/200. Took 0.046809 seconds. 
  Full-batch training loss = 0.083744, test loss = 0.396035
  Training set accuracy = 0.985000, Test set accuracy = 0.884000
 epoch 136/200. Took 0.055131 seconds. 
  Full-batch training loss = 0.083008, test loss = 0.395953
  Training set accuracy = 0.985500, Test set accuracy = 0.884400
 epoch 137/200. Took 0.051231 seconds. 
  Full-batch training loss = 0.082254, test loss = 0.396334
  Training set accuracy = 0.986000, Test set accuracy = 0.884600
 epoch 138/200. Took 0.049601 seconds. 
  Full-batch training loss = 0.081537, test loss = 0.396802
  Training set accuracy = 0.986000, Test set accuracy = 0.884700
 epoch 139/200. Took 0.051193 seconds. 
  Full-batch training loss = 0.080878, test loss = 0.396658
  Training set accuracy = 0.986500, Test set accuracy = 0.884300
 epoch 140/200. Took 0.051688 seconds. 
  Full-batch training loss = 0.080196, test loss = 0.397241
  Training set accuracy = 0.986500, Test set accuracy = 0.884000
 epoch 141/200. Took 0.045085 seconds. 
  Full-batch training loss = 0.079438, test loss = 0.397803
  Training set accuracy = 0.987500, Test set accuracy = 0.884500
 epoch 142/200. Took 0.048355 seconds. 
  Full-batch training loss = 0.078785, test loss = 0.397895
  Training set accuracy = 0.987500, Test set accuracy = 0.884400
 epoch 143/200. Took 0.052242 seconds. 
  Full-batch training loss = 0.078162, test loss = 0.398627
  Training set accuracy = 0.987000, Test set accuracy = 0.884300
 epoch 144/200. Took 0.043913 seconds. 
  Full-batch training loss = 0.077421, test loss = 0.398821
  Training set accuracy = 0.987500, Test set accuracy = 0.884500
 epoch 145/200. Took 0.044347 seconds. 
  Full-batch training loss = 0.076767, test loss = 0.398085
  Training set accuracy = 0.987500, Test set accuracy = 0.884700
 epoch 146/200. Took 0.04343 seconds. 
  Full-batch training loss = 0.076121, test loss = 0.398700
  Training set accuracy = 0.987500, Test set accuracy = 0.884600
 epoch 147/200. Took 0.04621 seconds. 
  Full-batch training loss = 0.075453, test loss = 0.399614
  Training set accuracy = 0.988000, Test set accuracy = 0.884000
 epoch 148/200. Took 0.037384 seconds. 
  Full-batch training loss = 0.074849, test loss = 0.400488
  Training set accuracy = 0.988000, Test set accuracy = 0.883700
 epoch 149/200. Took 0.029134 seconds. 
  Full-batch training loss = 0.074221, test loss = 0.399407
  Training set accuracy = 0.988000, Test set accuracy = 0.884400
 epoch 150/200. Took 0.033496 seconds. 
  Full-batch training loss = 0.073538, test loss = 0.400025
  Training set accuracy = 0.988000, Test set accuracy = 0.884000
 epoch 151/200. Took 0.029288 seconds. 
  Full-batch training loss = 0.072920, test loss = 0.400562
  Training set accuracy = 0.988000, Test set accuracy = 0.884100
 epoch 152/200. Took 0.033182 seconds. 
  Full-batch training loss = 0.072320, test loss = 0.400427
  Training set accuracy = 0.988000, Test set accuracy = 0.883900
 epoch 153/200. Took 0.032004 seconds. 
  Full-batch training loss = 0.071721, test loss = 0.401199
  Training set accuracy = 0.988000, Test set accuracy = 0.884100
 epoch 154/200. Took 0.031302 seconds. 
  Full-batch training loss = 0.071096, test loss = 0.401511
  Training set accuracy = 0.988000, Test set accuracy = 0.884800
 epoch 155/200. Took 0.03301 seconds. 
  Full-batch training loss = 0.070545, test loss = 0.401248
  Training set accuracy = 0.988500, Test set accuracy = 0.884700
 epoch 156/200. Took 0.035119 seconds. 
  Full-batch training loss = 0.070064, test loss = 0.403200
  Training set accuracy = 0.988000, Test set accuracy = 0.884100
 epoch 157/200. Took 0.029324 seconds. 
  Full-batch training loss = 0.069333, test loss = 0.402333
  Training set accuracy = 0.988500, Test set accuracy = 0.884300
 epoch 158/200. Took 0.031253 seconds. 
  Full-batch training loss = 0.068832, test loss = 0.403194
  Training set accuracy = 0.988000, Test set accuracy = 0.884600
 epoch 159/200. Took 0.029562 seconds. 
  Full-batch training loss = 0.068171, test loss = 0.402998
  Training set accuracy = 0.988500, Test set accuracy = 0.884100
 epoch 160/200. Took 0.029805 seconds. 
  Full-batch training loss = 0.067649, test loss = 0.402841
  Training set accuracy = 0.988500, Test set accuracy = 0.884900
 epoch 161/200. Took 0.027488 seconds. 
  Full-batch training loss = 0.067068, test loss = 0.404136
  Training set accuracy = 0.988500, Test set accuracy = 0.884300
 epoch 162/200. Took 0.031753 seconds. 
  Full-batch training loss = 0.066468, test loss = 0.403420
  Training set accuracy = 0.988500, Test set accuracy = 0.884600
 epoch 163/200. Took 0.043819 seconds. 
  Full-batch training loss = 0.065884, test loss = 0.403327
  Training set accuracy = 0.988500, Test set accuracy = 0.885100
 epoch 164/200. Took 0.043107 seconds. 
  Full-batch training loss = 0.065384, test loss = 0.403658
  Training set accuracy = 0.988500, Test set accuracy = 0.885000
 epoch 165/200. Took 0.045312 seconds. 
  Full-batch training loss = 0.064784, test loss = 0.403767
  Training set accuracy = 0.988500, Test set accuracy = 0.885200
 epoch 166/200. Took 0.052083 seconds. 
  Full-batch training loss = 0.064236, test loss = 0.404381
  Training set accuracy = 0.989000, Test set accuracy = 0.884700
 epoch 167/200. Took 0.052836 seconds. 
  Full-batch training loss = 0.063696, test loss = 0.405596
  Training set accuracy = 0.988500, Test set accuracy = 0.884400
 epoch 168/200. Took 0.04623 seconds. 
  Full-batch training loss = 0.063193, test loss = 0.405775
  Training set accuracy = 0.989500, Test set accuracy = 0.884900
 epoch 169/200. Took 0.04665 seconds. 
  Full-batch training loss = 0.062629, test loss = 0.405109
  Training set accuracy = 0.989500, Test set accuracy = 0.885700
 epoch 170/200. Took 0.04797 seconds. 
  Full-batch training loss = 0.062049, test loss = 0.405346
  Training set accuracy = 0.989500, Test set accuracy = 0.885900
 epoch 171/200. Took 0.04579 seconds. 
  Full-batch training loss = 0.061530, test loss = 0.405960
  Training set accuracy = 0.989500, Test set accuracy = 0.885000
 epoch 172/200. Took 0.045302 seconds. 
  Full-batch training loss = 0.060988, test loss = 0.405712
  Training set accuracy = 0.990000, Test set accuracy = 0.886200
 epoch 173/200. Took 0.051504 seconds. 
  Full-batch training loss = 0.060478, test loss = 0.406294
  Training set accuracy = 0.990000, Test set accuracy = 0.885900
 epoch 174/200. Took 0.049279 seconds. 
  Full-batch training loss = 0.059970, test loss = 0.406668
  Training set accuracy = 0.990000, Test set accuracy = 0.885600
 epoch 175/200. Took 0.04746 seconds. 
  Full-batch training loss = 0.059453, test loss = 0.407209
  Training set accuracy = 0.990000, Test set accuracy = 0.884500
 epoch 176/200. Took 0.063848 seconds. 
  Full-batch training loss = 0.058932, test loss = 0.407237
  Training set accuracy = 0.990000, Test set accuracy = 0.885200
 epoch 177/200. Took 0.033381 seconds. 
  Full-batch training loss = 0.058485, test loss = 0.407476
  Training set accuracy = 0.990000, Test set accuracy = 0.884900
 epoch 178/200. Took 0.036636 seconds. 
  Full-batch training loss = 0.057980, test loss = 0.408216
  Training set accuracy = 0.990000, Test set accuracy = 0.884900
 epoch 179/200. Took 0.028877 seconds. 
  Full-batch training loss = 0.057513, test loss = 0.408034
  Training set accuracy = 0.990500, Test set accuracy = 0.885800
 epoch 180/200. Took 0.041665 seconds. 
  Full-batch training loss = 0.057060, test loss = 0.408333
  Training set accuracy = 0.990000, Test set accuracy = 0.885000
 epoch 181/200. Took 0.042826 seconds. 
  Full-batch training loss = 0.056572, test loss = 0.408302
  Training set accuracy = 0.991000, Test set accuracy = 0.885400
 epoch 182/200. Took 0.04188 seconds. 
  Full-batch training loss = 0.056129, test loss = 0.408993
  Training set accuracy = 0.991000, Test set accuracy = 0.885400
 epoch 183/200. Took 0.031303 seconds. 
  Full-batch training loss = 0.055684, test loss = 0.409174
  Training set accuracy = 0.990500, Test set accuracy = 0.884900
 epoch 184/200. Took 0.031343 seconds. 
  Full-batch training loss = 0.055238, test loss = 0.409591
  Training set accuracy = 0.991000, Test set accuracy = 0.885100
 epoch 185/200. Took 0.029553 seconds. 
  Full-batch training loss = 0.054797, test loss = 0.409989
  Training set accuracy = 0.992500, Test set accuracy = 0.885200
 epoch 186/200. Took 0.029406 seconds. 
  Full-batch training loss = 0.054368, test loss = 0.409602
  Training set accuracy = 0.991500, Test set accuracy = 0.885800
 epoch 187/200. Took 0.027988 seconds. 
  Full-batch training loss = 0.053926, test loss = 0.409862
  Training set accuracy = 0.991000, Test set accuracy = 0.885500
 epoch 188/200. Took 0.031833 seconds. 
  Full-batch training loss = 0.053502, test loss = 0.410438
  Training set accuracy = 0.992000, Test set accuracy = 0.885600
 epoch 189/200. Took 0.031296 seconds. 
  Full-batch training loss = 0.053105, test loss = 0.410584
  Training set accuracy = 0.991000, Test set accuracy = 0.885400
 epoch 190/200. Took 0.031265 seconds. 
  Full-batch training loss = 0.052680, test loss = 0.411209
  Training set accuracy = 0.992500, Test set accuracy = 0.885000
 epoch 191/200. Took 0.04966 seconds. 
  Full-batch training loss = 0.052272, test loss = 0.410847
  Training set accuracy = 0.991500, Test set accuracy = 0.885900
 epoch 192/200. Took 0.044664 seconds. 
  Full-batch training loss = 0.051859, test loss = 0.411121
  Training set accuracy = 0.991500, Test set accuracy = 0.885800
 epoch 193/200. Took 0.04917 seconds. 
  Full-batch training loss = 0.051464, test loss = 0.411211
  Training set accuracy = 0.992000, Test set accuracy = 0.885900
 epoch 194/200. Took 0.048819 seconds. 
  Full-batch training loss = 0.051056, test loss = 0.412031
  Training set accuracy = 0.992000, Test set accuracy = 0.885900
 epoch 195/200. Took 0.048886 seconds. 
  Full-batch training loss = 0.050681, test loss = 0.412407
  Training set accuracy = 0.992500, Test set accuracy = 0.885100
 epoch 196/200. Took 0.047364 seconds. 
  Full-batch training loss = 0.050320, test loss = 0.412093
  Training set accuracy = 0.991500, Test set accuracy = 0.886200
 epoch 197/200. Took 0.050521 seconds. 
  Full-batch training loss = 0.049932, test loss = 0.413010
  Training set accuracy = 0.992500, Test set accuracy = 0.885200
 epoch 198/200. Took 0.050964 seconds. 
  Full-batch training loss = 0.049538, test loss = 0.412831
  Training set accuracy = 0.992500, Test set accuracy = 0.885600
 epoch 199/200. Took 0.050199 seconds. 
  Full-batch training loss = 0.049166, test loss = 0.412962
  Training set accuracy = 0.992000, Test set accuracy = 0.886000
 epoch 200/200. Took 0.048047 seconds. 
  Full-batch training loss = 0.048817, test loss = 0.413954
  Training set accuracy = 0.993000, Test set accuracy = 0.885300
Elapsed time is 38.721395 seconds.
End Training

learningRateRBM =

    0.1000

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 50 epochs (batchsize: 100)
 epoch 1/50. Took 0.083304 seconds. Average reconstruction error is: 67.7152
 epoch 2/50. Took 0.09116 seconds. Average reconstruction error is: 38.3878
 epoch 3/50. Took 0.090623 seconds. Average reconstruction error is: 33.2253
 epoch 4/50. Took 0.084694 seconds. Average reconstruction error is: 30.4089
 epoch 5/50. Took 0.088287 seconds. Average reconstruction error is: 28.5742
 epoch 6/50. Took 0.094738 seconds. Average reconstruction error is: 27.2266
 epoch 7/50. Took 0.082263 seconds. Average reconstruction error is: 26.3301
 epoch 8/50. Took 0.075664 seconds. Average reconstruction error is: 25.5488
 epoch 9/50. Took 0.084051 seconds. Average reconstruction error is: 24.9445
 epoch 10/50. Took 0.088978 seconds. Average reconstruction error is: 24.3982
 epoch 11/50. Took 0.087454 seconds. Average reconstruction error is: 23.8741
 epoch 12/50. Took 0.086468 seconds. Average reconstruction error is: 23.4761
 epoch 13/50. Took 0.091481 seconds. Average reconstruction error is: 23.1083
 epoch 14/50. Took 0.083416 seconds. Average reconstruction error is: 22.7874
 epoch 15/50. Took 0.089391 seconds. Average reconstruction error is: 22.5646
 epoch 16/50. Took 0.093518 seconds. Average reconstruction error is: 22.364
 epoch 17/50. Took 0.089819 seconds. Average reconstruction error is: 22.0875
 epoch 18/50. Took 0.078772 seconds. Average reconstruction error is: 21.9618
 epoch 19/50. Took 0.084536 seconds. Average reconstruction error is: 21.7755
 epoch 20/50. Took 0.090132 seconds. Average reconstruction error is: 21.5672
 epoch 21/50. Took 0.080908 seconds. Average reconstruction error is: 21.4529
 epoch 22/50. Took 0.082723 seconds. Average reconstruction error is: 21.2754
 epoch 23/50. Took 0.083069 seconds. Average reconstruction error is: 21.1739
 epoch 24/50. Took 0.079374 seconds. Average reconstruction error is: 21.0212
 epoch 25/50. Took 0.08163 seconds. Average reconstruction error is: 20.9076
 epoch 26/50. Took 0.088432 seconds. Average reconstruction error is: 20.7999
 epoch 27/50. Took 0.080118 seconds. Average reconstruction error is: 20.7784
 epoch 28/50. Took 0.085729 seconds. Average reconstruction error is: 20.6608
 epoch 29/50. Took 0.091026 seconds. Average reconstruction error is: 20.5002
 epoch 30/50. Took 0.080905 seconds. Average reconstruction error is: 20.4573
 epoch 31/50. Took 0.096815 seconds. Average reconstruction error is: 20.3919
 epoch 32/50. Took 0.10113 seconds. Average reconstruction error is: 20.3209
 epoch 33/50. Took 0.10131 seconds. Average reconstruction error is: 20.2889
 epoch 34/50. Took 0.10349 seconds. Average reconstruction error is: 20.2308
 epoch 35/50. Took 0.098548 seconds. Average reconstruction error is: 20.1025
 epoch 36/50. Took 0.085331 seconds. Average reconstruction error is: 20.0616
 epoch 37/50. Took 0.078815 seconds. Average reconstruction error is: 20.0345
 epoch 38/50. Took 0.088642 seconds. Average reconstruction error is: 19.9146
 epoch 39/50. Took 0.079172 seconds. Average reconstruction error is: 19.8643
 epoch 40/50. Took 0.091715 seconds. Average reconstruction error is: 19.789
 epoch 41/50. Took 0.084861 seconds. Average reconstruction error is: 19.7922
 epoch 42/50. Took 0.085677 seconds. Average reconstruction error is: 19.663
 epoch 43/50. Took 0.082362 seconds. Average reconstruction error is: 19.6827
 epoch 44/50. Took 0.083164 seconds. Average reconstruction error is: 19.5727
 epoch 45/50. Took 0.078845 seconds. Average reconstruction error is: 19.5356
 epoch 46/50. Took 0.079736 seconds. Average reconstruction error is: 19.5395
 epoch 47/50. Took 0.080961 seconds. Average reconstruction error is: 19.4594
 epoch 48/50. Took 0.084035 seconds. Average reconstruction error is: 19.3977
 epoch 49/50. Took 0.086616 seconds. Average reconstruction error is: 19.3876
 epoch 50/50. Took 0.087951 seconds. Average reconstruction error is: 19.3329
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.052545 seconds. 
  Full-batch training loss = 1.180428, test loss = 1.187776
  Training set accuracy = 0.742000, Test set accuracy = 0.739200
 epoch 2/200. Took 0.05076 seconds. 
  Full-batch training loss = 0.813906, test loss = 0.825007
  Training set accuracy = 0.808000, Test set accuracy = 0.813800
 epoch 3/200. Took 0.053962 seconds. 
  Full-batch training loss = 0.685100, test loss = 0.698331
  Training set accuracy = 0.836000, Test set accuracy = 0.831900
 epoch 4/200. Took 0.049082 seconds. 
  Full-batch training loss = 0.606416, test loss = 0.624822
  Training set accuracy = 0.850500, Test set accuracy = 0.842100
 epoch 5/200. Took 0.047896 seconds. 
  Full-batch training loss = 0.559663, test loss = 0.583068
  Training set accuracy = 0.858500, Test set accuracy = 0.845100
 epoch 6/200. Took 0.047823 seconds. 
  Full-batch training loss = 0.522597, test loss = 0.548734
  Training set accuracy = 0.864500, Test set accuracy = 0.852200
 epoch 7/200. Took 0.048136 seconds. 
  Full-batch training loss = 0.495148, test loss = 0.525462
  Training set accuracy = 0.870000, Test set accuracy = 0.853900
 epoch 8/200. Took 0.044642 seconds. 
  Full-batch training loss = 0.473320, test loss = 0.507619
  Training set accuracy = 0.876000, Test set accuracy = 0.861500
 epoch 9/200. Took 0.043159 seconds. 
  Full-batch training loss = 0.456717, test loss = 0.493347
  Training set accuracy = 0.876500, Test set accuracy = 0.861800
 epoch 10/200. Took 0.051091 seconds. 
  Full-batch training loss = 0.439101, test loss = 0.481121
  Training set accuracy = 0.883000, Test set accuracy = 0.865900
 epoch 11/200. Took 0.048047 seconds. 
  Full-batch training loss = 0.425722, test loss = 0.472277
  Training set accuracy = 0.887000, Test set accuracy = 0.866800
 epoch 12/200. Took 0.043529 seconds. 
  Full-batch training loss = 0.413325, test loss = 0.461403
  Training set accuracy = 0.890500, Test set accuracy = 0.869700
 epoch 13/200. Took 0.04693 seconds. 
  Full-batch training loss = 0.401793, test loss = 0.455058
  Training set accuracy = 0.893500, Test set accuracy = 0.868000
 epoch 14/200. Took 0.049436 seconds. 
  Full-batch training loss = 0.392539, test loss = 0.447480
  Training set accuracy = 0.894000, Test set accuracy = 0.870900
 epoch 15/200. Took 0.047158 seconds. 
  Full-batch training loss = 0.382236, test loss = 0.441961
  Training set accuracy = 0.897000, Test set accuracy = 0.872100
 epoch 16/200. Took 0.046026 seconds. 
  Full-batch training loss = 0.373527, test loss = 0.436347
  Training set accuracy = 0.901500, Test set accuracy = 0.874100
 epoch 17/200. Took 0.05378 seconds. 
  Full-batch training loss = 0.365042, test loss = 0.432383
  Training set accuracy = 0.902000, Test set accuracy = 0.873200
 epoch 18/200. Took 0.051105 seconds. 
  Full-batch training loss = 0.358583, test loss = 0.427705
  Training set accuracy = 0.905000, Test set accuracy = 0.876400
 epoch 19/200. Took 0.049449 seconds. 
  Full-batch training loss = 0.351384, test loss = 0.423937
  Training set accuracy = 0.906000, Test set accuracy = 0.875700
 epoch 20/200. Took 0.043578 seconds. 
  Full-batch training loss = 0.343836, test loss = 0.420644
  Training set accuracy = 0.908000, Test set accuracy = 0.876400
 epoch 21/200. Took 0.045328 seconds. 
  Full-batch training loss = 0.338392, test loss = 0.417732
  Training set accuracy = 0.912000, Test set accuracy = 0.878000
 epoch 22/200. Took 0.049319 seconds. 
  Full-batch training loss = 0.331520, test loss = 0.414326
  Training set accuracy = 0.911500, Test set accuracy = 0.877100
 epoch 23/200. Took 0.047279 seconds. 
  Full-batch training loss = 0.327063, test loss = 0.414311
  Training set accuracy = 0.915500, Test set accuracy = 0.878300
 epoch 24/200. Took 0.048462 seconds. 
  Full-batch training loss = 0.320887, test loss = 0.410975
  Training set accuracy = 0.911500, Test set accuracy = 0.875600
 epoch 25/200. Took 0.046641 seconds. 
  Full-batch training loss = 0.315409, test loss = 0.407760
  Training set accuracy = 0.913000, Test set accuracy = 0.877400
 epoch 26/200. Took 0.04716 seconds. 
  Full-batch training loss = 0.310649, test loss = 0.405872
  Training set accuracy = 0.917500, Test set accuracy = 0.880400
 epoch 27/200. Took 0.048333 seconds. 
  Full-batch training loss = 0.306341, test loss = 0.404872
  Training set accuracy = 0.914500, Test set accuracy = 0.877500
 epoch 28/200. Took 0.048526 seconds. 
  Full-batch training loss = 0.300714, test loss = 0.402217
  Training set accuracy = 0.919000, Test set accuracy = 0.880800
 epoch 29/200. Took 0.044093 seconds. 
  Full-batch training loss = 0.296762, test loss = 0.402348
  Training set accuracy = 0.919500, Test set accuracy = 0.878600
 epoch 30/200. Took 0.047529 seconds. 
  Full-batch training loss = 0.292404, test loss = 0.399227
  Training set accuracy = 0.920000, Test set accuracy = 0.880800
 epoch 31/200. Took 0.043789 seconds. 
  Full-batch training loss = 0.287292, test loss = 0.397989
  Training set accuracy = 0.920000, Test set accuracy = 0.879200
 epoch 32/200. Took 0.046111 seconds. 
  Full-batch training loss = 0.283359, test loss = 0.396178
  Training set accuracy = 0.923500, Test set accuracy = 0.880800
 epoch 33/200. Took 0.044029 seconds. 
  Full-batch training loss = 0.278808, test loss = 0.394623
  Training set accuracy = 0.923000, Test set accuracy = 0.882600
 epoch 34/200. Took 0.042973 seconds. 
  Full-batch training loss = 0.275457, test loss = 0.394819
  Training set accuracy = 0.925000, Test set accuracy = 0.880000
 epoch 35/200. Took 0.043738 seconds. 
  Full-batch training loss = 0.271134, test loss = 0.393760
  Training set accuracy = 0.926000, Test set accuracy = 0.881600
 epoch 36/200. Took 0.053789 seconds. 
  Full-batch training loss = 0.267250, test loss = 0.391425
  Training set accuracy = 0.928000, Test set accuracy = 0.880700
 epoch 37/200. Took 0.049982 seconds. 
  Full-batch training loss = 0.264955, test loss = 0.391703
  Training set accuracy = 0.929500, Test set accuracy = 0.882400
 epoch 38/200. Took 0.046629 seconds. 
  Full-batch training loss = 0.259990, test loss = 0.390176
  Training set accuracy = 0.929500, Test set accuracy = 0.881700
 epoch 39/200. Took 0.047872 seconds. 
  Full-batch training loss = 0.256828, test loss = 0.389143
  Training set accuracy = 0.932000, Test set accuracy = 0.883400
 epoch 40/200. Took 0.04862 seconds. 
  Full-batch training loss = 0.252696, test loss = 0.387787
  Training set accuracy = 0.933000, Test set accuracy = 0.881900
 epoch 41/200. Took 0.049693 seconds. 
  Full-batch training loss = 0.249496, test loss = 0.386741
  Training set accuracy = 0.934000, Test set accuracy = 0.882300
 epoch 42/200. Took 0.045848 seconds. 
  Full-batch training loss = 0.246109, test loss = 0.386446
  Training set accuracy = 0.936500, Test set accuracy = 0.881700
 epoch 43/200. Took 0.04582 seconds. 
  Full-batch training loss = 0.243390, test loss = 0.385799
  Training set accuracy = 0.937000, Test set accuracy = 0.882100
 epoch 44/200. Took 0.052322 seconds. 
  Full-batch training loss = 0.239813, test loss = 0.385342
  Training set accuracy = 0.939500, Test set accuracy = 0.883000
 epoch 45/200. Took 0.042136 seconds. 
  Full-batch training loss = 0.236592, test loss = 0.384808
  Training set accuracy = 0.939000, Test set accuracy = 0.882300
 epoch 46/200. Took 0.029974 seconds. 
  Full-batch training loss = 0.233910, test loss = 0.384247
  Training set accuracy = 0.937500, Test set accuracy = 0.882700
 epoch 47/200. Took 0.031901 seconds. 
  Full-batch training loss = 0.230309, test loss = 0.383149
  Training set accuracy = 0.940500, Test set accuracy = 0.882700
 epoch 48/200. Took 0.033045 seconds. 
  Full-batch training loss = 0.227367, test loss = 0.382374
  Training set accuracy = 0.943500, Test set accuracy = 0.883900
 epoch 49/200. Took 0.033148 seconds. 
  Full-batch training loss = 0.224666, test loss = 0.382208
  Training set accuracy = 0.942500, Test set accuracy = 0.883400
 epoch 50/200. Took 0.034085 seconds. 
  Full-batch training loss = 0.221710, test loss = 0.381609
  Training set accuracy = 0.942500, Test set accuracy = 0.884100
 epoch 51/200. Took 0.030577 seconds. 
  Full-batch training loss = 0.219142, test loss = 0.381864
  Training set accuracy = 0.942000, Test set accuracy = 0.883700
 epoch 52/200. Took 0.029751 seconds. 
  Full-batch training loss = 0.216244, test loss = 0.381153
  Training set accuracy = 0.944000, Test set accuracy = 0.884300
 epoch 53/200. Took 0.028078 seconds. 
  Full-batch training loss = 0.214060, test loss = 0.380621
  Training set accuracy = 0.946000, Test set accuracy = 0.884800
 epoch 54/200. Took 0.028089 seconds. 
  Full-batch training loss = 0.210797, test loss = 0.379530
  Training set accuracy = 0.946000, Test set accuracy = 0.884500
 epoch 55/200. Took 0.029033 seconds. 
  Full-batch training loss = 0.207836, test loss = 0.379150
  Training set accuracy = 0.946000, Test set accuracy = 0.884700
 epoch 56/200. Took 0.028667 seconds. 
  Full-batch training loss = 0.205177, test loss = 0.379625
  Training set accuracy = 0.947000, Test set accuracy = 0.883500
 epoch 57/200. Took 0.032374 seconds. 
  Full-batch training loss = 0.203401, test loss = 0.379059
  Training set accuracy = 0.947000, Test set accuracy = 0.885100
 epoch 58/200. Took 0.028803 seconds. 
  Full-batch training loss = 0.200476, test loss = 0.378979
  Training set accuracy = 0.947000, Test set accuracy = 0.884400
 epoch 59/200. Took 0.02961 seconds. 
  Full-batch training loss = 0.197564, test loss = 0.377931
  Training set accuracy = 0.948500, Test set accuracy = 0.884500
 epoch 60/200. Took 0.048051 seconds. 
  Full-batch training loss = 0.195246, test loss = 0.378133
  Training set accuracy = 0.949000, Test set accuracy = 0.884500
 epoch 61/200. Took 0.045528 seconds. 
  Full-batch training loss = 0.192855, test loss = 0.377805
  Training set accuracy = 0.949500, Test set accuracy = 0.884500
 epoch 62/200. Took 0.049678 seconds. 
  Full-batch training loss = 0.190521, test loss = 0.377400
  Training set accuracy = 0.951500, Test set accuracy = 0.884300
 epoch 63/200. Took 0.044028 seconds. 
  Full-batch training loss = 0.188264, test loss = 0.376866
  Training set accuracy = 0.952000, Test set accuracy = 0.885200
 epoch 64/200. Took 0.047116 seconds. 
  Full-batch training loss = 0.186125, test loss = 0.377697
  Training set accuracy = 0.951000, Test set accuracy = 0.885000
 epoch 65/200. Took 0.044676 seconds. 
  Full-batch training loss = 0.183692, test loss = 0.376573
  Training set accuracy = 0.952000, Test set accuracy = 0.885400
 epoch 66/200. Took 0.044916 seconds. 
  Full-batch training loss = 0.181493, test loss = 0.376573
  Training set accuracy = 0.952500, Test set accuracy = 0.884600
 epoch 67/200. Took 0.048345 seconds. 
  Full-batch training loss = 0.179493, test loss = 0.376494
  Training set accuracy = 0.952500, Test set accuracy = 0.885500
 epoch 68/200. Took 0.042511 seconds. 
  Full-batch training loss = 0.177103, test loss = 0.376402
  Training set accuracy = 0.953500, Test set accuracy = 0.886100
 epoch 69/200. Took 0.047443 seconds. 
  Full-batch training loss = 0.175338, test loss = 0.376618
  Training set accuracy = 0.954500, Test set accuracy = 0.885300
 epoch 70/200. Took 0.043648 seconds. 
  Full-batch training loss = 0.173633, test loss = 0.376481
  Training set accuracy = 0.954000, Test set accuracy = 0.885500
 epoch 71/200. Took 0.052566 seconds. 
  Full-batch training loss = 0.171482, test loss = 0.376443
  Training set accuracy = 0.954000, Test set accuracy = 0.885600
 epoch 72/200. Took 0.043316 seconds. 
  Full-batch training loss = 0.168841, test loss = 0.375610
  Training set accuracy = 0.954000, Test set accuracy = 0.884900
 epoch 73/200. Took 0.045297 seconds. 
  Full-batch training loss = 0.166881, test loss = 0.375214
  Training set accuracy = 0.955000, Test set accuracy = 0.885300
 epoch 74/200. Took 0.043657 seconds. 
  Full-batch training loss = 0.165105, test loss = 0.375568
  Training set accuracy = 0.955500, Test set accuracy = 0.886100
 epoch 75/200. Took 0.043322 seconds. 
  Full-batch training loss = 0.163205, test loss = 0.375244
  Training set accuracy = 0.956000, Test set accuracy = 0.886400
 epoch 76/200. Took 0.052344 seconds. 
  Full-batch training loss = 0.161842, test loss = 0.375883
  Training set accuracy = 0.958000, Test set accuracy = 0.885600
 epoch 77/200. Took 0.050765 seconds. 
  Full-batch training loss = 0.159620, test loss = 0.375222
  Training set accuracy = 0.957000, Test set accuracy = 0.885900
 epoch 78/200. Took 0.047737 seconds. 
  Full-batch training loss = 0.157720, test loss = 0.375203
  Training set accuracy = 0.960000, Test set accuracy = 0.886500
 epoch 79/200. Took 0.047294 seconds. 
  Full-batch training loss = 0.155931, test loss = 0.375356
  Training set accuracy = 0.960500, Test set accuracy = 0.886000
 epoch 80/200. Took 0.045917 seconds. 
  Full-batch training loss = 0.154375, test loss = 0.375246
  Training set accuracy = 0.961500, Test set accuracy = 0.886700
 epoch 81/200. Took 0.043394 seconds. 
  Full-batch training loss = 0.152418, test loss = 0.375135
  Training set accuracy = 0.961500, Test set accuracy = 0.886000
 epoch 82/200. Took 0.047587 seconds. 
  Full-batch training loss = 0.150833, test loss = 0.375218
  Training set accuracy = 0.963500, Test set accuracy = 0.887500
 epoch 83/200. Took 0.045065 seconds. 
  Full-batch training loss = 0.149155, test loss = 0.375069
  Training set accuracy = 0.964500, Test set accuracy = 0.886800
 epoch 84/200. Took 0.052444 seconds. 
  Full-batch training loss = 0.147700, test loss = 0.375473
  Training set accuracy = 0.964000, Test set accuracy = 0.887600
 epoch 85/200. Took 0.048641 seconds. 
  Full-batch training loss = 0.145925, test loss = 0.375236
  Training set accuracy = 0.963000, Test set accuracy = 0.886800
 epoch 86/200. Took 0.044524 seconds. 
  Full-batch training loss = 0.144308, test loss = 0.374793
  Training set accuracy = 0.964000, Test set accuracy = 0.887600
 epoch 87/200. Took 0.04151 seconds. 
  Full-batch training loss = 0.142633, test loss = 0.375098
  Training set accuracy = 0.965500, Test set accuracy = 0.887200
 epoch 88/200. Took 0.048633 seconds. 
  Full-batch training loss = 0.141202, test loss = 0.375008
  Training set accuracy = 0.965500, Test set accuracy = 0.888000
 epoch 89/200. Took 0.049002 seconds. 
  Full-batch training loss = 0.139744, test loss = 0.375407
  Training set accuracy = 0.967500, Test set accuracy = 0.887000
 epoch 90/200. Took 0.048602 seconds. 
  Full-batch training loss = 0.138317, test loss = 0.375303
  Training set accuracy = 0.966500, Test set accuracy = 0.887900
 epoch 91/200. Took 0.04934 seconds. 
  Full-batch training loss = 0.136807, test loss = 0.375628
  Training set accuracy = 0.968000, Test set accuracy = 0.887000
 epoch 92/200. Took 0.048582 seconds. 
  Full-batch training loss = 0.135406, test loss = 0.375549
  Training set accuracy = 0.968500, Test set accuracy = 0.887800
 epoch 93/200. Took 0.046727 seconds. 
  Full-batch training loss = 0.133810, test loss = 0.375135
  Training set accuracy = 0.968500, Test set accuracy = 0.887500
 epoch 94/200. Took 0.047665 seconds. 
  Full-batch training loss = 0.132459, test loss = 0.375743
  Training set accuracy = 0.970000, Test set accuracy = 0.887900
 epoch 95/200. Took 0.048197 seconds. 
  Full-batch training loss = 0.131059, test loss = 0.375843
  Training set accuracy = 0.971000, Test set accuracy = 0.888400
 epoch 96/200. Took 0.031712 seconds. 
  Full-batch training loss = 0.129765, test loss = 0.375852
  Training set accuracy = 0.970500, Test set accuracy = 0.888500
 epoch 97/200. Took 0.032029 seconds. 
  Full-batch training loss = 0.128541, test loss = 0.376334
  Training set accuracy = 0.971000, Test set accuracy = 0.888600
 epoch 98/200. Took 0.031962 seconds. 
  Full-batch training loss = 0.126968, test loss = 0.375706
  Training set accuracy = 0.971000, Test set accuracy = 0.888300
 epoch 99/200. Took 0.035909 seconds. 
  Full-batch training loss = 0.125658, test loss = 0.376003
  Training set accuracy = 0.972500, Test set accuracy = 0.888000
 epoch 100/200. Took 0.029597 seconds. 
  Full-batch training loss = 0.124368, test loss = 0.376216
  Training set accuracy = 0.971500, Test set accuracy = 0.887900
 epoch 101/200. Took 0.035019 seconds. 
  Full-batch training loss = 0.123057, test loss = 0.376117
  Training set accuracy = 0.971500, Test set accuracy = 0.888500
 epoch 102/200. Took 0.027969 seconds. 
  Full-batch training loss = 0.121896, test loss = 0.376435
  Training set accuracy = 0.972500, Test set accuracy = 0.888100
 epoch 103/200. Took 0.035605 seconds. 
  Full-batch training loss = 0.120461, test loss = 0.376518
  Training set accuracy = 0.973500, Test set accuracy = 0.888000
 epoch 104/200. Took 0.033002 seconds. 
  Full-batch training loss = 0.119317, test loss = 0.377003
  Training set accuracy = 0.975000, Test set accuracy = 0.888100
 epoch 105/200. Took 0.03041 seconds. 
  Full-batch training loss = 0.118035, test loss = 0.376742
  Training set accuracy = 0.973000, Test set accuracy = 0.888600
 epoch 106/200. Took 0.028728 seconds. 
  Full-batch training loss = 0.117026, test loss = 0.376843
  Training set accuracy = 0.974500, Test set accuracy = 0.888800
 epoch 107/200. Took 0.029984 seconds. 
  Full-batch training loss = 0.115645, test loss = 0.376996
  Training set accuracy = 0.976000, Test set accuracy = 0.888400
 epoch 108/200. Took 0.031946 seconds. 
  Full-batch training loss = 0.114429, test loss = 0.377326
  Training set accuracy = 0.976500, Test set accuracy = 0.888700
 epoch 109/200. Took 0.03711 seconds. 
  Full-batch training loss = 0.113216, test loss = 0.377343
  Training set accuracy = 0.977500, Test set accuracy = 0.888700
 epoch 110/200. Took 0.03189 seconds. 
  Full-batch training loss = 0.112079, test loss = 0.377239
  Training set accuracy = 0.977000, Test set accuracy = 0.889000
 epoch 111/200. Took 0.043711 seconds. 
  Full-batch training loss = 0.110993, test loss = 0.377939
  Training set accuracy = 0.978500, Test set accuracy = 0.888900
 epoch 112/200. Took 0.048508 seconds. 
  Full-batch training loss = 0.110042, test loss = 0.378445
  Training set accuracy = 0.978500, Test set accuracy = 0.889000
 epoch 113/200. Took 0.045578 seconds. 
  Full-batch training loss = 0.108674, test loss = 0.378588
  Training set accuracy = 0.979500, Test set accuracy = 0.889100
 epoch 114/200. Took 0.048507 seconds. 
  Full-batch training loss = 0.107599, test loss = 0.378776
  Training set accuracy = 0.979500, Test set accuracy = 0.888600
 epoch 115/200. Took 0.048326 seconds. 
  Full-batch training loss = 0.106545, test loss = 0.378940
  Training set accuracy = 0.981500, Test set accuracy = 0.888600
 epoch 116/200. Took 0.047743 seconds. 
  Full-batch training loss = 0.105427, test loss = 0.378973
  Training set accuracy = 0.980000, Test set accuracy = 0.889500
 epoch 117/200. Took 0.043255 seconds. 
  Full-batch training loss = 0.104415, test loss = 0.379206
  Training set accuracy = 0.980000, Test set accuracy = 0.889400
 epoch 118/200. Took 0.043319 seconds. 
  Full-batch training loss = 0.103395, test loss = 0.379271
  Training set accuracy = 0.980000, Test set accuracy = 0.889400
 epoch 119/200. Took 0.049106 seconds. 
  Full-batch training loss = 0.102319, test loss = 0.379544
  Training set accuracy = 0.982000, Test set accuracy = 0.889200
 epoch 120/200. Took 0.04802 seconds. 
  Full-batch training loss = 0.101309, test loss = 0.379569
  Training set accuracy = 0.982000, Test set accuracy = 0.888800
 epoch 121/200. Took 0.051322 seconds. 
  Full-batch training loss = 0.100440, test loss = 0.379754
  Training set accuracy = 0.982500, Test set accuracy = 0.889200
 epoch 122/200. Took 0.052497 seconds. 
  Full-batch training loss = 0.099411, test loss = 0.379856
  Training set accuracy = 0.983500, Test set accuracy = 0.888900
 epoch 123/200. Took 0.049102 seconds. 
  Full-batch training loss = 0.098450, test loss = 0.380666
  Training set accuracy = 0.983000, Test set accuracy = 0.888300
 epoch 124/200. Took 0.048138 seconds. 
  Full-batch training loss = 0.097498, test loss = 0.380635
  Training set accuracy = 0.983000, Test set accuracy = 0.888800
 epoch 125/200. Took 0.044265 seconds. 
  Full-batch training loss = 0.096509, test loss = 0.380441
  Training set accuracy = 0.983500, Test set accuracy = 0.888800
 epoch 126/200. Took 0.048273 seconds. 
  Full-batch training loss = 0.095744, test loss = 0.380933
  Training set accuracy = 0.983000, Test set accuracy = 0.888900
 epoch 127/200. Took 0.048223 seconds. 
  Full-batch training loss = 0.094697, test loss = 0.380919
  Training set accuracy = 0.984000, Test set accuracy = 0.888900
 epoch 128/200. Took 0.048514 seconds. 
  Full-batch training loss = 0.093809, test loss = 0.381320
  Training set accuracy = 0.983500, Test set accuracy = 0.889700
 epoch 129/200. Took 0.048667 seconds. 
  Full-batch training loss = 0.092906, test loss = 0.381171
  Training set accuracy = 0.983500, Test set accuracy = 0.889600
 epoch 130/200. Took 0.045139 seconds. 
  Full-batch training loss = 0.092094, test loss = 0.381829
  Training set accuracy = 0.985000, Test set accuracy = 0.889100
 epoch 131/200. Took 0.046035 seconds. 
  Full-batch training loss = 0.091135, test loss = 0.382044
  Training set accuracy = 0.984000, Test set accuracy = 0.889400
 epoch 132/200. Took 0.043544 seconds. 
  Full-batch training loss = 0.090272, test loss = 0.382372
  Training set accuracy = 0.984500, Test set accuracy = 0.889000
 epoch 133/200. Took 0.04772 seconds. 
  Full-batch training loss = 0.089420, test loss = 0.382587
  Training set accuracy = 0.984500, Test set accuracy = 0.888900
 epoch 134/200. Took 0.047583 seconds. 
  Full-batch training loss = 0.088566, test loss = 0.382772
  Training set accuracy = 0.985000, Test set accuracy = 0.889100
 epoch 135/200. Took 0.04509 seconds. 
  Full-batch training loss = 0.087726, test loss = 0.382996
  Training set accuracy = 0.986000, Test set accuracy = 0.889500
 epoch 136/200. Took 0.046779 seconds. 
  Full-batch training loss = 0.086940, test loss = 0.383206
  Training set accuracy = 0.986000, Test set accuracy = 0.889200
 epoch 137/200. Took 0.050649 seconds. 
  Full-batch training loss = 0.086100, test loss = 0.383554
  Training set accuracy = 0.987000, Test set accuracy = 0.889500
 epoch 138/200. Took 0.047574 seconds. 
  Full-batch training loss = 0.085325, test loss = 0.383404
  Training set accuracy = 0.986500, Test set accuracy = 0.889600
 epoch 139/200. Took 0.043067 seconds. 
  Full-batch training loss = 0.084597, test loss = 0.383766
  Training set accuracy = 0.987000, Test set accuracy = 0.889700
 epoch 140/200. Took 0.051159 seconds. 
  Full-batch training loss = 0.083786, test loss = 0.383903
  Training set accuracy = 0.987500, Test set accuracy = 0.889900
 epoch 141/200. Took 0.047898 seconds. 
  Full-batch training loss = 0.082997, test loss = 0.384587
  Training set accuracy = 0.988000, Test set accuracy = 0.889100
 epoch 142/200. Took 0.047288 seconds. 
  Full-batch training loss = 0.082352, test loss = 0.384350
  Training set accuracy = 0.987500, Test set accuracy = 0.890300
 epoch 143/200. Took 0.048303 seconds. 
  Full-batch training loss = 0.081504, test loss = 0.384781
  Training set accuracy = 0.988500, Test set accuracy = 0.889900
 epoch 144/200. Took 0.049905 seconds. 
  Full-batch training loss = 0.080808, test loss = 0.385267
  Training set accuracy = 0.989000, Test set accuracy = 0.889900
 epoch 145/200. Took 0.052463 seconds. 
  Full-batch training loss = 0.080072, test loss = 0.384995
  Training set accuracy = 0.989000, Test set accuracy = 0.889900
 epoch 146/200. Took 0.046081 seconds. 
  Full-batch training loss = 0.079364, test loss = 0.385430
  Training set accuracy = 0.988500, Test set accuracy = 0.889900
 epoch 147/200. Took 0.043584 seconds. 
  Full-batch training loss = 0.078718, test loss = 0.385743
  Training set accuracy = 0.989500, Test set accuracy = 0.889900
 epoch 148/200. Took 0.046523 seconds. 
  Full-batch training loss = 0.077994, test loss = 0.385867
  Training set accuracy = 0.989500, Test set accuracy = 0.890100
 epoch 149/200. Took 0.047324 seconds. 
  Full-batch training loss = 0.077339, test loss = 0.386395
  Training set accuracy = 0.990000, Test set accuracy = 0.890300
 epoch 150/200. Took 0.044374 seconds. 
  Full-batch training loss = 0.076681, test loss = 0.386187
  Training set accuracy = 0.990000, Test set accuracy = 0.889900
 epoch 151/200. Took 0.052682 seconds. 
  Full-batch training loss = 0.076057, test loss = 0.386718
  Training set accuracy = 0.990000, Test set accuracy = 0.890100
 epoch 152/200. Took 0.049721 seconds. 
  Full-batch training loss = 0.075430, test loss = 0.386625
  Training set accuracy = 0.990000, Test set accuracy = 0.890000
 epoch 153/200. Took 0.04818 seconds. 
  Full-batch training loss = 0.074830, test loss = 0.387054
  Training set accuracy = 0.990500, Test set accuracy = 0.890300
 epoch 154/200. Took 0.048439 seconds. 
  Full-batch training loss = 0.074183, test loss = 0.387028
  Training set accuracy = 0.990000, Test set accuracy = 0.889900
 epoch 155/200. Took 0.028957 seconds. 
  Full-batch training loss = 0.073583, test loss = 0.387247
  Training set accuracy = 0.990500, Test set accuracy = 0.890100
 epoch 156/200. Took 0.029337 seconds. 
  Full-batch training loss = 0.072970, test loss = 0.388075
  Training set accuracy = 0.991000, Test set accuracy = 0.890500
 epoch 157/200. Took 0.028987 seconds. 
  Full-batch training loss = 0.072378, test loss = 0.387950
  Training set accuracy = 0.990500, Test set accuracy = 0.889800
 epoch 158/200. Took 0.028606 seconds. 
  Full-batch training loss = 0.071788, test loss = 0.388318
  Training set accuracy = 0.991000, Test set accuracy = 0.889900
 epoch 159/200. Took 0.032055 seconds. 
  Full-batch training loss = 0.071283, test loss = 0.388474
  Training set accuracy = 0.990500, Test set accuracy = 0.890000
 epoch 160/200. Took 0.031198 seconds. 
  Full-batch training loss = 0.070671, test loss = 0.388432
  Training set accuracy = 0.991000, Test set accuracy = 0.890400
 epoch 161/200. Took 0.031756 seconds. 
  Full-batch training loss = 0.070082, test loss = 0.388901
  Training set accuracy = 0.991000, Test set accuracy = 0.889900
 epoch 162/200. Took 0.034163 seconds. 
  Full-batch training loss = 0.069543, test loss = 0.389235
  Training set accuracy = 0.991000, Test set accuracy = 0.889800
 epoch 163/200. Took 0.032027 seconds. 
  Full-batch training loss = 0.069040, test loss = 0.389087
  Training set accuracy = 0.991000, Test set accuracy = 0.889800
 epoch 164/200. Took 0.03742 seconds. 
  Full-batch training loss = 0.068475, test loss = 0.389545
  Training set accuracy = 0.991000, Test set accuracy = 0.890400
 epoch 165/200. Took 0.032267 seconds. 
  Full-batch training loss = 0.067975, test loss = 0.389761
  Training set accuracy = 0.991500, Test set accuracy = 0.889800
 epoch 166/200. Took 0.03403 seconds. 
  Full-batch training loss = 0.067495, test loss = 0.390395
  Training set accuracy = 0.991000, Test set accuracy = 0.890300
 epoch 167/200. Took 0.030886 seconds. 
  Full-batch training loss = 0.066908, test loss = 0.390191
  Training set accuracy = 0.991500, Test set accuracy = 0.889600
 epoch 168/200. Took 0.031653 seconds. 
  Full-batch training loss = 0.066443, test loss = 0.390512
  Training set accuracy = 0.991500, Test set accuracy = 0.890100
 epoch 169/200. Took 0.038009 seconds. 
  Full-batch training loss = 0.065911, test loss = 0.390658
  Training set accuracy = 0.992000, Test set accuracy = 0.889900
 epoch 170/200. Took 0.045848 seconds. 
  Full-batch training loss = 0.065461, test loss = 0.391392
  Training set accuracy = 0.991500, Test set accuracy = 0.890100
 epoch 171/200. Took 0.049499 seconds. 
  Full-batch training loss = 0.064927, test loss = 0.391291
  Training set accuracy = 0.991500, Test set accuracy = 0.890400
 epoch 172/200. Took 0.044899 seconds. 
  Full-batch training loss = 0.064433, test loss = 0.391569
  Training set accuracy = 0.992000, Test set accuracy = 0.889800
 epoch 173/200. Took 0.045413 seconds. 
  Full-batch training loss = 0.063961, test loss = 0.391943
  Training set accuracy = 0.992000, Test set accuracy = 0.890300
 epoch 174/200. Took 0.048119 seconds. 
  Full-batch training loss = 0.063476, test loss = 0.391995
  Training set accuracy = 0.992000, Test set accuracy = 0.889700
 epoch 175/200. Took 0.047614 seconds. 
  Full-batch training loss = 0.063024, test loss = 0.392218
  Training set accuracy = 0.992000, Test set accuracy = 0.890200
 epoch 176/200. Took 0.047834 seconds. 
  Full-batch training loss = 0.062544, test loss = 0.392515
  Training set accuracy = 0.992000, Test set accuracy = 0.889900
 epoch 177/200. Took 0.048841 seconds. 
  Full-batch training loss = 0.062105, test loss = 0.392698
  Training set accuracy = 0.992000, Test set accuracy = 0.890100
 epoch 178/200. Took 0.048639 seconds. 
  Full-batch training loss = 0.061644, test loss = 0.393056
  Training set accuracy = 0.992000, Test set accuracy = 0.890000
 epoch 179/200. Took 0.047623 seconds. 
  Full-batch training loss = 0.061197, test loss = 0.392907
  Training set accuracy = 0.992000, Test set accuracy = 0.890800
 epoch 180/200. Took 0.047149 seconds. 
  Full-batch training loss = 0.060791, test loss = 0.393307
  Training set accuracy = 0.992500, Test set accuracy = 0.890500
 epoch 181/200. Took 0.042105 seconds. 
  Full-batch training loss = 0.060344, test loss = 0.393535
  Training set accuracy = 0.992000, Test set accuracy = 0.890300
 epoch 182/200. Took 0.044694 seconds. 
  Full-batch training loss = 0.059900, test loss = 0.393795
  Training set accuracy = 0.992500, Test set accuracy = 0.890300
 epoch 183/200. Took 0.044576 seconds. 
  Full-batch training loss = 0.059490, test loss = 0.393841
  Training set accuracy = 0.992500, Test set accuracy = 0.890600
 epoch 184/200. Took 0.043611 seconds. 
  Full-batch training loss = 0.059088, test loss = 0.394211
  Training set accuracy = 0.992500, Test set accuracy = 0.890700
 epoch 185/200. Took 0.041484 seconds. 
  Full-batch training loss = 0.058654, test loss = 0.394408
  Training set accuracy = 0.992500, Test set accuracy = 0.890400
 epoch 186/200. Took 0.043754 seconds. 
  Full-batch training loss = 0.058232, test loss = 0.394792
  Training set accuracy = 0.993000, Test set accuracy = 0.890100
 epoch 187/200. Took 0.046961 seconds. 
  Full-batch training loss = 0.057819, test loss = 0.394922
  Training set accuracy = 0.993000, Test set accuracy = 0.890600
 epoch 188/200. Took 0.04582 seconds. 
  Full-batch training loss = 0.057403, test loss = 0.395154
  Training set accuracy = 0.993000, Test set accuracy = 0.890500
 epoch 189/200. Took 0.049019 seconds. 
  Full-batch training loss = 0.056996, test loss = 0.395444
  Training set accuracy = 0.993000, Test set accuracy = 0.890900
 epoch 190/200. Took 0.049035 seconds. 
  Full-batch training loss = 0.056616, test loss = 0.395292
  Training set accuracy = 0.993000, Test set accuracy = 0.890800
 epoch 191/200. Took 0.047667 seconds. 
  Full-batch training loss = 0.056224, test loss = 0.395784
  Training set accuracy = 0.993500, Test set accuracy = 0.891100
 epoch 192/200. Took 0.047534 seconds. 
  Full-batch training loss = 0.055842, test loss = 0.396252
  Training set accuracy = 0.993000, Test set accuracy = 0.890600
 epoch 193/200. Took 0.043564 seconds. 
  Full-batch training loss = 0.055450, test loss = 0.396154
  Training set accuracy = 0.994000, Test set accuracy = 0.891100
 epoch 194/200. Took 0.050441 seconds. 
  Full-batch training loss = 0.055081, test loss = 0.396794
  Training set accuracy = 0.994000, Test set accuracy = 0.891200
 epoch 195/200. Took 0.047984 seconds. 
  Full-batch training loss = 0.054716, test loss = 0.396717
  Training set accuracy = 0.994500, Test set accuracy = 0.890900
 epoch 196/200. Took 0.04978 seconds. 
  Full-batch training loss = 0.054345, test loss = 0.396928
  Training set accuracy = 0.994000, Test set accuracy = 0.891000
 epoch 197/200. Took 0.04337 seconds. 
  Full-batch training loss = 0.053997, test loss = 0.396854
  Training set accuracy = 0.994000, Test set accuracy = 0.891200
 epoch 198/200. Took 0.047773 seconds. 
  Full-batch training loss = 0.053626, test loss = 0.397409
  Training set accuracy = 0.995000, Test set accuracy = 0.891000
 epoch 199/200. Took 0.047229 seconds. 
  Full-batch training loss = 0.053281, test loss = 0.397929
  Training set accuracy = 0.994000, Test set accuracy = 0.890600
 epoch 200/200. Took 0.045282 seconds. 
  Full-batch training loss = 0.052900, test loss = 0.397581
  Training set accuracy = 0.995000, Test set accuracy = 0.890700
Elapsed time is 47.547921 seconds.
End Training

learningRateRBM =

    0.0100

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.074476 seconds. Average reconstruction error is: 109.0913
 epoch 2/20. Took 0.08655 seconds. Average reconstruction error is: 61.3208
 epoch 3/20. Took 0.08209 seconds. Average reconstruction error is: 55.3616
 epoch 4/20. Took 0.082181 seconds. Average reconstruction error is: 50.7304
 epoch 5/20. Took 0.085496 seconds. Average reconstruction error is: 46.5466
 epoch 6/20. Took 0.084723 seconds. Average reconstruction error is: 43.4329
 epoch 7/20. Took 0.084762 seconds. Average reconstruction error is: 41.2465
 epoch 8/20. Took 0.087242 seconds. Average reconstruction error is: 39.6749
 epoch 9/20. Took 0.079092 seconds. Average reconstruction error is: 38.4282
 epoch 10/20. Took 0.075063 seconds. Average reconstruction error is: 37.4271
 epoch 11/20. Took 0.071979 seconds. Average reconstruction error is: 36.5565
 epoch 12/20. Took 0.087062 seconds. Average reconstruction error is: 35.8008
 epoch 13/20. Took 0.082289 seconds. Average reconstruction error is: 35.1517
 epoch 14/20. Took 0.084752 seconds. Average reconstruction error is: 34.5571
 epoch 15/20. Took 0.090553 seconds. Average reconstruction error is: 33.9781
 epoch 16/20. Took 0.081982 seconds. Average reconstruction error is: 33.493
 epoch 17/20. Took 0.080996 seconds. Average reconstruction error is: 32.9989
 epoch 18/20. Took 0.085316 seconds. Average reconstruction error is: 32.5219
 epoch 19/20. Took 0.085535 seconds. Average reconstruction error is: 32.1522
 epoch 20/20. Took 0.081938 seconds. Average reconstruction error is: 31.7608
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.047888 seconds. 
  Full-batch training loss = 1.033671, test loss = 1.043884
  Training set accuracy = 0.732500, Test set accuracy = 0.727900
 epoch 2/200. Took 0.045647 seconds. 
  Full-batch training loss = 0.794401, test loss = 0.810320
  Training set accuracy = 0.758500, Test set accuracy = 0.765600
 epoch 3/200. Took 0.046516 seconds. 
  Full-batch training loss = 0.702417, test loss = 0.724861
  Training set accuracy = 0.782500, Test set accuracy = 0.789700
 epoch 4/200. Took 0.043723 seconds. 
  Full-batch training loss = 0.631379, test loss = 0.662027
  Training set accuracy = 0.817000, Test set accuracy = 0.807700
 epoch 5/200. Took 0.047722 seconds. 
  Full-batch training loss = 0.592075, test loss = 0.630569
  Training set accuracy = 0.811500, Test set accuracy = 0.809700
 epoch 6/200. Took 0.050771 seconds. 
  Full-batch training loss = 0.548839, test loss = 0.592977
  Training set accuracy = 0.840000, Test set accuracy = 0.825500
 epoch 7/200. Took 0.047546 seconds. 
  Full-batch training loss = 0.520043, test loss = 0.571829
  Training set accuracy = 0.853000, Test set accuracy = 0.836500
 epoch 8/200. Took 0.046939 seconds. 
  Full-batch training loss = 0.493631, test loss = 0.547194
  Training set accuracy = 0.853500, Test set accuracy = 0.839300
 epoch 9/200. Took 0.043827 seconds. 
  Full-batch training loss = 0.466109, test loss = 0.528190
  Training set accuracy = 0.865000, Test set accuracy = 0.849100
 epoch 10/200. Took 0.047529 seconds. 
  Full-batch training loss = 0.445677, test loss = 0.511795
  Training set accuracy = 0.869500, Test set accuracy = 0.854200
 epoch 11/200. Took 0.045525 seconds. 
  Full-batch training loss = 0.425249, test loss = 0.495167
  Training set accuracy = 0.880000, Test set accuracy = 0.855600
 epoch 12/200. Took 0.048047 seconds. 
  Full-batch training loss = 0.407276, test loss = 0.479912
  Training set accuracy = 0.888000, Test set accuracy = 0.862100
 epoch 13/200. Took 0.05151 seconds. 
  Full-batch training loss = 0.386649, test loss = 0.466917
  Training set accuracy = 0.891000, Test set accuracy = 0.866500
 epoch 14/200. Took 0.049646 seconds. 
  Full-batch training loss = 0.370995, test loss = 0.457511
  Training set accuracy = 0.898500, Test set accuracy = 0.869600
 epoch 15/200. Took 0.048008 seconds. 
  Full-batch training loss = 0.356640, test loss = 0.447601
  Training set accuracy = 0.901000, Test set accuracy = 0.872900
 epoch 16/200. Took 0.050734 seconds. 
  Full-batch training loss = 0.340875, test loss = 0.438034
  Training set accuracy = 0.909500, Test set accuracy = 0.876700
 epoch 17/200. Took 0.048325 seconds. 
  Full-batch training loss = 0.328931, test loss = 0.429541
  Training set accuracy = 0.910500, Test set accuracy = 0.878100
 epoch 18/200. Took 0.047817 seconds. 
  Full-batch training loss = 0.315673, test loss = 0.422523
  Training set accuracy = 0.914000, Test set accuracy = 0.880300
 epoch 19/200. Took 0.047671 seconds. 
  Full-batch training loss = 0.302599, test loss = 0.414116
  Training set accuracy = 0.919500, Test set accuracy = 0.883100
 epoch 20/200. Took 0.047888 seconds. 
  Full-batch training loss = 0.291266, test loss = 0.408292
  Training set accuracy = 0.921500, Test set accuracy = 0.886600
 epoch 21/200. Took 0.051596 seconds. 
  Full-batch training loss = 0.279759, test loss = 0.400115
  Training set accuracy = 0.925500, Test set accuracy = 0.888700
 epoch 22/200. Took 0.047702 seconds. 
  Full-batch training loss = 0.270415, test loss = 0.395110
  Training set accuracy = 0.928500, Test set accuracy = 0.889300
 epoch 23/200. Took 0.044966 seconds. 
  Full-batch training loss = 0.259256, test loss = 0.388857
  Training set accuracy = 0.931000, Test set accuracy = 0.891000
 epoch 24/200. Took 0.045008 seconds. 
  Full-batch training loss = 0.250562, test loss = 0.384934
  Training set accuracy = 0.937000, Test set accuracy = 0.890900
 epoch 25/200. Took 0.052215 seconds. 
  Full-batch training loss = 0.242348, test loss = 0.380126
  Training set accuracy = 0.935000, Test set accuracy = 0.893700
 epoch 26/200. Took 0.050137 seconds. 
  Full-batch training loss = 0.233630, test loss = 0.374495
  Training set accuracy = 0.942500, Test set accuracy = 0.892500
 epoch 27/200. Took 0.057441 seconds. 
  Full-batch training loss = 0.225681, test loss = 0.369883
  Training set accuracy = 0.942500, Test set accuracy = 0.893700
 epoch 28/200. Took 0.059065 seconds. 
  Full-batch training loss = 0.219211, test loss = 0.365333
  Training set accuracy = 0.945000, Test set accuracy = 0.895100
 epoch 29/200. Took 0.048154 seconds. 
  Full-batch training loss = 0.210155, test loss = 0.362913
  Training set accuracy = 0.949500, Test set accuracy = 0.896400
 epoch 30/200. Took 0.061655 seconds. 
  Full-batch training loss = 0.204676, test loss = 0.359273
  Training set accuracy = 0.952500, Test set accuracy = 0.896500
 epoch 31/200. Took 0.047859 seconds. 
  Full-batch training loss = 0.198121, test loss = 0.355903
  Training set accuracy = 0.952500, Test set accuracy = 0.898900
 epoch 32/200. Took 0.049142 seconds. 
  Full-batch training loss = 0.190721, test loss = 0.353958
  Training set accuracy = 0.959000, Test set accuracy = 0.898800
 epoch 33/200. Took 0.059553 seconds. 
  Full-batch training loss = 0.184504, test loss = 0.348198
  Training set accuracy = 0.959500, Test set accuracy = 0.900800
 epoch 34/200. Took 0.030315 seconds. 
  Full-batch training loss = 0.179462, test loss = 0.345882
  Training set accuracy = 0.961000, Test set accuracy = 0.901900
 epoch 35/200. Took 0.032278 seconds. 
  Full-batch training loss = 0.174399, test loss = 0.345017
  Training set accuracy = 0.962000, Test set accuracy = 0.901200
 epoch 36/200. Took 0.049045 seconds. 
  Full-batch training loss = 0.167551, test loss = 0.341329
  Training set accuracy = 0.963000, Test set accuracy = 0.902400
 epoch 37/200. Took 0.049852 seconds. 
  Full-batch training loss = 0.163103, test loss = 0.340627
  Training set accuracy = 0.967000, Test set accuracy = 0.902300
 epoch 38/200. Took 0.033723 seconds. 
  Full-batch training loss = 0.157874, test loss = 0.337204
  Training set accuracy = 0.968000, Test set accuracy = 0.903500
 epoch 39/200. Took 0.045565 seconds. 
  Full-batch training loss = 0.153839, test loss = 0.335804
  Training set accuracy = 0.970500, Test set accuracy = 0.904200
 epoch 40/200. Took 0.045622 seconds. 
  Full-batch training loss = 0.149579, test loss = 0.334040
  Training set accuracy = 0.971500, Test set accuracy = 0.904900
 epoch 41/200. Took 0.062479 seconds. 
  Full-batch training loss = 0.144708, test loss = 0.331310
  Training set accuracy = 0.973500, Test set accuracy = 0.904700
 epoch 42/200. Took 0.08727 seconds. 
  Full-batch training loss = 0.141786, test loss = 0.329876
  Training set accuracy = 0.971500, Test set accuracy = 0.906600
 epoch 43/200. Took 0.072005 seconds. 
  Full-batch training loss = 0.136753, test loss = 0.329091
  Training set accuracy = 0.975500, Test set accuracy = 0.905600
 epoch 44/200. Took 0.060186 seconds. 
  Full-batch training loss = 0.133670, test loss = 0.326433
  Training set accuracy = 0.974500, Test set accuracy = 0.907600
 epoch 45/200. Took 0.085494 seconds. 
  Full-batch training loss = 0.129187, test loss = 0.324833
  Training set accuracy = 0.976500, Test set accuracy = 0.907200
 epoch 46/200. Took 0.060229 seconds. 
  Full-batch training loss = 0.126674, test loss = 0.324951
  Training set accuracy = 0.975500, Test set accuracy = 0.907700
 epoch 47/200. Took 0.056897 seconds. 
  Full-batch training loss = 0.123402, test loss = 0.325652
  Training set accuracy = 0.980000, Test set accuracy = 0.907100
 epoch 48/200. Took 0.058557 seconds. 
  Full-batch training loss = 0.119438, test loss = 0.322290
  Training set accuracy = 0.980000, Test set accuracy = 0.908700
 epoch 49/200. Took 0.05634 seconds. 
  Full-batch training loss = 0.116357, test loss = 0.320568
  Training set accuracy = 0.980500, Test set accuracy = 0.909400
 epoch 50/200. Took 0.059857 seconds. 
  Full-batch training loss = 0.113859, test loss = 0.322602
  Training set accuracy = 0.981500, Test set accuracy = 0.908800
 epoch 51/200. Took 0.060609 seconds. 
  Full-batch training loss = 0.110326, test loss = 0.318777
  Training set accuracy = 0.981000, Test set accuracy = 0.909700
 epoch 52/200. Took 0.058725 seconds. 
  Full-batch training loss = 0.107880, test loss = 0.319511
  Training set accuracy = 0.981000, Test set accuracy = 0.909600
 epoch 53/200. Took 0.058719 seconds. 
  Full-batch training loss = 0.104888, test loss = 0.316796
  Training set accuracy = 0.983500, Test set accuracy = 0.910300
 epoch 54/200. Took 0.081026 seconds. 
  Full-batch training loss = 0.102146, test loss = 0.317033
  Training set accuracy = 0.983000, Test set accuracy = 0.909500
 epoch 55/200. Took 0.084017 seconds. 
  Full-batch training loss = 0.099812, test loss = 0.317241
  Training set accuracy = 0.984500, Test set accuracy = 0.910300
 epoch 56/200. Took 0.067312 seconds. 
  Full-batch training loss = 0.097417, test loss = 0.314340
  Training set accuracy = 0.983000, Test set accuracy = 0.910100
 epoch 57/200. Took 0.07035 seconds. 
  Full-batch training loss = 0.094773, test loss = 0.313860
  Training set accuracy = 0.985500, Test set accuracy = 0.910400
 epoch 58/200. Took 0.063633 seconds. 
  Full-batch training loss = 0.092775, test loss = 0.314571
  Training set accuracy = 0.986500, Test set accuracy = 0.911300
 epoch 59/200. Took 0.060434 seconds. 
  Full-batch training loss = 0.090243, test loss = 0.312559
  Training set accuracy = 0.986500, Test set accuracy = 0.910800
 epoch 60/200. Took 0.094145 seconds. 
  Full-batch training loss = 0.088420, test loss = 0.313917
  Training set accuracy = 0.987500, Test set accuracy = 0.910900
 epoch 61/200. Took 0.068909 seconds. 
  Full-batch training loss = 0.086142, test loss = 0.312167
  Training set accuracy = 0.987500, Test set accuracy = 0.911600
 epoch 62/200. Took 0.065545 seconds. 
  Full-batch training loss = 0.084075, test loss = 0.312167
  Training set accuracy = 0.989000, Test set accuracy = 0.911700
 epoch 63/200. Took 0.062859 seconds. 
  Full-batch training loss = 0.082084, test loss = 0.312013
  Training set accuracy = 0.989000, Test set accuracy = 0.911200
 epoch 64/200. Took 0.098144 seconds. 
  Full-batch training loss = 0.080743, test loss = 0.309990
  Training set accuracy = 0.989500, Test set accuracy = 0.911700
 epoch 65/200. Took 0.11515 seconds. 
  Full-batch training loss = 0.078202, test loss = 0.310514
  Training set accuracy = 0.991000, Test set accuracy = 0.912400
 epoch 66/200. Took 0.077956 seconds. 
  Full-batch training loss = 0.076476, test loss = 0.310032
  Training set accuracy = 0.991000, Test set accuracy = 0.912700
 epoch 67/200. Took 0.065214 seconds. 
  Full-batch training loss = 0.074732, test loss = 0.309567
  Training set accuracy = 0.991000, Test set accuracy = 0.912900
 epoch 68/200. Took 0.060022 seconds. 
  Full-batch training loss = 0.073359, test loss = 0.311047
  Training set accuracy = 0.990500, Test set accuracy = 0.912400
 epoch 69/200. Took 0.068101 seconds. 
  Full-batch training loss = 0.071454, test loss = 0.309781
  Training set accuracy = 0.991000, Test set accuracy = 0.913600
 epoch 70/200. Took 0.079077 seconds. 
  Full-batch training loss = 0.069740, test loss = 0.308336
  Training set accuracy = 0.992000, Test set accuracy = 0.913500
 epoch 71/200. Took 0.067427 seconds. 
  Full-batch training loss = 0.068275, test loss = 0.309157
  Training set accuracy = 0.992000, Test set accuracy = 0.913300
 epoch 72/200. Took 0.072045 seconds. 
  Full-batch training loss = 0.066672, test loss = 0.308459
  Training set accuracy = 0.992500, Test set accuracy = 0.913900
 epoch 73/200. Took 0.081786 seconds. 
  Full-batch training loss = 0.065300, test loss = 0.308263
  Training set accuracy = 0.993000, Test set accuracy = 0.913300
 epoch 74/200. Took 0.064954 seconds. 
  Full-batch training loss = 0.063924, test loss = 0.308368
  Training set accuracy = 0.992000, Test set accuracy = 0.914000
 epoch 75/200. Took 0.061898 seconds. 
  Full-batch training loss = 0.062397, test loss = 0.307667
  Training set accuracy = 0.993000, Test set accuracy = 0.914000
 epoch 76/200. Took 0.063448 seconds. 
  Full-batch training loss = 0.061269, test loss = 0.306587
  Training set accuracy = 0.994000, Test set accuracy = 0.914500
 epoch 77/200. Took 0.067341 seconds. 
  Full-batch training loss = 0.059809, test loss = 0.307327
  Training set accuracy = 0.993500, Test set accuracy = 0.914700
 epoch 78/200. Took 0.069789 seconds. 
  Full-batch training loss = 0.058611, test loss = 0.306748
  Training set accuracy = 0.994000, Test set accuracy = 0.913700
 epoch 79/200. Took 0.094229 seconds. 
  Full-batch training loss = 0.057351, test loss = 0.307404
  Training set accuracy = 0.994000, Test set accuracy = 0.914300
 epoch 80/200. Took 0.071499 seconds. 
  Full-batch training loss = 0.056373, test loss = 0.307405
  Training set accuracy = 0.994000, Test set accuracy = 0.914000
 epoch 81/200. Took 0.082687 seconds. 
  Full-batch training loss = 0.055158, test loss = 0.306671
  Training set accuracy = 0.995000, Test set accuracy = 0.914700
 epoch 82/200. Took 0.071247 seconds. 
  Full-batch training loss = 0.054101, test loss = 0.306157
  Training set accuracy = 0.995000, Test set accuracy = 0.915500
 epoch 83/200. Took 0.11489 seconds. 
  Full-batch training loss = 0.053060, test loss = 0.306810
  Training set accuracy = 0.995000, Test set accuracy = 0.914800
 epoch 84/200. Took 0.083831 seconds. 
  Full-batch training loss = 0.051908, test loss = 0.306632
  Training set accuracy = 0.995000, Test set accuracy = 0.914500
 epoch 85/200. Took 0.071067 seconds. 
  Full-batch training loss = 0.050951, test loss = 0.306721
  Training set accuracy = 0.995000, Test set accuracy = 0.915100
 epoch 86/200. Took 0.08304 seconds. 
  Full-batch training loss = 0.049945, test loss = 0.306932
  Training set accuracy = 0.995500, Test set accuracy = 0.915500
 epoch 87/200. Took 0.061002 seconds. 
  Full-batch training loss = 0.049089, test loss = 0.306849
  Training set accuracy = 0.995500, Test set accuracy = 0.914800
 epoch 88/200. Took 0.065163 seconds. 
  Full-batch training loss = 0.048133, test loss = 0.307303
  Training set accuracy = 0.995500, Test set accuracy = 0.914700
 epoch 89/200. Took 0.067323 seconds. 
  Full-batch training loss = 0.047225, test loss = 0.306990
  Training set accuracy = 0.995500, Test set accuracy = 0.914700
 epoch 90/200. Took 0.068422 seconds. 
  Full-batch training loss = 0.046385, test loss = 0.307376
  Training set accuracy = 0.995500, Test set accuracy = 0.915400
 epoch 91/200. Took 0.075622 seconds. 
  Full-batch training loss = 0.045476, test loss = 0.306528
  Training set accuracy = 0.996500, Test set accuracy = 0.915400
 epoch 92/200. Took 0.054376 seconds. 
  Full-batch training loss = 0.044659, test loss = 0.306320
  Training set accuracy = 0.996500, Test set accuracy = 0.915700
 epoch 93/200. Took 0.071849 seconds. 
  Full-batch training loss = 0.043972, test loss = 0.306002
  Training set accuracy = 0.996500, Test set accuracy = 0.915900
 epoch 94/200. Took 0.061157 seconds. 
  Full-batch training loss = 0.043138, test loss = 0.306308
  Training set accuracy = 0.997000, Test set accuracy = 0.915400
 epoch 95/200. Took 0.065198 seconds. 
  Full-batch training loss = 0.042447, test loss = 0.306912
  Training set accuracy = 0.997000, Test set accuracy = 0.915800
 epoch 96/200. Took 0.073254 seconds. 
  Full-batch training loss = 0.041669, test loss = 0.307157
  Training set accuracy = 0.997500, Test set accuracy = 0.916200
 epoch 97/200. Took 0.069304 seconds. 
  Full-batch training loss = 0.040916, test loss = 0.306742
  Training set accuracy = 0.997500, Test set accuracy = 0.916200
 epoch 98/200. Took 0.076299 seconds. 
  Full-batch training loss = 0.040299, test loss = 0.307365
  Training set accuracy = 0.997500, Test set accuracy = 0.915300
 epoch 99/200. Took 0.073642 seconds. 
  Full-batch training loss = 0.039568, test loss = 0.307432
  Training set accuracy = 0.997500, Test set accuracy = 0.916000
 epoch 100/200. Took 0.067974 seconds. 
  Full-batch training loss = 0.038931, test loss = 0.306327
  Training set accuracy = 0.997500, Test set accuracy = 0.915900
 epoch 101/200. Took 0.078024 seconds. 
  Full-batch training loss = 0.038297, test loss = 0.306743
  Training set accuracy = 0.998000, Test set accuracy = 0.915900
 epoch 102/200. Took 0.070749 seconds. 
  Full-batch training loss = 0.037628, test loss = 0.307126
  Training set accuracy = 0.998000, Test set accuracy = 0.916000
 epoch 103/200. Took 0.082313 seconds. 
  Full-batch training loss = 0.037068, test loss = 0.306926
  Training set accuracy = 0.998000, Test set accuracy = 0.916000
 epoch 104/200. Took 0.063387 seconds. 
  Full-batch training loss = 0.036437, test loss = 0.307377
  Training set accuracy = 0.998000, Test set accuracy = 0.916500
 epoch 105/200. Took 0.068389 seconds. 
  Full-batch training loss = 0.035897, test loss = 0.307508
  Training set accuracy = 0.998500, Test set accuracy = 0.916400
 epoch 106/200. Took 0.066872 seconds. 
  Full-batch training loss = 0.035358, test loss = 0.306752
  Training set accuracy = 0.998500, Test set accuracy = 0.916700
 epoch 107/200. Took 0.054547 seconds. 
  Full-batch training loss = 0.034795, test loss = 0.307655
  Training set accuracy = 0.998000, Test set accuracy = 0.916200
 epoch 108/200. Took 0.051647 seconds. 
  Full-batch training loss = 0.034210, test loss = 0.307307
  Training set accuracy = 0.998500, Test set accuracy = 0.916500
 epoch 109/200. Took 0.057927 seconds. 
  Full-batch training loss = 0.033696, test loss = 0.307726
  Training set accuracy = 0.998500, Test set accuracy = 0.916500
 epoch 110/200. Took 0.053969 seconds. 
  Full-batch training loss = 0.033183, test loss = 0.307638
  Training set accuracy = 0.998000, Test set accuracy = 0.916500
 epoch 111/200. Took 0.058438 seconds. 
  Full-batch training loss = 0.032683, test loss = 0.308333
  Training set accuracy = 0.999000, Test set accuracy = 0.916800
 epoch 112/200. Took 0.065806 seconds. 
  Full-batch training loss = 0.032213, test loss = 0.307860
  Training set accuracy = 0.999000, Test set accuracy = 0.916900
 epoch 113/200. Took 0.060665 seconds. 
  Full-batch training loss = 0.031730, test loss = 0.308211
  Training set accuracy = 0.999000, Test set accuracy = 0.916900
 epoch 114/200. Took 0.067578 seconds. 
  Full-batch training loss = 0.031258, test loss = 0.308103
  Training set accuracy = 0.999000, Test set accuracy = 0.917200
 epoch 115/200. Took 0.066096 seconds. 
  Full-batch training loss = 0.030806, test loss = 0.308368
  Training set accuracy = 0.999000, Test set accuracy = 0.916800
 epoch 116/200. Took 0.061831 seconds. 
  Full-batch training loss = 0.030395, test loss = 0.308105
  Training set accuracy = 0.999000, Test set accuracy = 0.916900
 epoch 117/200. Took 0.06871 seconds. 
  Full-batch training loss = 0.029958, test loss = 0.308410
  Training set accuracy = 0.999000, Test set accuracy = 0.916800
 epoch 118/200. Took 0.072751 seconds. 
  Full-batch training loss = 0.029532, test loss = 0.308469
  Training set accuracy = 0.999500, Test set accuracy = 0.916900
 epoch 119/200. Took 0.060132 seconds. 
  Full-batch training loss = 0.029118, test loss = 0.309419
  Training set accuracy = 0.999000, Test set accuracy = 0.917000
 epoch 120/200. Took 0.073723 seconds. 
  Full-batch training loss = 0.028718, test loss = 0.308978
  Training set accuracy = 0.999500, Test set accuracy = 0.917000
 epoch 121/200. Took 0.067341 seconds. 
  Full-batch training loss = 0.028329, test loss = 0.309163
  Training set accuracy = 0.999500, Test set accuracy = 0.916900
 epoch 122/200. Took 0.061413 seconds. 
  Full-batch training loss = 0.028000, test loss = 0.310038
  Training set accuracy = 0.999500, Test set accuracy = 0.917700
 epoch 123/200. Took 0.064603 seconds. 
  Full-batch training loss = 0.027565, test loss = 0.309320
  Training set accuracy = 1.000000, Test set accuracy = 0.917600
 epoch 124/200. Took 0.069526 seconds. 
  Full-batch training loss = 0.027232, test loss = 0.309358
  Training set accuracy = 1.000000, Test set accuracy = 0.917200
 epoch 125/200. Took 0.061886 seconds. 
  Full-batch training loss = 0.026840, test loss = 0.309948
  Training set accuracy = 1.000000, Test set accuracy = 0.917200
 epoch 126/200. Took 0.063426 seconds. 
  Full-batch training loss = 0.026517, test loss = 0.310285
  Training set accuracy = 1.000000, Test set accuracy = 0.917500
 epoch 127/200. Took 0.05669 seconds. 
  Full-batch training loss = 0.026172, test loss = 0.309619
  Training set accuracy = 1.000000, Test set accuracy = 0.917100
 epoch 128/200. Took 0.065935 seconds. 
  Full-batch training loss = 0.025827, test loss = 0.309821
  Training set accuracy = 1.000000, Test set accuracy = 0.917400
 epoch 129/200. Took 0.067141 seconds. 
  Full-batch training loss = 0.025495, test loss = 0.310064
  Training set accuracy = 1.000000, Test set accuracy = 0.917100
 epoch 130/200. Took 0.062558 seconds. 
  Full-batch training loss = 0.025179, test loss = 0.310346
  Training set accuracy = 1.000000, Test set accuracy = 0.917700
 epoch 131/200. Took 0.062075 seconds. 
  Full-batch training loss = 0.024880, test loss = 0.310416
  Training set accuracy = 1.000000, Test set accuracy = 0.916900
 epoch 132/200. Took 0.054516 seconds. 
  Full-batch training loss = 0.024555, test loss = 0.310944
  Training set accuracy = 1.000000, Test set accuracy = 0.917700
 epoch 133/200. Took 0.049991 seconds. 
  Full-batch training loss = 0.024261, test loss = 0.310759
  Training set accuracy = 1.000000, Test set accuracy = 0.917900
 epoch 134/200. Took 0.052923 seconds. 
  Full-batch training loss = 0.023967, test loss = 0.310514
  Training set accuracy = 1.000000, Test set accuracy = 0.917800
 epoch 135/200. Took 0.05988 seconds. 
  Full-batch training loss = 0.023678, test loss = 0.310980
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 136/200. Took 0.062534 seconds. 
  Full-batch training loss = 0.023419, test loss = 0.311590
  Training set accuracy = 1.000000, Test set accuracy = 0.917900
 epoch 137/200. Took 0.065389 seconds. 
  Full-batch training loss = 0.023129, test loss = 0.311255
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 138/200. Took 0.072303 seconds. 
  Full-batch training loss = 0.022849, test loss = 0.311554
  Training set accuracy = 1.000000, Test set accuracy = 0.917800
 epoch 139/200. Took 0.056782 seconds. 
  Full-batch training loss = 0.022584, test loss = 0.311884
  Training set accuracy = 1.000000, Test set accuracy = 0.917600
 epoch 140/200. Took 0.057827 seconds. 
  Full-batch training loss = 0.022345, test loss = 0.312511
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 141/200. Took 0.056463 seconds. 
  Full-batch training loss = 0.022078, test loss = 0.311970
  Training set accuracy = 1.000000, Test set accuracy = 0.917800
 epoch 142/200. Took 0.060452 seconds. 
  Full-batch training loss = 0.021819, test loss = 0.312091
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 143/200. Took 0.057191 seconds. 
  Full-batch training loss = 0.021580, test loss = 0.312416
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 144/200. Took 0.050897 seconds. 
  Full-batch training loss = 0.021343, test loss = 0.312772
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 145/200. Took 0.054411 seconds. 
  Full-batch training loss = 0.021111, test loss = 0.312523
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 146/200. Took 0.058931 seconds. 
  Full-batch training loss = 0.020884, test loss = 0.312425
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 147/200. Took 0.06016 seconds. 
  Full-batch training loss = 0.020657, test loss = 0.312668
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 148/200. Took 0.081283 seconds. 
  Full-batch training loss = 0.020428, test loss = 0.312852
  Training set accuracy = 1.000000, Test set accuracy = 0.917900
 epoch 149/200. Took 0.057438 seconds. 
  Full-batch training loss = 0.020208, test loss = 0.313059
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 150/200. Took 0.059584 seconds. 
  Full-batch training loss = 0.019998, test loss = 0.313211
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 151/200. Took 0.062819 seconds. 
  Full-batch training loss = 0.019783, test loss = 0.313421
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 152/200. Took 0.058693 seconds. 
  Full-batch training loss = 0.019591, test loss = 0.313650
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 153/200. Took 0.052172 seconds. 
  Full-batch training loss = 0.019377, test loss = 0.313937
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 154/200. Took 0.059097 seconds. 
  Full-batch training loss = 0.019193, test loss = 0.313732
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 155/200. Took 0.067471 seconds. 
  Full-batch training loss = 0.018988, test loss = 0.313920
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 156/200. Took 0.071634 seconds. 
  Full-batch training loss = 0.018813, test loss = 0.313764
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 157/200. Took 0.060323 seconds. 
  Full-batch training loss = 0.018611, test loss = 0.313880
  Training set accuracy = 1.000000, Test set accuracy = 0.917900
 epoch 158/200. Took 0.055143 seconds. 
  Full-batch training loss = 0.018423, test loss = 0.314468
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 159/200. Took 0.057539 seconds. 
  Full-batch training loss = 0.018236, test loss = 0.314306
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 160/200. Took 0.060058 seconds. 
  Full-batch training loss = 0.018067, test loss = 0.314907
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 161/200. Took 0.063058 seconds. 
  Full-batch training loss = 0.017891, test loss = 0.314886
  Training set accuracy = 1.000000, Test set accuracy = 0.918500
 epoch 162/200. Took 0.054055 seconds. 
  Full-batch training loss = 0.017729, test loss = 0.314889
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 163/200. Took 0.05467 seconds. 
  Full-batch training loss = 0.017548, test loss = 0.315199
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 164/200. Took 0.064146 seconds. 
  Full-batch training loss = 0.017388, test loss = 0.315322
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 165/200. Took 0.058957 seconds. 
  Full-batch training loss = 0.017218, test loss = 0.315563
  Training set accuracy = 1.000000, Test set accuracy = 0.918600
 epoch 166/200. Took 0.05459 seconds. 
  Full-batch training loss = 0.017067, test loss = 0.315690
  Training set accuracy = 1.000000, Test set accuracy = 0.918100
 epoch 167/200. Took 0.063335 seconds. 
  Full-batch training loss = 0.016905, test loss = 0.315589
  Training set accuracy = 1.000000, Test set accuracy = 0.917900
 epoch 168/200. Took 0.055264 seconds. 
  Full-batch training loss = 0.016739, test loss = 0.315678
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 169/200. Took 0.070555 seconds. 
  Full-batch training loss = 0.016588, test loss = 0.315902
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 170/200. Took 0.06681 seconds. 
  Full-batch training loss = 0.016443, test loss = 0.315708
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 171/200. Took 0.065403 seconds. 
  Full-batch training loss = 0.016293, test loss = 0.316195
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 172/200. Took 0.064522 seconds. 
  Full-batch training loss = 0.016145, test loss = 0.316676
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 173/200. Took 0.061167 seconds. 
  Full-batch training loss = 0.016000, test loss = 0.316520
  Training set accuracy = 1.000000, Test set accuracy = 0.918000
 epoch 174/200. Took 0.064813 seconds. 
  Full-batch training loss = 0.015860, test loss = 0.316409
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 175/200. Took 0.074406 seconds. 
  Full-batch training loss = 0.015721, test loss = 0.316712
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 176/200. Took 0.074243 seconds. 
  Full-batch training loss = 0.015586, test loss = 0.316850
  Training set accuracy = 1.000000, Test set accuracy = 0.918600
 epoch 177/200. Took 0.059739 seconds. 
  Full-batch training loss = 0.015450, test loss = 0.317138
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 178/200. Took 0.059013 seconds. 
  Full-batch training loss = 0.015314, test loss = 0.317230
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 179/200. Took 0.05546 seconds. 
  Full-batch training loss = 0.015187, test loss = 0.317242
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 180/200. Took 0.060524 seconds. 
  Full-batch training loss = 0.015055, test loss = 0.317357
  Training set accuracy = 1.000000, Test set accuracy = 0.918300
 epoch 181/200. Took 0.06674 seconds. 
  Full-batch training loss = 0.014935, test loss = 0.317718
  Training set accuracy = 1.000000, Test set accuracy = 0.918600
 epoch 182/200. Took 0.071018 seconds. 
  Full-batch training loss = 0.014805, test loss = 0.317588
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 183/200. Took 0.058931 seconds. 
  Full-batch training loss = 0.014683, test loss = 0.317712
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 184/200. Took 0.072349 seconds. 
  Full-batch training loss = 0.014574, test loss = 0.317756
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 185/200. Took 0.06436 seconds. 
  Full-batch training loss = 0.014438, test loss = 0.318178
  Training set accuracy = 1.000000, Test set accuracy = 0.918200
 epoch 186/200. Took 0.080446 seconds. 
  Full-batch training loss = 0.014323, test loss = 0.318500
  Training set accuracy = 1.000000, Test set accuracy = 0.918800
 epoch 187/200. Took 0.06282 seconds. 
  Full-batch training loss = 0.014205, test loss = 0.318204
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 188/200. Took 0.057225 seconds. 
  Full-batch training loss = 0.014091, test loss = 0.318479
  Training set accuracy = 1.000000, Test set accuracy = 0.918500
 epoch 189/200. Took 0.085729 seconds. 
  Full-batch training loss = 0.013978, test loss = 0.318521
  Training set accuracy = 1.000000, Test set accuracy = 0.918400
 epoch 190/200. Took 0.072385 seconds. 
  Full-batch training loss = 0.013872, test loss = 0.318577
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 191/200. Took 0.086924 seconds. 
  Full-batch training loss = 0.013761, test loss = 0.318759
  Training set accuracy = 1.000000, Test set accuracy = 0.918600
 epoch 192/200. Took 0.076074 seconds. 
  Full-batch training loss = 0.013651, test loss = 0.319109
  Training set accuracy = 1.000000, Test set accuracy = 0.918500
 epoch 193/200. Took 0.079528 seconds. 
  Full-batch training loss = 0.013544, test loss = 0.318951
  Training set accuracy = 1.000000, Test set accuracy = 0.918900
 epoch 194/200. Took 0.064547 seconds. 
  Full-batch training loss = 0.013438, test loss = 0.319557
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 195/200. Took 0.069154 seconds. 
  Full-batch training loss = 0.013341, test loss = 0.319516
  Training set accuracy = 1.000000, Test set accuracy = 0.918800
 epoch 196/200. Took 0.068982 seconds. 
  Full-batch training loss = 0.013231, test loss = 0.319389
  Training set accuracy = 1.000000, Test set accuracy = 0.918800
 epoch 197/200. Took 0.081077 seconds. 
  Full-batch training loss = 0.013129, test loss = 0.319569
  Training set accuracy = 1.000000, Test set accuracy = 0.918900
 epoch 198/200. Took 0.0785 seconds. 
  Full-batch training loss = 0.013032, test loss = 0.319732
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 199/200. Took 0.069467 seconds. 
  Full-batch training loss = 0.012935, test loss = 0.320097
  Training set accuracy = 1.000000, Test set accuracy = 0.918700
 epoch 200/200. Took 0.071093 seconds. 
  Full-batch training loss = 0.012836, test loss = 0.319955
  Training set accuracy = 1.000000, Test set accuracy = 0.918600
Elapsed time is 57.392971 seconds.
End Training

learningRateRBM =

    0.0100

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 50 epochs (batchsize: 100)
 epoch 1/50. Took 0.10479 seconds. Average reconstruction error is: 107.706
 epoch 2/50. Took 0.11204 seconds. Average reconstruction error is: 61.3987
 epoch 3/50. Took 0.12236 seconds. Average reconstruction error is: 55.9712
 epoch 4/50. Took 0.12921 seconds. Average reconstruction error is: 51.5922
 epoch 5/50. Took 0.12782 seconds. Average reconstruction error is: 47.4684
 epoch 6/50. Took 0.13941 seconds. Average reconstruction error is: 44.0772
 epoch 7/50. Took 0.12687 seconds. Average reconstruction error is: 41.6685
 epoch 8/50. Took 0.12783 seconds. Average reconstruction error is: 39.878
 epoch 9/50. Took 0.13331 seconds. Average reconstruction error is: 38.5756
 epoch 10/50. Took 0.12201 seconds. Average reconstruction error is: 37.5561
 epoch 11/50. Took 0.12583 seconds. Average reconstruction error is: 36.7324
 epoch 12/50. Took 0.11722 seconds. Average reconstruction error is: 36.0193
 epoch 13/50. Took 0.10514 seconds. Average reconstruction error is: 35.3286
 epoch 14/50. Took 0.10515 seconds. Average reconstruction error is: 34.6654
 epoch 15/50. Took 0.12042 seconds. Average reconstruction error is: 34.1207
 epoch 16/50. Took 0.10892 seconds. Average reconstruction error is: 33.5825
 epoch 17/50. Took 0.11345 seconds. Average reconstruction error is: 33.0791
 epoch 18/50. Took 0.12164 seconds. Average reconstruction error is: 32.6479
 epoch 19/50. Took 0.11631 seconds. Average reconstruction error is: 32.1728
 epoch 20/50. Took 0.12069 seconds. Average reconstruction error is: 31.7583
 epoch 21/50. Took 0.10958 seconds. Average reconstruction error is: 31.3998
 epoch 22/50. Took 0.11704 seconds. Average reconstruction error is: 31.0404
 epoch 23/50. Took 0.12157 seconds. Average reconstruction error is: 30.6737
 epoch 24/50. Took 0.11008 seconds. Average reconstruction error is: 30.3469
 epoch 25/50. Took 0.10516 seconds. Average reconstruction error is: 30.0484
 epoch 26/50. Took 0.10764 seconds. Average reconstruction error is: 29.7356
 epoch 27/50. Took 0.095941 seconds. Average reconstruction error is: 29.4795
 epoch 28/50. Took 0.10051 seconds. Average reconstruction error is: 29.239
 epoch 29/50. Took 0.10182 seconds. Average reconstruction error is: 29.0413
 epoch 30/50. Took 0.10844 seconds. Average reconstruction error is: 28.8223
 epoch 31/50. Took 0.1122 seconds. Average reconstruction error is: 28.629
 epoch 32/50. Took 0.11287 seconds. Average reconstruction error is: 28.4074
 epoch 33/50. Took 0.12801 seconds. Average reconstruction error is: 28.1807
 epoch 34/50. Took 0.11453 seconds. Average reconstruction error is: 28.0283
 epoch 35/50. Took 0.13572 seconds. Average reconstruction error is: 27.8708
 epoch 36/50. Took 0.11197 seconds. Average reconstruction error is: 27.7255
 epoch 37/50. Took 0.12698 seconds. Average reconstruction error is: 27.5098
 epoch 38/50. Took 0.1193 seconds. Average reconstruction error is: 27.338
 epoch 39/50. Took 0.11662 seconds. Average reconstruction error is: 27.1998
 epoch 40/50. Took 0.097329 seconds. Average reconstruction error is: 27.0028
 epoch 41/50. Took 0.09219 seconds. Average reconstruction error is: 26.9007
 epoch 42/50. Took 0.1006 seconds. Average reconstruction error is: 26.7256
 epoch 43/50. Took 0.096665 seconds. Average reconstruction error is: 26.6085
 epoch 44/50. Took 0.10127 seconds. Average reconstruction error is: 26.5334
 epoch 45/50. Took 0.095019 seconds. Average reconstruction error is: 26.3177
 epoch 46/50. Took 0.089813 seconds. Average reconstruction error is: 26.1966
 epoch 47/50. Took 0.098532 seconds. Average reconstruction error is: 26.096
 epoch 48/50. Took 0.095916 seconds. Average reconstruction error is: 26.0171
 epoch 49/50. Took 0.099991 seconds. Average reconstruction error is: 25.8109
 epoch 50/50. Took 0.099288 seconds. Average reconstruction error is: 25.7914
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.055233 seconds. 
  Full-batch training loss = 1.065003, test loss = 1.069701
  Training set accuracy = 0.724500, Test set accuracy = 0.724900
 epoch 2/200. Took 0.077088 seconds. 
  Full-batch training loss = 0.738469, test loss = 0.752727
  Training set accuracy = 0.797000, Test set accuracy = 0.792100
 epoch 3/200. Took 0.072515 seconds. 
  Full-batch training loss = 0.634706, test loss = 0.658044
  Training set accuracy = 0.819000, Test set accuracy = 0.815700
 epoch 4/200. Took 0.064357 seconds. 
  Full-batch training loss = 0.567782, test loss = 0.599613
  Training set accuracy = 0.845500, Test set accuracy = 0.835100
 epoch 5/200. Took 0.066318 seconds. 
  Full-batch training loss = 0.529839, test loss = 0.564757
  Training set accuracy = 0.860000, Test set accuracy = 0.842900
 epoch 6/200. Took 0.059121 seconds. 
  Full-batch training loss = 0.494471, test loss = 0.537768
  Training set accuracy = 0.862000, Test set accuracy = 0.847800
 epoch 7/200. Took 0.057736 seconds. 
  Full-batch training loss = 0.468022, test loss = 0.515493
  Training set accuracy = 0.871500, Test set accuracy = 0.854200
 epoch 8/200. Took 0.055999 seconds. 
  Full-batch training loss = 0.447062, test loss = 0.500817
  Training set accuracy = 0.878500, Test set accuracy = 0.858300
 epoch 9/200. Took 0.061637 seconds. 
  Full-batch training loss = 0.427074, test loss = 0.481144
  Training set accuracy = 0.885000, Test set accuracy = 0.863300
 epoch 10/200. Took 0.06089 seconds. 
  Full-batch training loss = 0.409536, test loss = 0.474216
  Training set accuracy = 0.886500, Test set accuracy = 0.862400
 epoch 11/200. Took 0.057744 seconds. 
  Full-batch training loss = 0.399851, test loss = 0.470670
  Training set accuracy = 0.889500, Test set accuracy = 0.862000
 epoch 12/200. Took 0.054805 seconds. 
  Full-batch training loss = 0.381551, test loss = 0.455652
  Training set accuracy = 0.896500, Test set accuracy = 0.868000
 epoch 13/200. Took 0.055305 seconds. 
  Full-batch training loss = 0.373873, test loss = 0.456811
  Training set accuracy = 0.898500, Test set accuracy = 0.864400
 epoch 14/200. Took 0.062485 seconds. 
  Full-batch training loss = 0.358348, test loss = 0.438269
  Training set accuracy = 0.902000, Test set accuracy = 0.873200
 epoch 15/200. Took 0.062521 seconds. 
  Full-batch training loss = 0.347930, test loss = 0.431319
  Training set accuracy = 0.905000, Test set accuracy = 0.877300
 epoch 16/200. Took 0.065064 seconds. 
  Full-batch training loss = 0.338269, test loss = 0.429123
  Training set accuracy = 0.905500, Test set accuracy = 0.876200
 epoch 17/200. Took 0.054258 seconds. 
  Full-batch training loss = 0.325881, test loss = 0.420891
  Training set accuracy = 0.909500, Test set accuracy = 0.878800
 epoch 18/200. Took 0.053008 seconds. 
  Full-batch training loss = 0.317578, test loss = 0.415014
  Training set accuracy = 0.909000, Test set accuracy = 0.880900
 epoch 19/200. Took 0.066544 seconds. 
  Full-batch training loss = 0.310672, test loss = 0.410638
  Training set accuracy = 0.917500, Test set accuracy = 0.881100
 epoch 20/200. Took 0.072804 seconds. 
  Full-batch training loss = 0.302812, test loss = 0.411105
  Training set accuracy = 0.918000, Test set accuracy = 0.878900
 epoch 21/200. Took 0.061352 seconds. 
  Full-batch training loss = 0.294023, test loss = 0.404984
  Training set accuracy = 0.918000, Test set accuracy = 0.883100
 epoch 22/200. Took 0.059181 seconds. 
  Full-batch training loss = 0.285672, test loss = 0.398705
  Training set accuracy = 0.919500, Test set accuracy = 0.885800
 epoch 23/200. Took 0.04823 seconds. 
  Full-batch training loss = 0.280858, test loss = 0.397064
  Training set accuracy = 0.923000, Test set accuracy = 0.887000
 epoch 24/200. Took 0.055868 seconds. 
  Full-batch training loss = 0.272979, test loss = 0.392742
  Training set accuracy = 0.926500, Test set accuracy = 0.887500
 epoch 25/200. Took 0.058243 seconds. 
  Full-batch training loss = 0.265921, test loss = 0.388483
  Training set accuracy = 0.925500, Test set accuracy = 0.888900
 epoch 26/200. Took 0.063515 seconds. 
  Full-batch training loss = 0.261387, test loss = 0.388552
  Training set accuracy = 0.929000, Test set accuracy = 0.889100
 epoch 27/200. Took 0.06628 seconds. 
  Full-batch training loss = 0.253649, test loss = 0.384127
  Training set accuracy = 0.931500, Test set accuracy = 0.891000
 epoch 28/200. Took 0.054317 seconds. 
  Full-batch training loss = 0.248229, test loss = 0.379909
  Training set accuracy = 0.934500, Test set accuracy = 0.892000
 epoch 29/200. Took 0.05598 seconds. 
  Full-batch training loss = 0.241746, test loss = 0.376707
  Training set accuracy = 0.938000, Test set accuracy = 0.892800
 epoch 30/200. Took 0.062376 seconds. 
  Full-batch training loss = 0.236992, test loss = 0.377152
  Training set accuracy = 0.940500, Test set accuracy = 0.892600
 epoch 31/200. Took 0.061279 seconds. 
  Full-batch training loss = 0.232131, test loss = 0.374190
  Training set accuracy = 0.941000, Test set accuracy = 0.893800
 epoch 32/200. Took 0.064111 seconds. 
  Full-batch training loss = 0.229704, test loss = 0.376448
  Training set accuracy = 0.938500, Test set accuracy = 0.888900
 epoch 33/200. Took 0.052769 seconds. 
  Full-batch training loss = 0.221811, test loss = 0.372061
  Training set accuracy = 0.943500, Test set accuracy = 0.893700
 epoch 34/200. Took 0.05358 seconds. 
  Full-batch training loss = 0.217735, test loss = 0.369627
  Training set accuracy = 0.949000, Test set accuracy = 0.894300
 epoch 35/200. Took 0.070014 seconds. 
  Full-batch training loss = 0.212203, test loss = 0.363475
  Training set accuracy = 0.950000, Test set accuracy = 0.897100
 epoch 36/200. Took 0.076145 seconds. 
  Full-batch training loss = 0.207623, test loss = 0.365442
  Training set accuracy = 0.954000, Test set accuracy = 0.895800
 epoch 37/200. Took 0.056865 seconds. 
  Full-batch training loss = 0.203504, test loss = 0.362951
  Training set accuracy = 0.955500, Test set accuracy = 0.897600
 epoch 38/200. Took 0.064718 seconds. 
  Full-batch training loss = 0.200521, test loss = 0.360296
  Training set accuracy = 0.953000, Test set accuracy = 0.897800
 epoch 39/200. Took 0.064399 seconds. 
  Full-batch training loss = 0.195457, test loss = 0.358442
  Training set accuracy = 0.956000, Test set accuracy = 0.897400
 epoch 40/200. Took 0.066334 seconds. 
  Full-batch training loss = 0.191088, test loss = 0.358231
  Training set accuracy = 0.959000, Test set accuracy = 0.898100
 epoch 41/200. Took 0.053974 seconds. 
  Full-batch training loss = 0.190855, test loss = 0.361017
  Training set accuracy = 0.957000, Test set accuracy = 0.896800
 epoch 42/200. Took 0.055027 seconds. 
  Full-batch training loss = 0.185550, test loss = 0.355353
  Training set accuracy = 0.957500, Test set accuracy = 0.899600
 epoch 43/200. Took 0.051949 seconds. 
  Full-batch training loss = 0.180641, test loss = 0.354103
  Training set accuracy = 0.960500, Test set accuracy = 0.899500
 epoch 44/200. Took 0.064811 seconds. 
  Full-batch training loss = 0.176300, test loss = 0.351300
  Training set accuracy = 0.963000, Test set accuracy = 0.899800
 epoch 45/200. Took 0.061839 seconds. 
  Full-batch training loss = 0.172975, test loss = 0.350573
  Training set accuracy = 0.964000, Test set accuracy = 0.901100
 epoch 46/200. Took 0.063441 seconds. 
  Full-batch training loss = 0.170577, test loss = 0.352205
  Training set accuracy = 0.965000, Test set accuracy = 0.899600
 epoch 47/200. Took 0.052227 seconds. 
  Full-batch training loss = 0.166198, test loss = 0.348696
  Training set accuracy = 0.966000, Test set accuracy = 0.901900
 epoch 48/200. Took 0.063425 seconds. 
  Full-batch training loss = 0.163240, test loss = 0.346267
  Training set accuracy = 0.968500, Test set accuracy = 0.903300
 epoch 49/200. Took 0.06488 seconds. 
  Full-batch training loss = 0.159930, test loss = 0.347041
  Training set accuracy = 0.970000, Test set accuracy = 0.902400
 epoch 50/200. Took 0.064194 seconds. 
  Full-batch training loss = 0.157192, test loss = 0.346205
  Training set accuracy = 0.968000, Test set accuracy = 0.901400
 epoch 51/200. Took 0.064209 seconds. 
  Full-batch training loss = 0.154386, test loss = 0.346177
  Training set accuracy = 0.969000, Test set accuracy = 0.901100
 epoch 52/200. Took 0.05729 seconds. 
  Full-batch training loss = 0.150775, test loss = 0.344666
  Training set accuracy = 0.971000, Test set accuracy = 0.901100
 epoch 53/200. Took 0.056075 seconds. 
  Full-batch training loss = 0.148112, test loss = 0.340414
  Training set accuracy = 0.971500, Test set accuracy = 0.905000
 epoch 54/200. Took 0.063858 seconds. 
  Full-batch training loss = 0.144848, test loss = 0.340803
  Training set accuracy = 0.973000, Test set accuracy = 0.904600
 epoch 55/200. Took 0.072035 seconds. 
  Full-batch training loss = 0.142955, test loss = 0.341920
  Training set accuracy = 0.973000, Test set accuracy = 0.902400
 epoch 56/200. Took 0.061798 seconds. 
  Full-batch training loss = 0.139112, test loss = 0.338695
  Training set accuracy = 0.974500, Test set accuracy = 0.904300
 epoch 57/200. Took 0.064016 seconds. 
  Full-batch training loss = 0.136983, test loss = 0.337092
  Training set accuracy = 0.975500, Test set accuracy = 0.905300
 epoch 58/200. Took 0.053205 seconds. 
  Full-batch training loss = 0.133994, test loss = 0.337791
  Training set accuracy = 0.977000, Test set accuracy = 0.904900
 epoch 59/200. Took 0.057176 seconds. 
  Full-batch training loss = 0.131954, test loss = 0.336780
  Training set accuracy = 0.976000, Test set accuracy = 0.904500
 epoch 60/200. Took 0.061549 seconds. 
  Full-batch training loss = 0.129334, test loss = 0.338258
  Training set accuracy = 0.977500, Test set accuracy = 0.903200
 epoch 61/200. Took 0.061778 seconds. 
  Full-batch training loss = 0.126590, test loss = 0.335670
  Training set accuracy = 0.978000, Test set accuracy = 0.905100
 epoch 62/200. Took 0.062328 seconds. 
  Full-batch training loss = 0.124159, test loss = 0.334693
  Training set accuracy = 0.978500, Test set accuracy = 0.904900
 epoch 63/200. Took 0.048732 seconds. 
  Full-batch training loss = 0.122081, test loss = 0.335471
  Training set accuracy = 0.979000, Test set accuracy = 0.905000
 epoch 64/200. Took 0.054062 seconds. 
  Full-batch training loss = 0.119441, test loss = 0.334029
  Training set accuracy = 0.979000, Test set accuracy = 0.905700
 epoch 65/200. Took 0.055183 seconds. 
  Full-batch training loss = 0.117182, test loss = 0.333909
  Training set accuracy = 0.980500, Test set accuracy = 0.905400
 epoch 66/200. Took 0.049656 seconds. 
  Full-batch training loss = 0.114879, test loss = 0.332339
  Training set accuracy = 0.980000, Test set accuracy = 0.906100
 epoch 67/200. Took 0.056116 seconds. 
  Full-batch training loss = 0.112753, test loss = 0.333052
  Training set accuracy = 0.981500, Test set accuracy = 0.906100
 epoch 68/200. Took 0.056768 seconds. 
  Full-batch training loss = 0.110790, test loss = 0.332326
  Training set accuracy = 0.982500, Test set accuracy = 0.906000
 epoch 69/200. Took 0.053373 seconds. 
  Full-batch training loss = 0.108831, test loss = 0.330849
  Training set accuracy = 0.982500, Test set accuracy = 0.906100
 epoch 70/200. Took 0.057352 seconds. 
  Full-batch training loss = 0.106590, test loss = 0.331823
  Training set accuracy = 0.983000, Test set accuracy = 0.906300
 epoch 71/200. Took 0.045307 seconds. 
  Full-batch training loss = 0.104803, test loss = 0.331295
  Training set accuracy = 0.983500, Test set accuracy = 0.906100
 epoch 72/200. Took 0.0566 seconds. 
  Full-batch training loss = 0.102874, test loss = 0.330759
  Training set accuracy = 0.983000, Test set accuracy = 0.907300
 epoch 73/200. Took 0.052655 seconds. 
  Full-batch training loss = 0.100819, test loss = 0.330016
  Training set accuracy = 0.984000, Test set accuracy = 0.908200
 epoch 74/200. Took 0.0462 seconds. 
  Full-batch training loss = 0.098858, test loss = 0.329492
  Training set accuracy = 0.983000, Test set accuracy = 0.907400
 epoch 75/200. Took 0.051032 seconds. 
  Full-batch training loss = 0.097130, test loss = 0.330675
  Training set accuracy = 0.985000, Test set accuracy = 0.908100
 epoch 76/200. Took 0.054117 seconds. 
  Full-batch training loss = 0.095437, test loss = 0.327487
  Training set accuracy = 0.984500, Test set accuracy = 0.908700
 epoch 77/200. Took 0.057082 seconds. 
  Full-batch training loss = 0.093455, test loss = 0.329443
  Training set accuracy = 0.984500, Test set accuracy = 0.908200
 epoch 78/200. Took 0.055753 seconds. 
  Full-batch training loss = 0.091914, test loss = 0.327625
  Training set accuracy = 0.985000, Test set accuracy = 0.908900
 epoch 79/200. Took 0.060672 seconds. 
  Full-batch training loss = 0.090080, test loss = 0.328463
  Training set accuracy = 0.985500, Test set accuracy = 0.908300
 epoch 80/200. Took 0.058972 seconds. 
  Full-batch training loss = 0.088847, test loss = 0.328257
  Training set accuracy = 0.986000, Test set accuracy = 0.908500
 epoch 81/200. Took 0.057693 seconds. 
  Full-batch training loss = 0.086998, test loss = 0.328155
  Training set accuracy = 0.987000, Test set accuracy = 0.908400
 epoch 82/200. Took 0.05645 seconds. 
  Full-batch training loss = 0.085358, test loss = 0.327977
  Training set accuracy = 0.987000, Test set accuracy = 0.908300
 epoch 83/200. Took 0.059248 seconds. 
  Full-batch training loss = 0.083975, test loss = 0.327406
  Training set accuracy = 0.986000, Test set accuracy = 0.909200
 epoch 84/200. Took 0.054765 seconds. 
  Full-batch training loss = 0.082449, test loss = 0.326859
  Training set accuracy = 0.987500, Test set accuracy = 0.909200
 epoch 85/200. Took 0.059551 seconds. 
  Full-batch training loss = 0.081336, test loss = 0.325800
  Training set accuracy = 0.986500, Test set accuracy = 0.908700
 epoch 86/200. Took 0.059117 seconds. 
  Full-batch training loss = 0.079529, test loss = 0.327138
  Training set accuracy = 0.988000, Test set accuracy = 0.909200
 epoch 87/200. Took 0.060554 seconds. 
  Full-batch training loss = 0.078050, test loss = 0.326470
  Training set accuracy = 0.988500, Test set accuracy = 0.909200
 epoch 88/200. Took 0.056053 seconds. 
  Full-batch training loss = 0.076910, test loss = 0.326421
  Training set accuracy = 0.988500, Test set accuracy = 0.909300
 epoch 89/200. Took 0.056064 seconds. 
  Full-batch training loss = 0.075422, test loss = 0.325523
  Training set accuracy = 0.989000, Test set accuracy = 0.909600
 epoch 90/200. Took 0.057028 seconds. 
  Full-batch training loss = 0.074170, test loss = 0.327169
  Training set accuracy = 0.989000, Test set accuracy = 0.908600
 epoch 91/200. Took 0.053197 seconds. 
  Full-batch training loss = 0.072723, test loss = 0.325440
  Training set accuracy = 0.989500, Test set accuracy = 0.909600
 epoch 92/200. Took 0.052951 seconds. 
  Full-batch training loss = 0.071569, test loss = 0.326030
  Training set accuracy = 0.989000, Test set accuracy = 0.909800
 epoch 93/200. Took 0.053215 seconds. 
  Full-batch training loss = 0.070342, test loss = 0.325278
  Training set accuracy = 0.989500, Test set accuracy = 0.910200
 epoch 94/200. Took 0.055034 seconds. 
  Full-batch training loss = 0.069019, test loss = 0.325027
  Training set accuracy = 0.989000, Test set accuracy = 0.910100
 epoch 95/200. Took 0.056164 seconds. 
  Full-batch training loss = 0.067998, test loss = 0.326155
  Training set accuracy = 0.989500, Test set accuracy = 0.910100
 epoch 96/200. Took 0.061565 seconds. 
  Full-batch training loss = 0.066727, test loss = 0.325203
  Training set accuracy = 0.990500, Test set accuracy = 0.909600
 epoch 97/200. Took 0.054804 seconds. 
  Full-batch training loss = 0.065555, test loss = 0.323456
  Training set accuracy = 0.990500, Test set accuracy = 0.910700
 epoch 98/200. Took 0.058474 seconds. 
  Full-batch training loss = 0.064368, test loss = 0.324503
  Training set accuracy = 0.990000, Test set accuracy = 0.910500
 epoch 99/200. Took 0.053881 seconds. 
  Full-batch training loss = 0.063402, test loss = 0.324664
  Training set accuracy = 0.990000, Test set accuracy = 0.910800
 epoch 100/200. Took 0.055553 seconds. 
  Full-batch training loss = 0.062325, test loss = 0.324722
  Training set accuracy = 0.990500, Test set accuracy = 0.910300
 epoch 101/200. Took 0.058342 seconds. 
  Full-batch training loss = 0.061267, test loss = 0.323779
  Training set accuracy = 0.990000, Test set accuracy = 0.911100
 epoch 102/200. Took 0.06022 seconds. 
  Full-batch training loss = 0.060354, test loss = 0.324195
  Training set accuracy = 0.991500, Test set accuracy = 0.911100
 epoch 103/200. Took 0.054021 seconds. 
  Full-batch training loss = 0.059276, test loss = 0.324817
  Training set accuracy = 0.992000, Test set accuracy = 0.911100
 epoch 104/200. Took 0.056388 seconds. 
  Full-batch training loss = 0.058474, test loss = 0.323967
  Training set accuracy = 0.991000, Test set accuracy = 0.910900
 epoch 105/200. Took 0.051555 seconds. 
  Full-batch training loss = 0.057439, test loss = 0.323822
  Training set accuracy = 0.992000, Test set accuracy = 0.911700
 epoch 106/200. Took 0.0562 seconds. 
  Full-batch training loss = 0.056626, test loss = 0.325440
  Training set accuracy = 0.993000, Test set accuracy = 0.911400
 epoch 107/200. Took 0.10971 seconds. 
  Full-batch training loss = 0.055661, test loss = 0.324531
  Training set accuracy = 0.993500, Test set accuracy = 0.911100
 epoch 108/200. Took 0.057107 seconds. 
  Full-batch training loss = 0.054801, test loss = 0.324468
  Training set accuracy = 0.994000, Test set accuracy = 0.911700
 epoch 109/200. Took 0.054159 seconds. 
  Full-batch training loss = 0.054097, test loss = 0.324013
  Training set accuracy = 0.994500, Test set accuracy = 0.911800
 epoch 110/200. Took 0.054034 seconds. 
  Full-batch training loss = 0.053209, test loss = 0.324058
  Training set accuracy = 0.995000, Test set accuracy = 0.911400
 epoch 111/200. Took 0.05649 seconds. 
  Full-batch training loss = 0.052350, test loss = 0.324282
  Training set accuracy = 0.995500, Test set accuracy = 0.912200
 epoch 112/200. Took 0.055937 seconds. 
  Full-batch training loss = 0.051637, test loss = 0.324702
  Training set accuracy = 0.995000, Test set accuracy = 0.911600
 epoch 113/200. Took 0.05039 seconds. 
  Full-batch training loss = 0.050896, test loss = 0.324634
  Training set accuracy = 0.996500, Test set accuracy = 0.911500
 epoch 114/200. Took 0.055636 seconds. 
  Full-batch training loss = 0.050111, test loss = 0.325035
  Training set accuracy = 0.995500, Test set accuracy = 0.911800
 epoch 115/200. Took 0.052861 seconds. 
  Full-batch training loss = 0.049394, test loss = 0.324298
  Training set accuracy = 0.996500, Test set accuracy = 0.912200
 epoch 116/200. Took 0.054643 seconds. 
  Full-batch training loss = 0.048771, test loss = 0.324745
  Training set accuracy = 0.997000, Test set accuracy = 0.911900
 epoch 117/200. Took 0.057057 seconds. 
  Full-batch training loss = 0.047999, test loss = 0.325177
  Training set accuracy = 0.997000, Test set accuracy = 0.911800
 epoch 118/200. Took 0.061454 seconds. 
  Full-batch training loss = 0.047343, test loss = 0.324470
  Training set accuracy = 0.997000, Test set accuracy = 0.911900
 epoch 119/200. Took 0.052539 seconds. 
  Full-batch training loss = 0.046702, test loss = 0.324490
  Training set accuracy = 0.997000, Test set accuracy = 0.912200
 epoch 120/200. Took 0.055015 seconds. 
  Full-batch training loss = 0.046041, test loss = 0.325230
  Training set accuracy = 0.997000, Test set accuracy = 0.911800
 epoch 121/200. Took 0.057247 seconds. 
  Full-batch training loss = 0.045431, test loss = 0.324615
  Training set accuracy = 0.997000, Test set accuracy = 0.912100
 epoch 122/200. Took 0.05681 seconds. 
  Full-batch training loss = 0.044847, test loss = 0.324897
  Training set accuracy = 0.997000, Test set accuracy = 0.912200
 epoch 123/200. Took 0.056632 seconds. 
  Full-batch training loss = 0.044238, test loss = 0.325607
  Training set accuracy = 0.997000, Test set accuracy = 0.911900
 epoch 124/200. Took 0.052374 seconds. 
  Full-batch training loss = 0.043608, test loss = 0.325731
  Training set accuracy = 0.997000, Test set accuracy = 0.911900
 epoch 125/200. Took 0.064124 seconds. 
  Full-batch training loss = 0.043065, test loss = 0.325769
  Training set accuracy = 0.997000, Test set accuracy = 0.911700
 epoch 126/200. Took 0.053481 seconds. 
  Full-batch training loss = 0.042463, test loss = 0.325090
  Training set accuracy = 0.997000, Test set accuracy = 0.912200
 epoch 127/200. Took 0.053914 seconds. 
  Full-batch training loss = 0.041929, test loss = 0.325590
  Training set accuracy = 0.997000, Test set accuracy = 0.912400
 epoch 128/200. Took 0.056452 seconds. 
  Full-batch training loss = 0.041456, test loss = 0.326156
  Training set accuracy = 0.997000, Test set accuracy = 0.911900
 epoch 129/200. Took 0.060897 seconds. 
  Full-batch training loss = 0.040867, test loss = 0.325088
  Training set accuracy = 0.997000, Test set accuracy = 0.912600
 epoch 130/200. Took 0.050434 seconds. 
  Full-batch training loss = 0.040346, test loss = 0.325568
  Training set accuracy = 0.997000, Test set accuracy = 0.912200
 epoch 131/200. Took 0.057823 seconds. 
  Full-batch training loss = 0.039893, test loss = 0.326406
  Training set accuracy = 0.997500, Test set accuracy = 0.912200
 epoch 132/200. Took 0.048615 seconds. 
  Full-batch training loss = 0.039365, test loss = 0.325800
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 133/200. Took 0.063067 seconds. 
  Full-batch training loss = 0.038880, test loss = 0.325740
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 134/200. Took 0.053053 seconds. 
  Full-batch training loss = 0.038388, test loss = 0.325903
  Training set accuracy = 0.997500, Test set accuracy = 0.912300
 epoch 135/200. Took 0.056197 seconds. 
  Full-batch training loss = 0.037957, test loss = 0.325621
  Training set accuracy = 0.997500, Test set accuracy = 0.912300
 epoch 136/200. Took 0.056393 seconds. 
  Full-batch training loss = 0.037510, test loss = 0.326719
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 137/200. Took 0.056877 seconds. 
  Full-batch training loss = 0.037018, test loss = 0.326514
  Training set accuracy = 0.997500, Test set accuracy = 0.912200
 epoch 138/200. Took 0.052559 seconds. 
  Full-batch training loss = 0.036608, test loss = 0.326718
  Training set accuracy = 0.997500, Test set accuracy = 0.912800
 epoch 139/200. Took 0.052585 seconds. 
  Full-batch training loss = 0.036181, test loss = 0.326922
  Training set accuracy = 0.997500, Test set accuracy = 0.912200
 epoch 140/200. Took 0.050349 seconds. 
  Full-batch training loss = 0.035761, test loss = 0.326683
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 141/200. Took 0.054885 seconds. 
  Full-batch training loss = 0.035335, test loss = 0.326632
  Training set accuracy = 0.997500, Test set accuracy = 0.911900
 epoch 142/200. Took 0.0528 seconds. 
  Full-batch training loss = 0.034930, test loss = 0.327116
  Training set accuracy = 0.997500, Test set accuracy = 0.912200
 epoch 143/200. Took 0.05122 seconds. 
  Full-batch training loss = 0.034507, test loss = 0.327279
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 144/200. Took 0.048186 seconds. 
  Full-batch training loss = 0.034139, test loss = 0.326765
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 145/200. Took 0.055601 seconds. 
  Full-batch training loss = 0.033731, test loss = 0.327493
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 146/200. Took 0.062042 seconds. 
  Full-batch training loss = 0.033369, test loss = 0.327595
  Training set accuracy = 0.997500, Test set accuracy = 0.912600
 epoch 147/200. Took 0.061959 seconds. 
  Full-batch training loss = 0.032993, test loss = 0.327913
  Training set accuracy = 0.997500, Test set accuracy = 0.912400
 epoch 148/200. Took 0.051254 seconds. 
  Full-batch training loss = 0.032627, test loss = 0.327927
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 149/200. Took 0.053352 seconds. 
  Full-batch training loss = 0.032259, test loss = 0.327850
  Training set accuracy = 0.997500, Test set accuracy = 0.912400
 epoch 150/200. Took 0.054166 seconds. 
  Full-batch training loss = 0.031914, test loss = 0.328060
  Training set accuracy = 0.997500, Test set accuracy = 0.912000
 epoch 151/200. Took 0.054595 seconds. 
  Full-batch training loss = 0.031589, test loss = 0.328382
  Training set accuracy = 0.997500, Test set accuracy = 0.912300
 epoch 152/200. Took 0.050426 seconds. 
  Full-batch training loss = 0.031225, test loss = 0.328208
  Training set accuracy = 0.997500, Test set accuracy = 0.912200
 epoch 153/200. Took 0.056319 seconds. 
  Full-batch training loss = 0.030915, test loss = 0.328580
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 154/200. Took 0.06027 seconds. 
  Full-batch training loss = 0.030581, test loss = 0.328710
  Training set accuracy = 0.997500, Test set accuracy = 0.912000
 epoch 155/200. Took 0.054942 seconds. 
  Full-batch training loss = 0.030267, test loss = 0.328466
  Training set accuracy = 0.997500, Test set accuracy = 0.912300
 epoch 156/200. Took 0.065244 seconds. 
  Full-batch training loss = 0.029930, test loss = 0.329016
  Training set accuracy = 0.997500, Test set accuracy = 0.912600
 epoch 157/200. Took 0.054426 seconds. 
  Full-batch training loss = 0.029619, test loss = 0.329077
  Training set accuracy = 0.997500, Test set accuracy = 0.912700
 epoch 158/200. Took 0.054851 seconds. 
  Full-batch training loss = 0.029315, test loss = 0.328901
  Training set accuracy = 0.997500, Test set accuracy = 0.912700
 epoch 159/200. Took 0.056013 seconds. 
  Full-batch training loss = 0.029017, test loss = 0.328940
  Training set accuracy = 0.997500, Test set accuracy = 0.912300
 epoch 160/200. Took 0.055273 seconds. 
  Full-batch training loss = 0.028719, test loss = 0.329823
  Training set accuracy = 0.997500, Test set accuracy = 0.912700
 epoch 161/200. Took 0.050888 seconds. 
  Full-batch training loss = 0.028429, test loss = 0.329285
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 162/200. Took 0.055181 seconds. 
  Full-batch training loss = 0.028132, test loss = 0.329576
  Training set accuracy = 0.997500, Test set accuracy = 0.912700
 epoch 163/200. Took 0.055588 seconds. 
  Full-batch training loss = 0.027851, test loss = 0.330137
  Training set accuracy = 0.997500, Test set accuracy = 0.912600
 epoch 164/200. Took 0.056652 seconds. 
  Full-batch training loss = 0.027570, test loss = 0.329550
  Training set accuracy = 0.997500, Test set accuracy = 0.912600
 epoch 165/200. Took 0.056933 seconds. 
  Full-batch training loss = 0.027294, test loss = 0.330437
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 166/200. Took 0.053788 seconds. 
  Full-batch training loss = 0.027035, test loss = 0.330436
  Training set accuracy = 0.997500, Test set accuracy = 0.912500
 epoch 167/200. Took 0.063924 seconds. 
  Full-batch training loss = 0.026770, test loss = 0.330468
  Training set accuracy = 0.997500, Test set accuracy = 0.912700
 epoch 168/200. Took 0.05443 seconds. 
  Full-batch training loss = 0.026532, test loss = 0.331083
  Training set accuracy = 0.997500, Test set accuracy = 0.912600
 epoch 169/200. Took 0.04987 seconds. 
  Full-batch training loss = 0.026255, test loss = 0.330737
  Training set accuracy = 0.997500, Test set accuracy = 0.912100
 epoch 170/200. Took 0.054232 seconds. 
  Full-batch training loss = 0.026008, test loss = 0.330966
  Training set accuracy = 0.998000, Test set accuracy = 0.912800
 epoch 171/200. Took 0.0553 seconds. 
  Full-batch training loss = 0.025742, test loss = 0.330780
  Training set accuracy = 0.998000, Test set accuracy = 0.912600
 epoch 172/200. Took 0.056117 seconds. 
  Full-batch training loss = 0.025502, test loss = 0.330757
  Training set accuracy = 0.998000, Test set accuracy = 0.913300
 epoch 173/200. Took 0.058194 seconds. 
  Full-batch training loss = 0.025261, test loss = 0.331437
  Training set accuracy = 0.998000, Test set accuracy = 0.912900
 epoch 174/200. Took 0.05623 seconds. 
  Full-batch training loss = 0.025016, test loss = 0.331621
  Training set accuracy = 0.998000, Test set accuracy = 0.913000
 epoch 175/200. Took 0.053186 seconds. 
  Full-batch training loss = 0.024794, test loss = 0.331163
  Training set accuracy = 0.998000, Test set accuracy = 0.912100
 epoch 176/200. Took 0.055493 seconds. 
  Full-batch training loss = 0.024565, test loss = 0.331832
  Training set accuracy = 0.998000, Test set accuracy = 0.913200
 epoch 177/200. Took 0.053475 seconds. 
  Full-batch training loss = 0.024331, test loss = 0.332091
  Training set accuracy = 0.997500, Test set accuracy = 0.913100
 epoch 178/200. Took 0.055557 seconds. 
  Full-batch training loss = 0.024101, test loss = 0.332297
  Training set accuracy = 0.998000, Test set accuracy = 0.913000
 epoch 179/200. Took 0.05623 seconds. 
  Full-batch training loss = 0.023876, test loss = 0.332111
  Training set accuracy = 0.998000, Test set accuracy = 0.912600
 epoch 180/200. Took 0.056402 seconds. 
  Full-batch training loss = 0.023692, test loss = 0.332592
  Training set accuracy = 0.998000, Test set accuracy = 0.913100
 epoch 181/200. Took 0.050464 seconds. 
  Full-batch training loss = 0.023459, test loss = 0.332354
  Training set accuracy = 0.998500, Test set accuracy = 0.913200
 epoch 182/200. Took 0.055951 seconds. 
  Full-batch training loss = 0.023245, test loss = 0.332533
  Training set accuracy = 0.998500, Test set accuracy = 0.913200
 epoch 183/200. Took 0.055599 seconds. 
  Full-batch training loss = 0.023035, test loss = 0.332389
  Training set accuracy = 0.998500, Test set accuracy = 0.912800
 epoch 184/200. Took 0.051883 seconds. 
  Full-batch training loss = 0.022853, test loss = 0.333364
  Training set accuracy = 0.998500, Test set accuracy = 0.912800
 epoch 185/200. Took 0.05654 seconds. 
  Full-batch training loss = 0.022622, test loss = 0.333183
  Training set accuracy = 0.998500, Test set accuracy = 0.912700
 epoch 186/200. Took 0.053525 seconds. 
  Full-batch training loss = 0.022433, test loss = 0.333280
  Training set accuracy = 0.998500, Test set accuracy = 0.912800
 epoch 187/200. Took 0.053011 seconds. 
  Full-batch training loss = 0.022235, test loss = 0.333308
  Training set accuracy = 0.999000, Test set accuracy = 0.912800
 epoch 188/200. Took 0.056123 seconds. 
  Full-batch training loss = 0.022037, test loss = 0.333778
  Training set accuracy = 0.999000, Test set accuracy = 0.913300
 epoch 189/200. Took 0.052326 seconds. 
  Full-batch training loss = 0.021841, test loss = 0.333843
  Training set accuracy = 0.999000, Test set accuracy = 0.913000
 epoch 190/200. Took 0.049195 seconds. 
  Full-batch training loss = 0.021655, test loss = 0.333836
  Training set accuracy = 0.999000, Test set accuracy = 0.913400
 epoch 191/200. Took 0.058747 seconds. 
  Full-batch training loss = 0.021468, test loss = 0.333526
  Training set accuracy = 0.999000, Test set accuracy = 0.913400
 epoch 192/200. Took 0.060152 seconds. 
  Full-batch training loss = 0.021289, test loss = 0.334122
  Training set accuracy = 0.999000, Test set accuracy = 0.912700
 epoch 193/200. Took 0.055665 seconds. 
  Full-batch training loss = 0.021112, test loss = 0.333877
  Training set accuracy = 0.999000, Test set accuracy = 0.913700
 epoch 194/200. Took 0.058472 seconds. 
  Full-batch training loss = 0.020931, test loss = 0.334559
  Training set accuracy = 0.999000, Test set accuracy = 0.913500
 epoch 195/200. Took 0.055502 seconds. 
  Full-batch training loss = 0.020750, test loss = 0.334576
  Training set accuracy = 0.999000, Test set accuracy = 0.913400
 epoch 196/200. Took 0.058314 seconds. 
  Full-batch training loss = 0.020583, test loss = 0.334571
  Training set accuracy = 0.999000, Test set accuracy = 0.913500
 epoch 197/200. Took 0.071574 seconds. 
  Full-batch training loss = 0.020407, test loss = 0.334655
  Training set accuracy = 0.999000, Test set accuracy = 0.913400
 epoch 198/200. Took 0.059917 seconds. 
  Full-batch training loss = 0.020242, test loss = 0.334896
  Training set accuracy = 0.999000, Test set accuracy = 0.913800
 epoch 199/200. Took 0.054637 seconds. 
  Full-batch training loss = 0.020078, test loss = 0.334607
  Training set accuracy = 0.999500, Test set accuracy = 0.913300
 epoch 200/200. Took 0.054734 seconds. 
  Full-batch training loss = 0.019921, test loss = 0.335312
  Training set accuracy = 0.999000, Test set accuracy = 0.914100
Elapsed time is 60.055324 seconds.
End Training

learningRateRBM =

   1.0000e-03

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.090186 seconds. Average reconstruction error is: 164.5598
 epoch 2/20. Took 0.097423 seconds. Average reconstruction error is: 134.1564
 epoch 3/20. Took 0.095989 seconds. Average reconstruction error is: 108.9698
 epoch 4/20. Took 0.096611 seconds. Average reconstruction error is: 90.8662
 epoch 5/20. Took 0.10072 seconds. Average reconstruction error is: 81.2025
 epoch 6/20. Took 0.096529 seconds. Average reconstruction error is: 75.6994
 epoch 7/20. Took 0.09102 seconds. Average reconstruction error is: 71.925
 epoch 8/20. Took 0.096005 seconds. Average reconstruction error is: 69.2494
 epoch 9/20. Took 0.09662 seconds. Average reconstruction error is: 67.1942
 epoch 10/20. Took 0.098578 seconds. Average reconstruction error is: 65.5687
 epoch 11/20. Took 0.097462 seconds. Average reconstruction error is: 64.2188
 epoch 12/20. Took 0.10405 seconds. Average reconstruction error is: 63.2012
 epoch 13/20. Took 0.092176 seconds. Average reconstruction error is: 62.1109
 epoch 14/20. Took 0.098068 seconds. Average reconstruction error is: 61.2196
 epoch 15/20. Took 0.099614 seconds. Average reconstruction error is: 60.3057
 epoch 16/20. Took 0.092532 seconds. Average reconstruction error is: 59.6817
 epoch 17/20. Took 0.099085 seconds. Average reconstruction error is: 59.0606
 epoch 18/20. Took 0.094275 seconds. Average reconstruction error is: 58.4864
 epoch 19/20. Took 0.096377 seconds. Average reconstruction error is: 57.7527
 epoch 20/20. Took 0.094266 seconds. Average reconstruction error is: 57.2477
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.058344 seconds. 
  Full-batch training loss = 1.958058, test loss = 1.953646
  Training set accuracy = 0.328500, Test set accuracy = 0.314300
 epoch 2/200. Took 0.056102 seconds. 
  Full-batch training loss = 1.425779, test loss = 1.401184
  Training set accuracy = 0.677500, Test set accuracy = 0.695900
 epoch 3/200. Took 0.052694 seconds. 
  Full-batch training loss = 1.047550, test loss = 1.026110
  Training set accuracy = 0.765500, Test set accuracy = 0.769600
 epoch 4/200. Took 0.05174 seconds. 
  Full-batch training loss = 0.823841, test loss = 0.804864
  Training set accuracy = 0.801500, Test set accuracy = 0.805600
 epoch 5/200. Took 0.05068 seconds. 
  Full-batch training loss = 0.693924, test loss = 0.688206
  Training set accuracy = 0.841500, Test set accuracy = 0.832600
 epoch 6/200. Took 0.054319 seconds. 
  Full-batch training loss = 0.598369, test loss = 0.598461
  Training set accuracy = 0.858000, Test set accuracy = 0.848700
 epoch 7/200. Took 0.055644 seconds. 
  Full-batch training loss = 0.532263, test loss = 0.536748
  Training set accuracy = 0.869000, Test set accuracy = 0.865600
 epoch 8/200. Took 0.055566 seconds. 
  Full-batch training loss = 0.480931, test loss = 0.490305
  Training set accuracy = 0.881000, Test set accuracy = 0.875800
 epoch 9/200. Took 0.049669 seconds. 
  Full-batch training loss = 0.444247, test loss = 0.466262
  Training set accuracy = 0.889500, Test set accuracy = 0.879500
 epoch 10/200. Took 0.054782 seconds. 
  Full-batch training loss = 0.411232, test loss = 0.440008
  Training set accuracy = 0.898500, Test set accuracy = 0.884200
 epoch 11/200. Took 0.055746 seconds. 
  Full-batch training loss = 0.386940, test loss = 0.418791
  Training set accuracy = 0.903000, Test set accuracy = 0.887500
 epoch 12/200. Took 0.053045 seconds. 
  Full-batch training loss = 0.365332, test loss = 0.408537
  Training set accuracy = 0.906000, Test set accuracy = 0.886700
 epoch 13/200. Took 0.058334 seconds. 
  Full-batch training loss = 0.344498, test loss = 0.390833
  Training set accuracy = 0.909000, Test set accuracy = 0.889400
 epoch 14/200. Took 0.051034 seconds. 
  Full-batch training loss = 0.332323, test loss = 0.382477
  Training set accuracy = 0.911500, Test set accuracy = 0.889200
 epoch 15/200. Took 0.051619 seconds. 
  Full-batch training loss = 0.314210, test loss = 0.372540
  Training set accuracy = 0.925000, Test set accuracy = 0.894200
 epoch 16/200. Took 0.058947 seconds. 
  Full-batch training loss = 0.305997, test loss = 0.371578
  Training set accuracy = 0.923500, Test set accuracy = 0.892000
 epoch 17/200. Took 0.063474 seconds. 
  Full-batch training loss = 0.287861, test loss = 0.357519
  Training set accuracy = 0.931500, Test set accuracy = 0.894800
 epoch 18/200. Took 0.056972 seconds. 
  Full-batch training loss = 0.278568, test loss = 0.353323
  Training set accuracy = 0.934500, Test set accuracy = 0.896600
 epoch 19/200. Took 0.055039 seconds. 
  Full-batch training loss = 0.264678, test loss = 0.344787
  Training set accuracy = 0.938500, Test set accuracy = 0.897400
 epoch 20/200. Took 0.055438 seconds. 
  Full-batch training loss = 0.256153, test loss = 0.341028
  Training set accuracy = 0.939000, Test set accuracy = 0.899700
 epoch 21/200. Took 0.051186 seconds. 
  Full-batch training loss = 0.248969, test loss = 0.342253
  Training set accuracy = 0.942000, Test set accuracy = 0.897800
 epoch 22/200. Took 0.055617 seconds. 
  Full-batch training loss = 0.241396, test loss = 0.336024
  Training set accuracy = 0.941000, Test set accuracy = 0.900200
 epoch 23/200. Took 0.055115 seconds. 
  Full-batch training loss = 0.231033, test loss = 0.330654
  Training set accuracy = 0.942500, Test set accuracy = 0.900300
 epoch 24/200. Took 0.054785 seconds. 
  Full-batch training loss = 0.224473, test loss = 0.331226
  Training set accuracy = 0.943500, Test set accuracy = 0.899300
 epoch 25/200. Took 0.056941 seconds. 
  Full-batch training loss = 0.217042, test loss = 0.327533
  Training set accuracy = 0.944500, Test set accuracy = 0.901900
 epoch 26/200. Took 0.054697 seconds. 
  Full-batch training loss = 0.208454, test loss = 0.322804
  Training set accuracy = 0.952000, Test set accuracy = 0.903600
 epoch 27/200. Took 0.051091 seconds. 
  Full-batch training loss = 0.203213, test loss = 0.322566
  Training set accuracy = 0.954500, Test set accuracy = 0.900800
 epoch 28/200. Took 0.05131 seconds. 
  Full-batch training loss = 0.197497, test loss = 0.317305
  Training set accuracy = 0.952000, Test set accuracy = 0.903400
 epoch 29/200. Took 0.052243 seconds. 
  Full-batch training loss = 0.190764, test loss = 0.318876
  Training set accuracy = 0.954000, Test set accuracy = 0.903900
 epoch 30/200. Took 0.055653 seconds. 
  Full-batch training loss = 0.184393, test loss = 0.317169
  Training set accuracy = 0.958000, Test set accuracy = 0.904600
 epoch 31/200. Took 0.054034 seconds. 
  Full-batch training loss = 0.179740, test loss = 0.315833
  Training set accuracy = 0.957500, Test set accuracy = 0.905400
 epoch 32/200. Took 0.059143 seconds. 
  Full-batch training loss = 0.173594, test loss = 0.313713
  Training set accuracy = 0.960500, Test set accuracy = 0.906500
 epoch 33/200. Took 0.053876 seconds. 
  Full-batch training loss = 0.169196, test loss = 0.311519
  Training set accuracy = 0.962000, Test set accuracy = 0.905200
 epoch 34/200. Took 0.058634 seconds. 
  Full-batch training loss = 0.165037, test loss = 0.312509
  Training set accuracy = 0.961000, Test set accuracy = 0.906500
 epoch 35/200. Took 0.057696 seconds. 
  Full-batch training loss = 0.158575, test loss = 0.308761
  Training set accuracy = 0.966000, Test set accuracy = 0.906200
 epoch 36/200. Took 0.055241 seconds. 
  Full-batch training loss = 0.154566, test loss = 0.307971
  Training set accuracy = 0.966000, Test set accuracy = 0.907600
 epoch 37/200. Took 0.053625 seconds. 
  Full-batch training loss = 0.151020, test loss = 0.309490
  Training set accuracy = 0.967500, Test set accuracy = 0.906500
 epoch 38/200. Took 0.049431 seconds. 
  Full-batch training loss = 0.145127, test loss = 0.306565
  Training set accuracy = 0.969500, Test set accuracy = 0.906500
 epoch 39/200. Took 0.057926 seconds. 
  Full-batch training loss = 0.143725, test loss = 0.308658
  Training set accuracy = 0.971000, Test set accuracy = 0.906800
 epoch 40/200. Took 0.046855 seconds. 
  Full-batch training loss = 0.136958, test loss = 0.306183
  Training set accuracy = 0.971500, Test set accuracy = 0.906300
 epoch 41/200. Took 0.04987 seconds. 
  Full-batch training loss = 0.133224, test loss = 0.303327
  Training set accuracy = 0.972500, Test set accuracy = 0.908300
 epoch 42/200. Took 0.049818 seconds. 
  Full-batch training loss = 0.130684, test loss = 0.303915
  Training set accuracy = 0.972000, Test set accuracy = 0.908600
 epoch 43/200. Took 0.056974 seconds. 
  Full-batch training loss = 0.127581, test loss = 0.305620
  Training set accuracy = 0.975000, Test set accuracy = 0.907400
 epoch 44/200. Took 0.054886 seconds. 
  Full-batch training loss = 0.122322, test loss = 0.301699
  Training set accuracy = 0.976500, Test set accuracy = 0.908500
 epoch 45/200. Took 0.054211 seconds. 
  Full-batch training loss = 0.119961, test loss = 0.305252
  Training set accuracy = 0.979500, Test set accuracy = 0.906100
 epoch 46/200. Took 0.056712 seconds. 
  Full-batch training loss = 0.117534, test loss = 0.303771
  Training set accuracy = 0.979500, Test set accuracy = 0.908700
 epoch 47/200. Took 0.057061 seconds. 
  Full-batch training loss = 0.112372, test loss = 0.300841
  Training set accuracy = 0.978500, Test set accuracy = 0.909000
 epoch 48/200. Took 0.053626 seconds. 
  Full-batch training loss = 0.110880, test loss = 0.303389
  Training set accuracy = 0.980500, Test set accuracy = 0.907900
 epoch 49/200. Took 0.054135 seconds. 
  Full-batch training loss = 0.108256, test loss = 0.304529
  Training set accuracy = 0.981500, Test set accuracy = 0.908600
 epoch 50/200. Took 0.055988 seconds. 
  Full-batch training loss = 0.103434, test loss = 0.299009
  Training set accuracy = 0.983500, Test set accuracy = 0.910800
 epoch 51/200. Took 0.056545 seconds. 
  Full-batch training loss = 0.100932, test loss = 0.300843
  Training set accuracy = 0.986500, Test set accuracy = 0.908800
 epoch 52/200. Took 0.057319 seconds. 
  Full-batch training loss = 0.099022, test loss = 0.301076
  Training set accuracy = 0.984000, Test set accuracy = 0.908900
 epoch 53/200. Took 0.056635 seconds. 
  Full-batch training loss = 0.096615, test loss = 0.302544
  Training set accuracy = 0.986000, Test set accuracy = 0.907900
 epoch 54/200. Took 0.053303 seconds. 
  Full-batch training loss = 0.096069, test loss = 0.302317
  Training set accuracy = 0.984500, Test set accuracy = 0.909000
 epoch 55/200. Took 0.054106 seconds. 
  Full-batch training loss = 0.091055, test loss = 0.299791
  Training set accuracy = 0.987500, Test set accuracy = 0.910300
 epoch 56/200. Took 0.052369 seconds. 
  Full-batch training loss = 0.088600, test loss = 0.300194
  Training set accuracy = 0.987000, Test set accuracy = 0.910100
 epoch 57/200. Took 0.049236 seconds. 
  Full-batch training loss = 0.086558, test loss = 0.300218
  Training set accuracy = 0.990500, Test set accuracy = 0.909500
 epoch 58/200. Took 0.05761 seconds. 
  Full-batch training loss = 0.083555, test loss = 0.297901
  Training set accuracy = 0.990500, Test set accuracy = 0.912100
 epoch 59/200. Took 0.055002 seconds. 
  Full-batch training loss = 0.082402, test loss = 0.299875
  Training set accuracy = 0.991500, Test set accuracy = 0.908900
 epoch 60/200. Took 0.052318 seconds. 
  Full-batch training loss = 0.079713, test loss = 0.298969
  Training set accuracy = 0.990500, Test set accuracy = 0.910700
 epoch 61/200. Took 0.054748 seconds. 
  Full-batch training loss = 0.077883, test loss = 0.299755
  Training set accuracy = 0.992000, Test set accuracy = 0.909600
 epoch 62/200. Took 0.052341 seconds. 
  Full-batch training loss = 0.075182, test loss = 0.297630
  Training set accuracy = 0.992000, Test set accuracy = 0.911100
 epoch 63/200. Took 0.050595 seconds. 
  Full-batch training loss = 0.073389, test loss = 0.298811
  Training set accuracy = 0.993500, Test set accuracy = 0.910500
 epoch 64/200. Took 0.050353 seconds. 
  Full-batch training loss = 0.071668, test loss = 0.297531
  Training set accuracy = 0.993500, Test set accuracy = 0.911000
 epoch 65/200. Took 0.052294 seconds. 
  Full-batch training loss = 0.070467, test loss = 0.298413
  Training set accuracy = 0.993500, Test set accuracy = 0.910900
 epoch 66/200. Took 0.057336 seconds. 
  Full-batch training loss = 0.069140, test loss = 0.298475
  Training set accuracy = 0.993500, Test set accuracy = 0.911300
 epoch 67/200. Took 0.056663 seconds. 
  Full-batch training loss = 0.066654, test loss = 0.298379
  Training set accuracy = 0.994500, Test set accuracy = 0.911300
 epoch 68/200. Took 0.055192 seconds. 
  Full-batch training loss = 0.065089, test loss = 0.297838
  Training set accuracy = 0.994500, Test set accuracy = 0.911600
 epoch 69/200. Took 0.046713 seconds. 
  Full-batch training loss = 0.063475, test loss = 0.298311
  Training set accuracy = 0.994500, Test set accuracy = 0.910700
 epoch 70/200. Took 0.050493 seconds. 
  Full-batch training loss = 0.062200, test loss = 0.298812
  Training set accuracy = 0.995000, Test set accuracy = 0.911400
 epoch 71/200. Took 0.055088 seconds. 
  Full-batch training loss = 0.060839, test loss = 0.297695
  Training set accuracy = 0.995000, Test set accuracy = 0.912100
 epoch 72/200. Took 0.054972 seconds. 
  Full-batch training loss = 0.059214, test loss = 0.297523
  Training set accuracy = 0.995500, Test set accuracy = 0.911300
 epoch 73/200. Took 0.051884 seconds. 
  Full-batch training loss = 0.058147, test loss = 0.298839
  Training set accuracy = 0.995500, Test set accuracy = 0.911000
 epoch 74/200. Took 0.054844 seconds. 
  Full-batch training loss = 0.056777, test loss = 0.299986
  Training set accuracy = 0.995500, Test set accuracy = 0.910300
 epoch 75/200. Took 0.054234 seconds. 
  Full-batch training loss = 0.055082, test loss = 0.298082
  Training set accuracy = 0.996000, Test set accuracy = 0.911600
 epoch 76/200. Took 0.050243 seconds. 
  Full-batch training loss = 0.053997, test loss = 0.299067
  Training set accuracy = 0.995500, Test set accuracy = 0.911200
 epoch 77/200. Took 0.054507 seconds. 
  Full-batch training loss = 0.053010, test loss = 0.299348
  Training set accuracy = 0.996000, Test set accuracy = 0.912600
 epoch 78/200. Took 0.052786 seconds. 
  Full-batch training loss = 0.051946, test loss = 0.300789
  Training set accuracy = 0.996000, Test set accuracy = 0.909600
 epoch 79/200. Took 0.060509 seconds. 
  Full-batch training loss = 0.050540, test loss = 0.299100
  Training set accuracy = 0.996000, Test set accuracy = 0.911400
 epoch 80/200. Took 0.05289 seconds. 
  Full-batch training loss = 0.049951, test loss = 0.299816
  Training set accuracy = 0.996000, Test set accuracy = 0.911500
 epoch 81/200. Took 0.057951 seconds. 
  Full-batch training loss = 0.048479, test loss = 0.299292
  Training set accuracy = 0.996000, Test set accuracy = 0.910800
 epoch 82/200. Took 0.061513 seconds. 
  Full-batch training loss = 0.047560, test loss = 0.299499
  Training set accuracy = 0.996000, Test set accuracy = 0.912100
 epoch 83/200. Took 0.059086 seconds. 
  Full-batch training loss = 0.046471, test loss = 0.299253
  Training set accuracy = 0.997500, Test set accuracy = 0.911000
 epoch 84/200. Took 0.058988 seconds. 
  Full-batch training loss = 0.045452, test loss = 0.299355
  Training set accuracy = 0.997500, Test set accuracy = 0.911000
 epoch 85/200. Took 0.060507 seconds. 
  Full-batch training loss = 0.044572, test loss = 0.299890
  Training set accuracy = 0.997500, Test set accuracy = 0.910900
 epoch 86/200. Took 0.056413 seconds. 
  Full-batch training loss = 0.043514, test loss = 0.299790
  Training set accuracy = 0.997500, Test set accuracy = 0.911500
 epoch 87/200. Took 0.054011 seconds. 
  Full-batch training loss = 0.042778, test loss = 0.300521
  Training set accuracy = 0.998000, Test set accuracy = 0.911500
 epoch 88/200. Took 0.050066 seconds. 
  Full-batch training loss = 0.042022, test loss = 0.301425
  Training set accuracy = 0.998000, Test set accuracy = 0.911300
 epoch 89/200. Took 0.05509 seconds. 
  Full-batch training loss = 0.040989, test loss = 0.300726
  Training set accuracy = 0.998000, Test set accuracy = 0.911200
 epoch 90/200. Took 0.056325 seconds. 
  Full-batch training loss = 0.040377, test loss = 0.300870
  Training set accuracy = 0.998000, Test set accuracy = 0.911300
 epoch 91/200. Took 0.051229 seconds. 
  Full-batch training loss = 0.039575, test loss = 0.301491
  Training set accuracy = 0.998500, Test set accuracy = 0.913200
 epoch 92/200. Took 0.073717 seconds. 
  Full-batch training loss = 0.038757, test loss = 0.301194
  Training set accuracy = 0.998500, Test set accuracy = 0.911300
 epoch 93/200. Took 0.048165 seconds. 
  Full-batch training loss = 0.037976, test loss = 0.301990
  Training set accuracy = 0.998500, Test set accuracy = 0.911000
 epoch 94/200. Took 0.052937 seconds. 
  Full-batch training loss = 0.037401, test loss = 0.301596
  Training set accuracy = 0.998500, Test set accuracy = 0.911800
 epoch 95/200. Took 0.056188 seconds. 
  Full-batch training loss = 0.036890, test loss = 0.300520
  Training set accuracy = 0.998500, Test set accuracy = 0.913700
 epoch 96/200. Took 0.057338 seconds. 
  Full-batch training loss = 0.035985, test loss = 0.302388
  Training set accuracy = 0.999000, Test set accuracy = 0.912500
 epoch 97/200. Took 0.056417 seconds. 
  Full-batch training loss = 0.035549, test loss = 0.303568
  Training set accuracy = 0.999000, Test set accuracy = 0.912200
 epoch 98/200. Took 0.051499 seconds. 
  Full-batch training loss = 0.034827, test loss = 0.302863
  Training set accuracy = 0.999500, Test set accuracy = 0.911300
 epoch 99/200. Took 0.065616 seconds. 
  Full-batch training loss = 0.034096, test loss = 0.302773
  Training set accuracy = 0.999000, Test set accuracy = 0.912000
 epoch 100/200. Took 0.047479 seconds. 
  Full-batch training loss = 0.033534, test loss = 0.302769
  Training set accuracy = 0.999000, Test set accuracy = 0.912100
 epoch 101/200. Took 0.049026 seconds. 
  Full-batch training loss = 0.032818, test loss = 0.302613
  Training set accuracy = 0.999000, Test set accuracy = 0.912500
 epoch 102/200. Took 0.054981 seconds. 
  Full-batch training loss = 0.032398, test loss = 0.303121
  Training set accuracy = 0.999500, Test set accuracy = 0.912900
 epoch 103/200. Took 0.056 seconds. 
  Full-batch training loss = 0.031738, test loss = 0.303562
  Training set accuracy = 0.999000, Test set accuracy = 0.912300
 epoch 104/200. Took 0.055162 seconds. 
  Full-batch training loss = 0.031242, test loss = 0.303598
  Training set accuracy = 0.999500, Test set accuracy = 0.911700
 epoch 105/200. Took 0.055584 seconds. 
  Full-batch training loss = 0.030789, test loss = 0.303281
  Training set accuracy = 0.999500, Test set accuracy = 0.913000
 epoch 106/200. Took 0.054493 seconds. 
  Full-batch training loss = 0.030180, test loss = 0.303901
  Training set accuracy = 0.999500, Test set accuracy = 0.912100
 epoch 107/200. Took 0.053271 seconds. 
  Full-batch training loss = 0.029792, test loss = 0.303602
  Training set accuracy = 0.999000, Test set accuracy = 0.912800
 epoch 108/200. Took 0.055203 seconds. 
  Full-batch training loss = 0.029262, test loss = 0.304512
  Training set accuracy = 0.999500, Test set accuracy = 0.912700
 epoch 109/200. Took 0.051184 seconds. 
  Full-batch training loss = 0.028896, test loss = 0.303945
  Training set accuracy = 0.999500, Test set accuracy = 0.913800
 epoch 110/200. Took 0.052118 seconds. 
  Full-batch training loss = 0.028357, test loss = 0.303909
  Training set accuracy = 0.999500, Test set accuracy = 0.913300
 epoch 111/200. Took 0.056192 seconds. 
  Full-batch training loss = 0.027912, test loss = 0.305114
  Training set accuracy = 1.000000, Test set accuracy = 0.912900
 epoch 112/200. Took 0.05365 seconds. 
  Full-batch training loss = 0.027492, test loss = 0.304624
  Training set accuracy = 1.000000, Test set accuracy = 0.913900
 epoch 113/200. Took 0.05496 seconds. 
  Full-batch training loss = 0.027046, test loss = 0.304382
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 114/200. Took 0.054119 seconds. 
  Full-batch training loss = 0.026770, test loss = 0.306089
  Training set accuracy = 1.000000, Test set accuracy = 0.912900
 epoch 115/200. Took 0.054153 seconds. 
  Full-batch training loss = 0.026213, test loss = 0.304772
  Training set accuracy = 1.000000, Test set accuracy = 0.913400
 epoch 116/200. Took 0.053657 seconds. 
  Full-batch training loss = 0.025837, test loss = 0.305186
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 117/200. Took 0.053362 seconds. 
  Full-batch training loss = 0.025452, test loss = 0.305493
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 118/200. Took 0.057585 seconds. 
  Full-batch training loss = 0.025099, test loss = 0.305806
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 119/200. Took 0.056556 seconds. 
  Full-batch training loss = 0.024770, test loss = 0.306120
  Training set accuracy = 1.000000, Test set accuracy = 0.913700
 epoch 120/200. Took 0.05393 seconds. 
  Full-batch training loss = 0.024384, test loss = 0.306232
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 121/200. Took 0.052119 seconds. 
  Full-batch training loss = 0.024205, test loss = 0.307417
  Training set accuracy = 1.000000, Test set accuracy = 0.913300
 epoch 122/200. Took 0.065854 seconds. 
  Full-batch training loss = 0.023740, test loss = 0.306781
  Training set accuracy = 1.000000, Test set accuracy = 0.913600
 epoch 123/200. Took 0.055113 seconds. 
  Full-batch training loss = 0.023429, test loss = 0.306820
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 124/200. Took 0.050814 seconds. 
  Full-batch training loss = 0.023042, test loss = 0.307639
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 125/200. Took 0.053831 seconds. 
  Full-batch training loss = 0.022830, test loss = 0.307666
  Training set accuracy = 1.000000, Test set accuracy = 0.913300
 epoch 126/200. Took 0.054449 seconds. 
  Full-batch training loss = 0.022446, test loss = 0.307614
  Training set accuracy = 1.000000, Test set accuracy = 0.913100
 epoch 127/200. Took 0.055705 seconds. 
  Full-batch training loss = 0.022163, test loss = 0.307526
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 128/200. Took 0.060858 seconds. 
  Full-batch training loss = 0.021854, test loss = 0.308150
  Training set accuracy = 1.000000, Test set accuracy = 0.912900
 epoch 129/200. Took 0.055707 seconds. 
  Full-batch training loss = 0.021537, test loss = 0.308095
  Training set accuracy = 1.000000, Test set accuracy = 0.913200
 epoch 130/200. Took 0.060755 seconds. 
  Full-batch training loss = 0.021301, test loss = 0.308245
  Training set accuracy = 1.000000, Test set accuracy = 0.913600
 epoch 131/200. Took 0.062368 seconds. 
  Full-batch training loss = 0.021005, test loss = 0.308199
  Training set accuracy = 1.000000, Test set accuracy = 0.913000
 epoch 132/200. Took 0.057064 seconds. 
  Full-batch training loss = 0.020751, test loss = 0.308420
  Training set accuracy = 1.000000, Test set accuracy = 0.913800
 epoch 133/200. Took 0.056976 seconds. 
  Full-batch training loss = 0.020497, test loss = 0.308896
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 134/200. Took 0.05313 seconds. 
  Full-batch training loss = 0.020338, test loss = 0.309114
  Training set accuracy = 1.000000, Test set accuracy = 0.913800
 epoch 135/200. Took 0.058823 seconds. 
  Full-batch training loss = 0.020012, test loss = 0.309139
  Training set accuracy = 1.000000, Test set accuracy = 0.913800
 epoch 136/200. Took 0.060783 seconds. 
  Full-batch training loss = 0.019747, test loss = 0.309357
  Training set accuracy = 1.000000, Test set accuracy = 0.913100
 epoch 137/200. Took 0.059708 seconds. 
  Full-batch training loss = 0.019504, test loss = 0.309818
  Training set accuracy = 1.000000, Test set accuracy = 0.913900
 epoch 138/200. Took 0.057268 seconds. 
  Full-batch training loss = 0.019283, test loss = 0.309542
  Training set accuracy = 1.000000, Test set accuracy = 0.913300
 epoch 139/200. Took 0.058899 seconds. 
  Full-batch training loss = 0.019059, test loss = 0.309830
  Training set accuracy = 1.000000, Test set accuracy = 0.913100
 epoch 140/200. Took 0.055993 seconds. 
  Full-batch training loss = 0.018814, test loss = 0.310508
  Training set accuracy = 1.000000, Test set accuracy = 0.913100
 epoch 141/200. Took 0.053424 seconds. 
  Full-batch training loss = 0.018598, test loss = 0.310740
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 142/200. Took 0.056061 seconds. 
  Full-batch training loss = 0.018382, test loss = 0.310529
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 143/200. Took 0.055025 seconds. 
  Full-batch training loss = 0.018168, test loss = 0.310868
  Training set accuracy = 1.000000, Test set accuracy = 0.914000
 epoch 144/200. Took 0.055358 seconds. 
  Full-batch training loss = 0.018024, test loss = 0.310870
  Training set accuracy = 1.000000, Test set accuracy = 0.914000
 epoch 145/200. Took 0.058269 seconds. 
  Full-batch training loss = 0.017788, test loss = 0.311159
  Training set accuracy = 1.000000, Test set accuracy = 0.913400
 epoch 146/200. Took 0.058059 seconds. 
  Full-batch training loss = 0.017555, test loss = 0.311198
  Training set accuracy = 1.000000, Test set accuracy = 0.913700
 epoch 147/200. Took 0.0512 seconds. 
  Full-batch training loss = 0.017386, test loss = 0.311722
  Training set accuracy = 1.000000, Test set accuracy = 0.913700
 epoch 148/200. Took 0.05739 seconds. 
  Full-batch training loss = 0.017187, test loss = 0.311807
  Training set accuracy = 1.000000, Test set accuracy = 0.913600
 epoch 149/200. Took 0.057417 seconds. 
  Full-batch training loss = 0.017016, test loss = 0.312532
  Training set accuracy = 1.000000, Test set accuracy = 0.913500
 epoch 150/200. Took 0.057227 seconds. 
  Full-batch training loss = 0.016801, test loss = 0.312241
  Training set accuracy = 1.000000, Test set accuracy = 0.914000
 epoch 151/200. Took 0.067617 seconds. 
  Full-batch training loss = 0.016698, test loss = 0.312949
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 152/200. Took 0.060534 seconds. 
  Full-batch training loss = 0.016490, test loss = 0.312638
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 153/200. Took 0.06116 seconds. 
  Full-batch training loss = 0.016274, test loss = 0.313104
  Training set accuracy = 1.000000, Test set accuracy = 0.913700
 epoch 154/200. Took 0.053186 seconds. 
  Full-batch training loss = 0.016105, test loss = 0.312847
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 155/200. Took 0.063601 seconds. 
  Full-batch training loss = 0.015939, test loss = 0.313339
  Training set accuracy = 1.000000, Test set accuracy = 0.913600
 epoch 156/200. Took 0.053269 seconds. 
  Full-batch training loss = 0.015786, test loss = 0.313807
  Training set accuracy = 1.000000, Test set accuracy = 0.913300
 epoch 157/200. Took 0.053988 seconds. 
  Full-batch training loss = 0.015640, test loss = 0.313412
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 158/200. Took 0.058318 seconds. 
  Full-batch training loss = 0.015475, test loss = 0.314295
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 159/200. Took 0.058719 seconds. 
  Full-batch training loss = 0.015313, test loss = 0.314033
  Training set accuracy = 1.000000, Test set accuracy = 0.913900
 epoch 160/200. Took 0.046739 seconds. 
  Full-batch training loss = 0.015154, test loss = 0.314316
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 161/200. Took 0.055029 seconds. 
  Full-batch training loss = 0.015012, test loss = 0.314748
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 162/200. Took 0.05847 seconds. 
  Full-batch training loss = 0.014879, test loss = 0.314267
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 163/200. Took 0.062032 seconds. 
  Full-batch training loss = 0.014709, test loss = 0.314649
  Training set accuracy = 1.000000, Test set accuracy = 0.913700
 epoch 164/200. Took 0.066659 seconds. 
  Full-batch training loss = 0.014575, test loss = 0.315260
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 165/200. Took 0.05703 seconds. 
  Full-batch training loss = 0.014430, test loss = 0.315130
  Training set accuracy = 1.000000, Test set accuracy = 0.913600
 epoch 166/200. Took 0.05983 seconds. 
  Full-batch training loss = 0.014288, test loss = 0.315283
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 167/200. Took 0.055392 seconds. 
  Full-batch training loss = 0.014156, test loss = 0.315265
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 168/200. Took 0.056528 seconds. 
  Full-batch training loss = 0.014026, test loss = 0.315571
  Training set accuracy = 1.000000, Test set accuracy = 0.914000
 epoch 169/200. Took 0.058207 seconds. 
  Full-batch training loss = 0.013898, test loss = 0.315562
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 170/200. Took 0.054526 seconds. 
  Full-batch training loss = 0.013766, test loss = 0.315902
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 171/200. Took 0.059716 seconds. 
  Full-batch training loss = 0.013641, test loss = 0.316283
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 172/200. Took 0.056987 seconds. 
  Full-batch training loss = 0.013516, test loss = 0.316573
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 173/200. Took 0.050527 seconds. 
  Full-batch training loss = 0.013395, test loss = 0.316561
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 174/200. Took 0.056711 seconds. 
  Full-batch training loss = 0.013272, test loss = 0.316607
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 175/200. Took 0.054243 seconds. 
  Full-batch training loss = 0.013157, test loss = 0.317210
  Training set accuracy = 1.000000, Test set accuracy = 0.914000
 epoch 176/200. Took 0.058283 seconds. 
  Full-batch training loss = 0.013042, test loss = 0.317035
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 177/200. Took 0.057327 seconds. 
  Full-batch training loss = 0.012932, test loss = 0.317165
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 178/200. Took 0.057132 seconds. 
  Full-batch training loss = 0.012814, test loss = 0.317442
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 179/200. Took 0.057203 seconds. 
  Full-batch training loss = 0.012704, test loss = 0.317597
  Training set accuracy = 1.000000, Test set accuracy = 0.914800
 epoch 180/200. Took 0.064141 seconds. 
  Full-batch training loss = 0.012590, test loss = 0.317691
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 181/200. Took 0.055613 seconds. 
  Full-batch training loss = 0.012490, test loss = 0.318174
  Training set accuracy = 1.000000, Test set accuracy = 0.914700
 epoch 182/200. Took 0.053547 seconds. 
  Full-batch training loss = 0.012380, test loss = 0.318419
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 183/200. Took 0.055928 seconds. 
  Full-batch training loss = 0.012275, test loss = 0.318300
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 184/200. Took 0.058621 seconds. 
  Full-batch training loss = 0.012172, test loss = 0.318202
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 185/200. Took 0.053582 seconds. 
  Full-batch training loss = 0.012073, test loss = 0.318680
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 186/200. Took 0.058423 seconds. 
  Full-batch training loss = 0.011971, test loss = 0.319015
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 187/200. Took 0.053728 seconds. 
  Full-batch training loss = 0.011870, test loss = 0.318890
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 188/200. Took 0.051805 seconds. 
  Full-batch training loss = 0.011781, test loss = 0.319247
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 189/200. Took 0.058296 seconds. 
  Full-batch training loss = 0.011679, test loss = 0.319304
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 190/200. Took 0.058092 seconds. 
  Full-batch training loss = 0.011584, test loss = 0.319356
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 191/200. Took 0.057092 seconds. 
  Full-batch training loss = 0.011490, test loss = 0.319514
  Training set accuracy = 1.000000, Test set accuracy = 0.914400
 epoch 192/200. Took 0.059214 seconds. 
  Full-batch training loss = 0.011401, test loss = 0.319897
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 193/200. Took 0.061583 seconds. 
  Full-batch training loss = 0.011317, test loss = 0.319807
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 194/200. Took 0.054069 seconds. 
  Full-batch training loss = 0.011236, test loss = 0.320533
  Training set accuracy = 1.000000, Test set accuracy = 0.914100
 epoch 195/200. Took 0.058271 seconds. 
  Full-batch training loss = 0.011138, test loss = 0.320653
  Training set accuracy = 1.000000, Test set accuracy = 0.914300
 epoch 196/200. Took 0.057833 seconds. 
  Full-batch training loss = 0.011055, test loss = 0.320543
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 197/200. Took 0.053938 seconds. 
  Full-batch training loss = 0.010983, test loss = 0.320921
  Training set accuracy = 1.000000, Test set accuracy = 0.914600
 epoch 198/200. Took 0.050212 seconds. 
  Full-batch training loss = 0.010879, test loss = 0.320853
  Training set accuracy = 1.000000, Test set accuracy = 0.914500
 epoch 199/200. Took 0.056018 seconds. 
  Full-batch training loss = 0.010799, test loss = 0.320899
  Training set accuracy = 1.000000, Test set accuracy = 0.914200
 epoch 200/200. Took 0.054299 seconds. 
  Full-batch training loss = 0.010721, test loss = 0.320977
  Training set accuracy = 1.000000, Test set accuracy = 0.914700
Elapsed time is 54.347924 seconds.
End Training

learningRateRBM =

   1.0000e-03

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.100
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 50 epochs (batchsize: 100)
 epoch 1/50. Took 0.094826 seconds. Average reconstruction error is: 163.8467
 epoch 2/50. Took 0.090997 seconds. Average reconstruction error is: 132.6525
 epoch 3/50. Took 0.088481 seconds. Average reconstruction error is: 107.1386
 epoch 4/50. Took 0.10827 seconds. Average reconstruction error is: 89.7555
 epoch 5/50. Took 0.097365 seconds. Average reconstruction error is: 80.7048
 epoch 6/50. Took 0.094293 seconds. Average reconstruction error is: 75.3704
 epoch 7/50. Took 0.092491 seconds. Average reconstruction error is: 71.8576
 epoch 8/50. Took 0.095542 seconds. Average reconstruction error is: 69.4596
 epoch 9/50. Took 0.10393 seconds. Average reconstruction error is: 67.4149
 epoch 10/50. Took 0.10364 seconds. Average reconstruction error is: 65.825
 epoch 11/50. Took 0.091271 seconds. Average reconstruction error is: 64.5032
 epoch 12/50. Took 0.097424 seconds. Average reconstruction error is: 63.3846
 epoch 13/50. Took 0.099106 seconds. Average reconstruction error is: 62.4903
 epoch 14/50. Took 0.093754 seconds. Average reconstruction error is: 61.5558
 epoch 15/50. Took 0.094328 seconds. Average reconstruction error is: 60.8369
 epoch 16/50. Took 0.098235 seconds. Average reconstruction error is: 60.0204
 epoch 17/50. Took 0.093232 seconds. Average reconstruction error is: 59.4934
 epoch 18/50. Took 0.093394 seconds. Average reconstruction error is: 58.8084
 epoch 19/50. Took 0.096124 seconds. Average reconstruction error is: 58.1997
 epoch 20/50. Took 0.10136 seconds. Average reconstruction error is: 57.6164
 epoch 21/50. Took 0.10017 seconds. Average reconstruction error is: 57.0784
 epoch 22/50. Took 0.097688 seconds. Average reconstruction error is: 56.5587
 epoch 23/50. Took 0.096899 seconds. Average reconstruction error is: 55.9536
 epoch 24/50. Took 0.10515 seconds. Average reconstruction error is: 55.5138
 epoch 25/50. Took 0.095843 seconds. Average reconstruction error is: 54.9757
 epoch 26/50. Took 0.1025 seconds. Average reconstruction error is: 54.5138
 epoch 27/50. Took 0.09095 seconds. Average reconstruction error is: 53.9971
 epoch 28/50. Took 0.10341 seconds. Average reconstruction error is: 53.6393
 epoch 29/50. Took 0.10071 seconds. Average reconstruction error is: 53.0067
 epoch 30/50. Took 0.093581 seconds. Average reconstruction error is: 52.5448
 epoch 31/50. Took 0.095035 seconds. Average reconstruction error is: 52.1385
 epoch 32/50. Took 0.10264 seconds. Average reconstruction error is: 51.6039
 epoch 33/50. Took 0.10011 seconds. Average reconstruction error is: 51.2102
 epoch 34/50. Took 0.10628 seconds. Average reconstruction error is: 50.7626
 epoch 35/50. Took 0.096603 seconds. Average reconstruction error is: 50.3283
 epoch 36/50. Took 0.092171 seconds. Average reconstruction error is: 49.9041
 epoch 37/50. Took 0.094848 seconds. Average reconstruction error is: 49.407
 epoch 38/50. Took 0.1003 seconds. Average reconstruction error is: 49.0785
 epoch 39/50. Took 0.094558 seconds. Average reconstruction error is: 48.6857
 epoch 40/50. Took 0.094988 seconds. Average reconstruction error is: 48.293
 epoch 41/50. Took 0.10117 seconds. Average reconstruction error is: 47.9231
 epoch 42/50. Took 0.098492 seconds. Average reconstruction error is: 47.4698
 epoch 43/50. Took 0.096661 seconds. Average reconstruction error is: 47.1575
 epoch 44/50. Took 0.10517 seconds. Average reconstruction error is: 46.811
 epoch 45/50. Took 0.096276 seconds. Average reconstruction error is: 46.5212
 epoch 46/50. Took 0.10143 seconds. Average reconstruction error is: 46.1964
 epoch 47/50. Took 0.093135 seconds. Average reconstruction error is: 45.7883
 epoch 48/50. Took 0.091151 seconds. Average reconstruction error is: 45.4674
 epoch 49/50. Took 0.096869 seconds. Average reconstruction error is: 45.2165
 epoch 50/50. Took 0.099915 seconds. Average reconstruction error is: 44.8389
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.051742 seconds. 
  Full-batch training loss = 1.469715, test loss = 1.451914
  Training set accuracy = 0.565500, Test set accuracy = 0.571800
 epoch 2/200. Took 0.051363 seconds. 
  Full-batch training loss = 1.078975, test loss = 1.067009
  Training set accuracy = 0.682500, Test set accuracy = 0.695000
 epoch 3/200. Took 0.052813 seconds. 
  Full-batch training loss = 0.915077, test loss = 0.912603
  Training set accuracy = 0.700500, Test set accuracy = 0.702300
 epoch 4/200. Took 0.058709 seconds. 
  Full-batch training loss = 0.773877, test loss = 0.777369
  Training set accuracy = 0.780000, Test set accuracy = 0.787900
 epoch 5/200. Took 0.064967 seconds. 
  Full-batch training loss = 0.688940, test loss = 0.696348
  Training set accuracy = 0.795000, Test set accuracy = 0.802800
 epoch 6/200. Took 0.065005 seconds. 
  Full-batch training loss = 0.605454, test loss = 0.623121
  Training set accuracy = 0.843000, Test set accuracy = 0.833600
 epoch 7/200. Took 0.050614 seconds. 
  Full-batch training loss = 0.545795, test loss = 0.572810
  Training set accuracy = 0.857000, Test set accuracy = 0.844500
 epoch 8/200. Took 0.060026 seconds. 
  Full-batch training loss = 0.499912, test loss = 0.532474
  Training set accuracy = 0.874500, Test set accuracy = 0.856400
 epoch 9/200. Took 0.063724 seconds. 
  Full-batch training loss = 0.456470, test loss = 0.492604
  Training set accuracy = 0.890000, Test set accuracy = 0.868200
 epoch 10/200. Took 0.060268 seconds. 
  Full-batch training loss = 0.420787, test loss = 0.465142
  Training set accuracy = 0.902500, Test set accuracy = 0.878000
 epoch 11/200. Took 0.055472 seconds. 
  Full-batch training loss = 0.392901, test loss = 0.442695
  Training set accuracy = 0.904000, Test set accuracy = 0.881900
 epoch 12/200. Took 0.052139 seconds. 
  Full-batch training loss = 0.366768, test loss = 0.425354
  Training set accuracy = 0.914500, Test set accuracy = 0.888400
 epoch 13/200. Took 0.05134 seconds. 
  Full-batch training loss = 0.345792, test loss = 0.408880
  Training set accuracy = 0.919500, Test set accuracy = 0.891000
 epoch 14/200. Took 0.056366 seconds. 
  Full-batch training loss = 0.326420, test loss = 0.392810
  Training set accuracy = 0.926000, Test set accuracy = 0.894400
 epoch 15/200. Took 0.074023 seconds. 
  Full-batch training loss = 0.308118, test loss = 0.381568
  Training set accuracy = 0.929500, Test set accuracy = 0.898400
 epoch 16/200. Took 0.058894 seconds. 
  Full-batch training loss = 0.291532, test loss = 0.371424
  Training set accuracy = 0.936500, Test set accuracy = 0.899000
 epoch 17/200. Took 0.064985 seconds. 
  Full-batch training loss = 0.280698, test loss = 0.365849
  Training set accuracy = 0.938500, Test set accuracy = 0.900200
 epoch 18/200. Took 0.058868 seconds. 
  Full-batch training loss = 0.267388, test loss = 0.357911
  Training set accuracy = 0.942500, Test set accuracy = 0.898000
 epoch 19/200. Took 0.10898 seconds. 
  Full-batch training loss = 0.256464, test loss = 0.349413
  Training set accuracy = 0.943500, Test set accuracy = 0.900800
 epoch 20/200. Took 0.056438 seconds. 
  Full-batch training loss = 0.243924, test loss = 0.343402
  Training set accuracy = 0.952500, Test set accuracy = 0.902800
 epoch 21/200. Took 0.060437 seconds. 
  Full-batch training loss = 0.238962, test loss = 0.344122
  Training set accuracy = 0.946500, Test set accuracy = 0.902800
 epoch 22/200. Took 0.056973 seconds. 
  Full-batch training loss = 0.224349, test loss = 0.333692
  Training set accuracy = 0.954000, Test set accuracy = 0.905600
 epoch 23/200. Took 0.064003 seconds. 
  Full-batch training loss = 0.216558, test loss = 0.328790
  Training set accuracy = 0.952500, Test set accuracy = 0.905900
 epoch 24/200. Took 0.089311 seconds. 
  Full-batch training loss = 0.209248, test loss = 0.325368
  Training set accuracy = 0.957500, Test set accuracy = 0.906300
 epoch 25/200. Took 0.057032 seconds. 
  Full-batch training loss = 0.200472, test loss = 0.321653
  Training set accuracy = 0.961500, Test set accuracy = 0.909200
 epoch 26/200. Took 0.058112 seconds. 
  Full-batch training loss = 0.195897, test loss = 0.320571
  Training set accuracy = 0.961500, Test set accuracy = 0.909400
 epoch 27/200. Took 0.053848 seconds. 
  Full-batch training loss = 0.188923, test loss = 0.317779
  Training set accuracy = 0.958500, Test set accuracy = 0.908600
 epoch 28/200. Took 0.060789 seconds. 
  Full-batch training loss = 0.180022, test loss = 0.312569
  Training set accuracy = 0.964000, Test set accuracy = 0.911200
 epoch 29/200. Took 0.054116 seconds. 
  Full-batch training loss = 0.173787, test loss = 0.309998
  Training set accuracy = 0.965500, Test set accuracy = 0.910200
 epoch 30/200. Took 0.061206 seconds. 
  Full-batch training loss = 0.169962, test loss = 0.309117
  Training set accuracy = 0.964000, Test set accuracy = 0.907900
 epoch 31/200. Took 0.058728 seconds. 
  Full-batch training loss = 0.166336, test loss = 0.308502
  Training set accuracy = 0.964500, Test set accuracy = 0.909900
 epoch 32/200. Took 0.056759 seconds. 
  Full-batch training loss = 0.157783, test loss = 0.303595
  Training set accuracy = 0.967000, Test set accuracy = 0.909300
 epoch 33/200. Took 0.052635 seconds. 
  Full-batch training loss = 0.151726, test loss = 0.301264
  Training set accuracy = 0.970000, Test set accuracy = 0.911900
 epoch 34/200. Took 0.054907 seconds. 
  Full-batch training loss = 0.146601, test loss = 0.298979
  Training set accuracy = 0.973000, Test set accuracy = 0.913200
 epoch 35/200. Took 0.065628 seconds. 
  Full-batch training loss = 0.142047, test loss = 0.299346
  Training set accuracy = 0.972500, Test set accuracy = 0.913900
 epoch 36/200. Took 0.049414 seconds. 
  Full-batch training loss = 0.138306, test loss = 0.298622
  Training set accuracy = 0.972500, Test set accuracy = 0.912900
 epoch 37/200. Took 0.053064 seconds. 
  Full-batch training loss = 0.133676, test loss = 0.296158
  Training set accuracy = 0.972500, Test set accuracy = 0.913500
 epoch 38/200. Took 0.05043 seconds. 
  Full-batch training loss = 0.130994, test loss = 0.296889
  Training set accuracy = 0.974000, Test set accuracy = 0.914300
 epoch 39/200. Took 0.057996 seconds. 
  Full-batch training loss = 0.125984, test loss = 0.295263
  Training set accuracy = 0.976500, Test set accuracy = 0.915300
 epoch 40/200. Took 0.05643 seconds. 
  Full-batch training loss = 0.123339, test loss = 0.295156
  Training set accuracy = 0.975000, Test set accuracy = 0.915000
 epoch 41/200. Took 0.059731 seconds. 
  Full-batch training loss = 0.119018, test loss = 0.292789
  Training set accuracy = 0.978500, Test set accuracy = 0.916100
 epoch 42/200. Took 0.048454 seconds. 
  Full-batch training loss = 0.115445, test loss = 0.292371
  Training set accuracy = 0.979000, Test set accuracy = 0.914900
 epoch 43/200. Took 0.058938 seconds. 
  Full-batch training loss = 0.112756, test loss = 0.292050
  Training set accuracy = 0.978500, Test set accuracy = 0.915500
 epoch 44/200. Took 0.053345 seconds. 
  Full-batch training loss = 0.107211, test loss = 0.289052
  Training set accuracy = 0.981500, Test set accuracy = 0.916000
 epoch 45/200. Took 0.05771 seconds. 
  Full-batch training loss = 0.104222, test loss = 0.289745
  Training set accuracy = 0.980500, Test set accuracy = 0.916400
 epoch 46/200. Took 0.047373 seconds. 
  Full-batch training loss = 0.100789, test loss = 0.287395
  Training set accuracy = 0.981000, Test set accuracy = 0.917100
 epoch 47/200. Took 0.056391 seconds. 
  Full-batch training loss = 0.098699, test loss = 0.288087
  Training set accuracy = 0.984000, Test set accuracy = 0.918000
 epoch 48/200. Took 0.066075 seconds. 
  Full-batch training loss = 0.095428, test loss = 0.286576
  Training set accuracy = 0.984000, Test set accuracy = 0.917800
 epoch 49/200. Took 0.058886 seconds. 
  Full-batch training loss = 0.093196, test loss = 0.286862
  Training set accuracy = 0.983500, Test set accuracy = 0.918000
 epoch 50/200. Took 0.056611 seconds. 
  Full-batch training loss = 0.090271, test loss = 0.285483
  Training set accuracy = 0.984500, Test set accuracy = 0.918500
 epoch 51/200. Took 0.059794 seconds. 
  Full-batch training loss = 0.089860, test loss = 0.289214
  Training set accuracy = 0.987000, Test set accuracy = 0.918200
 epoch 52/200. Took 0.059992 seconds. 
  Full-batch training loss = 0.085266, test loss = 0.285224
  Training set accuracy = 0.985500, Test set accuracy = 0.918400
 epoch 53/200. Took 0.055867 seconds. 
  Full-batch training loss = 0.083134, test loss = 0.285535
  Training set accuracy = 0.987000, Test set accuracy = 0.917200
 epoch 54/200. Took 0.054754 seconds. 
  Full-batch training loss = 0.080438, test loss = 0.284269
  Training set accuracy = 0.988000, Test set accuracy = 0.917900
 epoch 55/200. Took 0.057328 seconds. 
  Full-batch training loss = 0.078464, test loss = 0.283219
  Training set accuracy = 0.987500, Test set accuracy = 0.919300
 epoch 56/200. Took 0.052795 seconds. 
  Full-batch training loss = 0.077062, test loss = 0.285005
  Training set accuracy = 0.989500, Test set accuracy = 0.918800
 epoch 57/200. Took 0.05296 seconds. 
  Full-batch training loss = 0.074839, test loss = 0.284109
  Training set accuracy = 0.990000, Test set accuracy = 0.919200
 epoch 58/200. Took 0.05545 seconds. 
  Full-batch training loss = 0.073461, test loss = 0.284524
  Training set accuracy = 0.988000, Test set accuracy = 0.917700
 epoch 59/200. Took 0.057712 seconds. 
  Full-batch training loss = 0.070822, test loss = 0.283637
  Training set accuracy = 0.992500, Test set accuracy = 0.919400
 epoch 60/200. Took 0.050433 seconds. 
  Full-batch training loss = 0.070073, test loss = 0.284651
  Training set accuracy = 0.991000, Test set accuracy = 0.919500
 epoch 61/200. Took 0.059127 seconds. 
  Full-batch training loss = 0.067372, test loss = 0.283008
  Training set accuracy = 0.992000, Test set accuracy = 0.919200
 epoch 62/200. Took 0.060757 seconds. 
  Full-batch training loss = 0.065815, test loss = 0.284488
  Training set accuracy = 0.992500, Test set accuracy = 0.918900
 epoch 63/200. Took 0.058066 seconds. 
  Full-batch training loss = 0.063861, test loss = 0.283157
  Training set accuracy = 0.992500, Test set accuracy = 0.919600
 epoch 64/200. Took 0.057051 seconds. 
  Full-batch training loss = 0.062114, test loss = 0.282540
  Training set accuracy = 0.992500, Test set accuracy = 0.920400
 epoch 65/200. Took 0.061628 seconds. 
  Full-batch training loss = 0.060851, test loss = 0.282815
  Training set accuracy = 0.994500, Test set accuracy = 0.919100
 epoch 66/200. Took 0.058378 seconds. 
  Full-batch training loss = 0.059320, test loss = 0.283282
  Training set accuracy = 0.994000, Test set accuracy = 0.920300
 epoch 67/200. Took 0.058632 seconds. 
  Full-batch training loss = 0.057867, test loss = 0.282978
  Training set accuracy = 0.994000, Test set accuracy = 0.921200
 epoch 68/200. Took 0.064384 seconds. 
  Full-batch training loss = 0.056573, test loss = 0.282441
  Training set accuracy = 0.995000, Test set accuracy = 0.919900
 epoch 69/200. Took 0.053138 seconds. 
  Full-batch training loss = 0.055440, test loss = 0.283331
  Training set accuracy = 0.996000, Test set accuracy = 0.919900
 epoch 70/200. Took 0.053922 seconds. 
  Full-batch training loss = 0.053736, test loss = 0.282453
  Training set accuracy = 0.996000, Test set accuracy = 0.919100
 epoch 71/200. Took 0.057734 seconds. 
  Full-batch training loss = 0.053093, test loss = 0.283264
  Training set accuracy = 0.996000, Test set accuracy = 0.920000
 epoch 72/200. Took 0.055262 seconds. 
  Full-batch training loss = 0.051728, test loss = 0.283565
  Training set accuracy = 0.995500, Test set accuracy = 0.919600
 epoch 73/200. Took 0.055794 seconds. 
  Full-batch training loss = 0.050314, test loss = 0.282688
  Training set accuracy = 0.996000, Test set accuracy = 0.920800
 epoch 74/200. Took 0.056795 seconds. 
  Full-batch training loss = 0.049100, test loss = 0.283320
  Training set accuracy = 0.997000, Test set accuracy = 0.919500
 epoch 75/200. Took 0.053408 seconds. 
  Full-batch training loss = 0.048114, test loss = 0.282065
  Training set accuracy = 0.997000, Test set accuracy = 0.919800
 epoch 76/200. Took 0.057882 seconds. 
  Full-batch training loss = 0.046726, test loss = 0.282523
  Training set accuracy = 0.997500, Test set accuracy = 0.920200
 epoch 77/200. Took 0.05895 seconds. 
  Full-batch training loss = 0.045736, test loss = 0.281982
  Training set accuracy = 0.997500, Test set accuracy = 0.920200
 epoch 78/200. Took 0.04788 seconds. 
  Full-batch training loss = 0.044848, test loss = 0.282581
  Training set accuracy = 0.998500, Test set accuracy = 0.919600
 epoch 79/200. Took 0.056148 seconds. 
  Full-batch training loss = 0.044369, test loss = 0.282981
  Training set accuracy = 0.998000, Test set accuracy = 0.919400
 epoch 80/200. Took 0.066961 seconds. 
  Full-batch training loss = 0.042870, test loss = 0.282801
  Training set accuracy = 0.999000, Test set accuracy = 0.920100
 epoch 81/200. Took 0.056018 seconds. 
  Full-batch training loss = 0.042067, test loss = 0.283074
  Training set accuracy = 0.999500, Test set accuracy = 0.921000
 epoch 82/200. Took 0.054917 seconds. 
  Full-batch training loss = 0.041362, test loss = 0.283251
  Training set accuracy = 0.999500, Test set accuracy = 0.919700
 epoch 83/200. Took 0.052525 seconds. 
  Full-batch training loss = 0.040357, test loss = 0.283465
  Training set accuracy = 0.999500, Test set accuracy = 0.919600
 epoch 84/200. Took 0.061842 seconds. 
  Full-batch training loss = 0.039634, test loss = 0.283632
  Training set accuracy = 0.999500, Test set accuracy = 0.919400
 epoch 85/200. Took 0.0588 seconds. 
  Full-batch training loss = 0.038687, test loss = 0.283499
  Training set accuracy = 0.999500, Test set accuracy = 0.919500
 epoch 86/200. Took 0.058306 seconds. 
  Full-batch training loss = 0.037993, test loss = 0.283710
  Training set accuracy = 0.999500, Test set accuracy = 0.920300
 epoch 87/200. Took 0.05529 seconds. 
  Full-batch training loss = 0.037243, test loss = 0.283393
  Training set accuracy = 0.999500, Test set accuracy = 0.919700
 epoch 88/200. Took 0.06336 seconds. 
  Full-batch training loss = 0.036739, test loss = 0.283334
  Training set accuracy = 0.999500, Test set accuracy = 0.920100
 epoch 89/200. Took 0.056968 seconds. 
  Full-batch training loss = 0.035852, test loss = 0.284359
  Training set accuracy = 0.999500, Test set accuracy = 0.920800
 epoch 90/200. Took 0.056316 seconds. 
  Full-batch training loss = 0.035095, test loss = 0.283965
  Training set accuracy = 0.999500, Test set accuracy = 0.920700
 epoch 91/200. Took 0.054806 seconds. 
  Full-batch training loss = 0.034495, test loss = 0.283732
  Training set accuracy = 1.000000, Test set accuracy = 0.920400
 epoch 92/200. Took 0.0539 seconds. 
  Full-batch training loss = 0.033927, test loss = 0.284601
  Training set accuracy = 1.000000, Test set accuracy = 0.920600
 epoch 93/200. Took 0.062968 seconds. 
  Full-batch training loss = 0.033197, test loss = 0.283925
  Training set accuracy = 1.000000, Test set accuracy = 0.920500
 epoch 94/200. Took 0.05198 seconds. 
  Full-batch training loss = 0.032746, test loss = 0.284426
  Training set accuracy = 1.000000, Test set accuracy = 0.920700
 epoch 95/200. Took 0.049757 seconds. 
  Full-batch training loss = 0.032251, test loss = 0.285190
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 96/200. Took 0.055054 seconds. 
  Full-batch training loss = 0.031694, test loss = 0.284553
  Training set accuracy = 1.000000, Test set accuracy = 0.920300
 epoch 97/200. Took 0.053022 seconds. 
  Full-batch training loss = 0.031045, test loss = 0.284861
  Training set accuracy = 1.000000, Test set accuracy = 0.919600
 epoch 98/200. Took 0.054649 seconds. 
  Full-batch training loss = 0.030446, test loss = 0.284652
  Training set accuracy = 1.000000, Test set accuracy = 0.920600
 epoch 99/200. Took 0.056932 seconds. 
  Full-batch training loss = 0.029967, test loss = 0.285591
  Training set accuracy = 1.000000, Test set accuracy = 0.921100
 epoch 100/200. Took 0.052892 seconds. 
  Full-batch training loss = 0.029426, test loss = 0.285642
  Training set accuracy = 1.000000, Test set accuracy = 0.920300
 epoch 101/200. Took 0.056328 seconds. 
  Full-batch training loss = 0.029072, test loss = 0.285673
  Training set accuracy = 1.000000, Test set accuracy = 0.920400
 epoch 102/200. Took 0.057745 seconds. 
  Full-batch training loss = 0.028453, test loss = 0.285253
  Training set accuracy = 1.000000, Test set accuracy = 0.920400
 epoch 103/200. Took 0.055814 seconds. 
  Full-batch training loss = 0.028172, test loss = 0.286143
  Training set accuracy = 1.000000, Test set accuracy = 0.921300
 epoch 104/200. Took 0.055255 seconds. 
  Full-batch training loss = 0.027542, test loss = 0.285520
  Training set accuracy = 1.000000, Test set accuracy = 0.920700
 epoch 105/200. Took 0.058032 seconds. 
  Full-batch training loss = 0.027245, test loss = 0.286022
  Training set accuracy = 1.000000, Test set accuracy = 0.920300
 epoch 106/200. Took 0.060761 seconds. 
  Full-batch training loss = 0.026690, test loss = 0.286049
  Training set accuracy = 1.000000, Test set accuracy = 0.920700
 epoch 107/200. Took 0.059006 seconds. 
  Full-batch training loss = 0.026299, test loss = 0.285845
  Training set accuracy = 1.000000, Test set accuracy = 0.920700
 epoch 108/200. Took 0.057829 seconds. 
  Full-batch training loss = 0.025894, test loss = 0.286502
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 109/200. Took 0.058522 seconds. 
  Full-batch training loss = 0.025525, test loss = 0.286876
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 110/200. Took 0.057044 seconds. 
  Full-batch training loss = 0.025130, test loss = 0.286470
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 111/200. Took 0.056429 seconds. 
  Full-batch training loss = 0.024736, test loss = 0.286709
  Training set accuracy = 1.000000, Test set accuracy = 0.921300
 epoch 112/200. Took 0.055759 seconds. 
  Full-batch training loss = 0.024352, test loss = 0.286989
  Training set accuracy = 1.000000, Test set accuracy = 0.920200
 epoch 113/200. Took 0.056001 seconds. 
  Full-batch training loss = 0.024061, test loss = 0.287367
  Training set accuracy = 1.000000, Test set accuracy = 0.921300
 epoch 114/200. Took 0.051132 seconds. 
  Full-batch training loss = 0.023715, test loss = 0.287102
  Training set accuracy = 1.000000, Test set accuracy = 0.920000
 epoch 115/200. Took 0.055233 seconds. 
  Full-batch training loss = 0.023386, test loss = 0.287574
  Training set accuracy = 1.000000, Test set accuracy = 0.921100
 epoch 116/200. Took 0.05414 seconds. 
  Full-batch training loss = 0.023006, test loss = 0.287548
  Training set accuracy = 1.000000, Test set accuracy = 0.920200
 epoch 117/200. Took 0.057642 seconds. 
  Full-batch training loss = 0.022727, test loss = 0.287507
  Training set accuracy = 1.000000, Test set accuracy = 0.920500
 epoch 118/200. Took 0.050058 seconds. 
  Full-batch training loss = 0.022420, test loss = 0.287833
  Training set accuracy = 1.000000, Test set accuracy = 0.920200
 epoch 119/200. Took 0.05349 seconds. 
  Full-batch training loss = 0.022104, test loss = 0.288077
  Training set accuracy = 1.000000, Test set accuracy = 0.921500
 epoch 120/200. Took 0.056953 seconds. 
  Full-batch training loss = 0.021780, test loss = 0.288023
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 121/200. Took 0.062064 seconds. 
  Full-batch training loss = 0.021521, test loss = 0.288517
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 122/200. Took 0.060818 seconds. 
  Full-batch training loss = 0.021205, test loss = 0.288176
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 123/200. Took 0.058341 seconds. 
  Full-batch training loss = 0.020920, test loss = 0.288603
  Training set accuracy = 1.000000, Test set accuracy = 0.920700
 epoch 124/200. Took 0.06401 seconds. 
  Full-batch training loss = 0.020662, test loss = 0.288635
  Training set accuracy = 1.000000, Test set accuracy = 0.921000
 epoch 125/200. Took 0.053919 seconds. 
  Full-batch training loss = 0.020391, test loss = 0.288879
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 126/200. Took 0.053285 seconds. 
  Full-batch training loss = 0.020137, test loss = 0.289042
  Training set accuracy = 1.000000, Test set accuracy = 0.921000
 epoch 127/200. Took 0.056682 seconds. 
  Full-batch training loss = 0.019891, test loss = 0.289323
  Training set accuracy = 1.000000, Test set accuracy = 0.921000
 epoch 128/200. Took 0.057221 seconds. 
  Full-batch training loss = 0.019648, test loss = 0.289403
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 129/200. Took 0.052523 seconds. 
  Full-batch training loss = 0.019422, test loss = 0.289279
  Training set accuracy = 1.000000, Test set accuracy = 0.921100
 epoch 130/200. Took 0.056351 seconds. 
  Full-batch training loss = 0.019153, test loss = 0.289732
  Training set accuracy = 1.000000, Test set accuracy = 0.921200
 epoch 131/200. Took 0.058449 seconds. 
  Full-batch training loss = 0.018954, test loss = 0.290188
  Training set accuracy = 1.000000, Test set accuracy = 0.921100
 epoch 132/200. Took 0.059441 seconds. 
  Full-batch training loss = 0.018701, test loss = 0.290162
  Training set accuracy = 1.000000, Test set accuracy = 0.921200
 epoch 133/200. Took 0.059062 seconds. 
  Full-batch training loss = 0.018509, test loss = 0.289772
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 134/200. Took 0.056777 seconds. 
  Full-batch training loss = 0.018278, test loss = 0.290868
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 135/200. Took 0.08452 seconds. 
  Full-batch training loss = 0.018046, test loss = 0.290806
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 136/200. Took 0.052974 seconds. 
  Full-batch training loss = 0.017858, test loss = 0.290852
  Training set accuracy = 1.000000, Test set accuracy = 0.920800
 epoch 137/200. Took 0.053221 seconds. 
  Full-batch training loss = 0.017622, test loss = 0.290621
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 138/200. Took 0.056123 seconds. 
  Full-batch training loss = 0.017427, test loss = 0.290892
  Training set accuracy = 1.000000, Test set accuracy = 0.920900
 epoch 139/200. Took 0.054557 seconds. 
  Full-batch training loss = 0.017241, test loss = 0.290836
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 140/200. Took 0.056236 seconds. 
  Full-batch training loss = 0.017048, test loss = 0.291268
  Training set accuracy = 1.000000, Test set accuracy = 0.921300
 epoch 141/200. Took 0.057365 seconds. 
  Full-batch training loss = 0.016848, test loss = 0.291194
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 142/200. Took 0.055659 seconds. 
  Full-batch training loss = 0.016666, test loss = 0.291689
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 143/200. Took 0.060344 seconds. 
  Full-batch training loss = 0.016488, test loss = 0.291832
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 144/200. Took 0.054525 seconds. 
  Full-batch training loss = 0.016316, test loss = 0.291931
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 145/200. Took 0.051975 seconds. 
  Full-batch training loss = 0.016132, test loss = 0.292151
  Training set accuracy = 1.000000, Test set accuracy = 0.921500
 epoch 146/200. Took 0.056172 seconds. 
  Full-batch training loss = 0.015976, test loss = 0.292171
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 147/200. Took 0.063674 seconds. 
  Full-batch training loss = 0.015805, test loss = 0.292374
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 148/200. Took 0.055703 seconds. 
  Full-batch training loss = 0.015658, test loss = 0.292371
  Training set accuracy = 1.000000, Test set accuracy = 0.921300
 epoch 149/200. Took 0.051388 seconds. 
  Full-batch training loss = 0.015466, test loss = 0.292550
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 150/200. Took 0.055856 seconds. 
  Full-batch training loss = 0.015299, test loss = 0.292916
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 151/200. Took 0.051888 seconds. 
  Full-batch training loss = 0.015154, test loss = 0.292991
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 152/200. Took 0.054399 seconds. 
  Full-batch training loss = 0.015035, test loss = 0.293113
  Training set accuracy = 1.000000, Test set accuracy = 0.921200
 epoch 153/200. Took 0.05952 seconds. 
  Full-batch training loss = 0.014870, test loss = 0.293199
  Training set accuracy = 1.000000, Test set accuracy = 0.921400
 epoch 154/200. Took 0.05754 seconds. 
  Full-batch training loss = 0.014695, test loss = 0.293428
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 155/200. Took 0.0569 seconds. 
  Full-batch training loss = 0.014565, test loss = 0.293334
  Training set accuracy = 1.000000, Test set accuracy = 0.921500
 epoch 156/200. Took 0.054712 seconds. 
  Full-batch training loss = 0.014406, test loss = 0.293728
  Training set accuracy = 1.000000, Test set accuracy = 0.921600
 epoch 157/200. Took 0.05812 seconds. 
  Full-batch training loss = 0.014272, test loss = 0.293941
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 158/200. Took 0.062209 seconds. 
  Full-batch training loss = 0.014140, test loss = 0.294007
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 159/200. Took 0.054783 seconds. 
  Full-batch training loss = 0.013995, test loss = 0.294033
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 160/200. Took 0.05484 seconds. 
  Full-batch training loss = 0.013863, test loss = 0.294267
  Training set accuracy = 1.000000, Test set accuracy = 0.922000
 epoch 161/200. Took 0.052818 seconds. 
  Full-batch training loss = 0.013743, test loss = 0.294561
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 162/200. Took 0.054925 seconds. 
  Full-batch training loss = 0.013599, test loss = 0.294630
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 163/200. Took 0.054992 seconds. 
  Full-batch training loss = 0.013486, test loss = 0.294866
  Training set accuracy = 1.000000, Test set accuracy = 0.922100
 epoch 164/200. Took 0.055043 seconds. 
  Full-batch training loss = 0.013356, test loss = 0.294715
  Training set accuracy = 1.000000, Test set accuracy = 0.921500
 epoch 165/200. Took 0.051578 seconds. 
  Full-batch training loss = 0.013230, test loss = 0.294937
  Training set accuracy = 1.000000, Test set accuracy = 0.921600
 epoch 166/200. Took 0.056867 seconds. 
  Full-batch training loss = 0.013107, test loss = 0.295011
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 167/200. Took 0.061396 seconds. 
  Full-batch training loss = 0.012993, test loss = 0.295347
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 168/200. Took 0.056729 seconds. 
  Full-batch training loss = 0.012883, test loss = 0.295314
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 169/200. Took 0.057867 seconds. 
  Full-batch training loss = 0.012761, test loss = 0.295446
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 170/200. Took 0.057104 seconds. 
  Full-batch training loss = 0.012645, test loss = 0.295528
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 171/200. Took 0.059315 seconds. 
  Full-batch training loss = 0.012534, test loss = 0.296079
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 172/200. Took 0.058221 seconds. 
  Full-batch training loss = 0.012437, test loss = 0.296323
  Training set accuracy = 1.000000, Test set accuracy = 0.921600
 epoch 173/200. Took 0.064929 seconds. 
  Full-batch training loss = 0.012318, test loss = 0.296188
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 174/200. Took 0.046932 seconds. 
  Full-batch training loss = 0.012217, test loss = 0.296455
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 175/200. Took 0.053149 seconds. 
  Full-batch training loss = 0.012106, test loss = 0.296474
  Training set accuracy = 1.000000, Test set accuracy = 0.922000
 epoch 176/200. Took 0.055053 seconds. 
  Full-batch training loss = 0.012012, test loss = 0.296744
  Training set accuracy = 1.000000, Test set accuracy = 0.922000
 epoch 177/200. Took 0.053558 seconds. 
  Full-batch training loss = 0.011904, test loss = 0.296533
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 178/200. Took 0.054274 seconds. 
  Full-batch training loss = 0.011813, test loss = 0.296981
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 179/200. Took 0.055153 seconds. 
  Full-batch training loss = 0.011710, test loss = 0.297134
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 180/200. Took 0.049312 seconds. 
  Full-batch training loss = 0.011609, test loss = 0.297015
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 181/200. Took 0.055758 seconds. 
  Full-batch training loss = 0.011516, test loss = 0.297250
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 182/200. Took 0.064771 seconds. 
  Full-batch training loss = 0.011430, test loss = 0.297232
  Training set accuracy = 1.000000, Test set accuracy = 0.922000
 epoch 183/200. Took 0.059131 seconds. 
  Full-batch training loss = 0.011330, test loss = 0.297616
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 184/200. Took 0.064758 seconds. 
  Full-batch training loss = 0.011240, test loss = 0.297752
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 185/200. Took 0.06858 seconds. 
  Full-batch training loss = 0.011158, test loss = 0.297998
  Training set accuracy = 1.000000, Test set accuracy = 0.922100
 epoch 186/200. Took 0.055593 seconds. 
  Full-batch training loss = 0.011058, test loss = 0.298047
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 187/200. Took 0.061437 seconds. 
  Full-batch training loss = 0.010971, test loss = 0.298197
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 188/200. Took 0.064187 seconds. 
  Full-batch training loss = 0.010885, test loss = 0.298102
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 189/200. Took 0.065845 seconds. 
  Full-batch training loss = 0.010800, test loss = 0.298495
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 190/200. Took 0.059814 seconds. 
  Full-batch training loss = 0.010722, test loss = 0.298495
  Training set accuracy = 1.000000, Test set accuracy = 0.922200
 epoch 191/200. Took 0.063608 seconds. 
  Full-batch training loss = 0.010636, test loss = 0.298670
  Training set accuracy = 1.000000, Test set accuracy = 0.921700
 epoch 192/200. Took 0.058455 seconds. 
  Full-batch training loss = 0.010561, test loss = 0.298767
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 193/200. Took 0.060168 seconds. 
  Full-batch training loss = 0.010483, test loss = 0.299062
  Training set accuracy = 1.000000, Test set accuracy = 0.922300
 epoch 194/200. Took 0.054749 seconds. 
  Full-batch training loss = 0.010397, test loss = 0.299062
  Training set accuracy = 1.000000, Test set accuracy = 0.921600
 epoch 195/200. Took 0.05717 seconds. 
  Full-batch training loss = 0.010316, test loss = 0.299251
  Training set accuracy = 1.000000, Test set accuracy = 0.922100
 epoch 196/200. Took 0.054966 seconds. 
  Full-batch training loss = 0.010245, test loss = 0.299142
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 197/200. Took 0.056353 seconds. 
  Full-batch training loss = 0.010163, test loss = 0.299450
  Training set accuracy = 1.000000, Test set accuracy = 0.921900
 epoch 198/200. Took 0.053375 seconds. 
  Full-batch training loss = 0.010088, test loss = 0.299617
  Training set accuracy = 1.000000, Test set accuracy = 0.922100
 epoch 199/200. Took 0.054982 seconds. 
  Full-batch training loss = 0.010015, test loss = 0.299781
  Training set accuracy = 1.000000, Test set accuracy = 0.921800
 epoch 200/200. Took 0.056009 seconds. 
  Full-batch training loss = 0.009946, test loss = 0.300034
  Training set accuracy = 1.000000, Test set accuracy = 0.922200
Elapsed time is 58.923786 seconds.
End Training

learningRateRBM =

    0.1000

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.092465 seconds. Average reconstruction error is: 69.6449
 epoch 2/20. Took 0.11192 seconds. Average reconstruction error is: 40.0511
 epoch 3/20. Took 0.11165 seconds. Average reconstruction error is: 33.552
 epoch 4/20. Took 0.094656 seconds. Average reconstruction error is: 30.6937
 epoch 5/20. Took 0.1143 seconds. Average reconstruction error is: 28.7173
 epoch 6/20. Took 0.12418 seconds. Average reconstruction error is: 27.4677
 epoch 7/20. Took 0.11014 seconds. Average reconstruction error is: 26.4873
 epoch 8/20. Took 0.1065 seconds. Average reconstruction error is: 25.7718
 epoch 9/20. Took 0.10238 seconds. Average reconstruction error is: 25.1764
 epoch 10/20. Took 0.11854 seconds. Average reconstruction error is: 24.7011
 epoch 11/20. Took 0.10744 seconds. Average reconstruction error is: 24.2749
 epoch 12/20. Took 0.11183 seconds. Average reconstruction error is: 23.9439
 epoch 13/20. Took 0.11457 seconds. Average reconstruction error is: 23.6493
 epoch 14/20. Took 0.12389 seconds. Average reconstruction error is: 23.4144
 epoch 15/20. Took 0.11809 seconds. Average reconstruction error is: 23.0892
 epoch 16/20. Took 0.098726 seconds. Average reconstruction error is: 22.8732
 epoch 17/20. Took 0.11146 seconds. Average reconstruction error is: 22.7053
 epoch 18/20. Took 0.11801 seconds. Average reconstruction error is: 22.4505
 epoch 19/20. Took 0.12243 seconds. Average reconstruction error is: 22.2192
 epoch 20/20. Took 0.13795 seconds. Average reconstruction error is: 22.0217
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.067918 seconds. 
  Full-batch training loss = 2.169282, test loss = 2.146854
  Training set accuracy = 0.252500, Test set accuracy = 0.262100
 epoch 2/200. Took 0.056839 seconds. 
  Full-batch training loss = 1.931336, test loss = 1.915237
  Training set accuracy = 0.418500, Test set accuracy = 0.408000
 epoch 3/200. Took 0.06508 seconds. 
  Full-batch training loss = 1.737805, test loss = 1.727152
  Training set accuracy = 0.534000, Test set accuracy = 0.536100
 epoch 4/200. Took 0.065372 seconds. 
  Full-batch training loss = 1.578549, test loss = 1.573189
  Training set accuracy = 0.638000, Test set accuracy = 0.636100
 epoch 5/200. Took 0.06989 seconds. 
  Full-batch training loss = 1.448188, test loss = 1.446827
  Training set accuracy = 0.695000, Test set accuracy = 0.689200
 epoch 6/200. Took 0.062167 seconds. 
  Full-batch training loss = 1.339086, test loss = 1.341210
  Training set accuracy = 0.725000, Test set accuracy = 0.726900
 epoch 7/200. Took 0.095872 seconds. 
  Full-batch training loss = 1.248676, test loss = 1.253791
  Training set accuracy = 0.748500, Test set accuracy = 0.749500
 epoch 8/200. Took 0.063582 seconds. 
  Full-batch training loss = 1.171705, test loss = 1.179231
  Training set accuracy = 0.776000, Test set accuracy = 0.767100
 epoch 9/200. Took 0.093608 seconds. 
  Full-batch training loss = 1.106514, test loss = 1.116475
  Training set accuracy = 0.790000, Test set accuracy = 0.780200
 epoch 10/200. Took 0.044668 seconds. 
  Full-batch training loss = 1.050808, test loss = 1.062507
  Training set accuracy = 0.801000, Test set accuracy = 0.787600
 epoch 11/200. Took 0.058295 seconds. 
  Full-batch training loss = 1.002264, test loss = 1.015928
  Training set accuracy = 0.806500, Test set accuracy = 0.794900
 epoch 12/200. Took 0.064268 seconds. 
  Full-batch training loss = 0.960311, test loss = 0.975478
  Training set accuracy = 0.812000, Test set accuracy = 0.800000
 epoch 13/200. Took 0.081635 seconds. 
  Full-batch training loss = 0.922952, test loss = 0.939659
  Training set accuracy = 0.812500, Test set accuracy = 0.802900
 epoch 14/200. Took 0.081952 seconds. 
  Full-batch training loss = 0.890413, test loss = 0.908559
  Training set accuracy = 0.822000, Test set accuracy = 0.806200
 epoch 15/200. Took 0.08412 seconds. 
  Full-batch training loss = 0.861127, test loss = 0.880704
  Training set accuracy = 0.823500, Test set accuracy = 0.808700
 epoch 16/200. Took 0.077941 seconds. 
  Full-batch training loss = 0.834945, test loss = 0.855439
  Training set accuracy = 0.824000, Test set accuracy = 0.811100
 epoch 17/200. Took 0.055699 seconds. 
  Full-batch training loss = 0.811419, test loss = 0.833086
  Training set accuracy = 0.828500, Test set accuracy = 0.814100
 epoch 18/200. Took 0.11136 seconds. 
  Full-batch training loss = 0.790074, test loss = 0.812507
  Training set accuracy = 0.831500, Test set accuracy = 0.815700
 epoch 19/200. Took 0.050406 seconds. 
  Full-batch training loss = 0.770522, test loss = 0.793958
  Training set accuracy = 0.832000, Test set accuracy = 0.818700
 epoch 20/200. Took 0.050803 seconds. 
  Full-batch training loss = 0.752731, test loss = 0.777137
  Training set accuracy = 0.835000, Test set accuracy = 0.819300
 epoch 21/200. Took 0.07049 seconds. 
  Full-batch training loss = 0.736352, test loss = 0.761609
  Training set accuracy = 0.837000, Test set accuracy = 0.821000
 epoch 22/200. Took 0.049588 seconds. 
  Full-batch training loss = 0.721315, test loss = 0.747538
  Training set accuracy = 0.837500, Test set accuracy = 0.822700
 epoch 23/200. Took 0.049166 seconds. 
  Full-batch training loss = 0.707257, test loss = 0.734214
  Training set accuracy = 0.839000, Test set accuracy = 0.824100
 epoch 24/200. Took 0.051154 seconds. 
  Full-batch training loss = 0.694370, test loss = 0.721999
  Training set accuracy = 0.841500, Test set accuracy = 0.825000
 epoch 25/200. Took 0.050554 seconds. 
  Full-batch training loss = 0.682305, test loss = 0.710813
  Training set accuracy = 0.842000, Test set accuracy = 0.826400
 epoch 26/200. Took 0.04426 seconds. 
  Full-batch training loss = 0.670983, test loss = 0.700263
  Training set accuracy = 0.841500, Test set accuracy = 0.827700
 epoch 27/200. Took 0.049791 seconds. 
  Full-batch training loss = 0.660318, test loss = 0.690133
  Training set accuracy = 0.844000, Test set accuracy = 0.828500
 epoch 28/200. Took 0.048758 seconds. 
  Full-batch training loss = 0.650397, test loss = 0.680907
  Training set accuracy = 0.844500, Test set accuracy = 0.829900
 epoch 29/200. Took 0.046863 seconds. 
  Full-batch training loss = 0.641020, test loss = 0.672298
  Training set accuracy = 0.847000, Test set accuracy = 0.830100
 epoch 30/200. Took 0.068382 seconds. 
  Full-batch training loss = 0.632203, test loss = 0.664075
  Training set accuracy = 0.846000, Test set accuracy = 0.831800
 epoch 31/200. Took 0.067336 seconds. 
  Full-batch training loss = 0.623794, test loss = 0.656511
  Training set accuracy = 0.848000, Test set accuracy = 0.832100
 epoch 32/200. Took 0.064532 seconds. 
  Full-batch training loss = 0.615871, test loss = 0.649005
  Training set accuracy = 0.847500, Test set accuracy = 0.833700
 epoch 33/200. Took 0.048252 seconds. 
  Full-batch training loss = 0.608269, test loss = 0.642152
  Training set accuracy = 0.848500, Test set accuracy = 0.834400
 epoch 34/200. Took 0.049484 seconds. 
  Full-batch training loss = 0.601036, test loss = 0.635658
  Training set accuracy = 0.850000, Test set accuracy = 0.834900
 epoch 35/200. Took 0.059464 seconds. 
  Full-batch training loss = 0.594160, test loss = 0.629228
  Training set accuracy = 0.851000, Test set accuracy = 0.836000
 epoch 36/200. Took 0.080144 seconds. 
  Full-batch training loss = 0.587700, test loss = 0.623213
  Training set accuracy = 0.852500, Test set accuracy = 0.838200
 epoch 37/200. Took 0.068399 seconds. 
  Full-batch training loss = 0.581436, test loss = 0.617720
  Training set accuracy = 0.851500, Test set accuracy = 0.838400
 epoch 38/200. Took 0.080057 seconds. 
  Full-batch training loss = 0.575454, test loss = 0.612249
  Training set accuracy = 0.853500, Test set accuracy = 0.840000
 epoch 39/200. Took 0.057545 seconds. 
  Full-batch training loss = 0.569701, test loss = 0.606977
  Training set accuracy = 0.854500, Test set accuracy = 0.840200
 epoch 40/200. Took 0.053441 seconds. 
  Full-batch training loss = 0.564221, test loss = 0.602297
  Training set accuracy = 0.854000, Test set accuracy = 0.840300
 epoch 41/200. Took 0.066886 seconds. 
  Full-batch training loss = 0.558926, test loss = 0.597638
  Training set accuracy = 0.856000, Test set accuracy = 0.841300
 epoch 42/200. Took 0.055658 seconds. 
  Full-batch training loss = 0.553866, test loss = 0.592854
  Training set accuracy = 0.857500, Test set accuracy = 0.842000
 epoch 43/200. Took 0.06488 seconds. 
  Full-batch training loss = 0.548917, test loss = 0.588589
  Training set accuracy = 0.857000, Test set accuracy = 0.842800
 epoch 44/200. Took 0.050648 seconds. 
  Full-batch training loss = 0.544185, test loss = 0.584288
  Training set accuracy = 0.857000, Test set accuracy = 0.843300
 epoch 45/200. Took 0.048832 seconds. 
  Full-batch training loss = 0.539662, test loss = 0.580527
  Training set accuracy = 0.857000, Test set accuracy = 0.843600
 epoch 46/200. Took 0.053073 seconds. 
  Full-batch training loss = 0.535249, test loss = 0.576521
  Training set accuracy = 0.858000, Test set accuracy = 0.844200
 epoch 47/200. Took 0.055412 seconds. 
  Full-batch training loss = 0.530981, test loss = 0.572764
  Training set accuracy = 0.858500, Test set accuracy = 0.844100
 epoch 48/200. Took 0.051606 seconds. 
  Full-batch training loss = 0.526864, test loss = 0.569090
  Training set accuracy = 0.861000, Test set accuracy = 0.845800
 epoch 49/200. Took 0.053328 seconds. 
  Full-batch training loss = 0.522874, test loss = 0.565697
  Training set accuracy = 0.859500, Test set accuracy = 0.845700
 epoch 50/200. Took 0.054994 seconds. 
  Full-batch training loss = 0.518995, test loss = 0.562300
  Training set accuracy = 0.861500, Test set accuracy = 0.846600
 epoch 51/200. Took 0.06316 seconds. 
  Full-batch training loss = 0.515228, test loss = 0.559172
  Training set accuracy = 0.862000, Test set accuracy = 0.847600
 epoch 52/200. Took 0.050225 seconds. 
  Full-batch training loss = 0.511621, test loss = 0.556074
  Training set accuracy = 0.862000, Test set accuracy = 0.848200
 epoch 53/200. Took 0.061462 seconds. 
  Full-batch training loss = 0.508123, test loss = 0.552934
  Training set accuracy = 0.863500, Test set accuracy = 0.849200
 epoch 54/200. Took 0.046926 seconds. 
  Full-batch training loss = 0.504631, test loss = 0.550119
  Training set accuracy = 0.863500, Test set accuracy = 0.849600
 epoch 55/200. Took 0.047939 seconds. 
  Full-batch training loss = 0.501274, test loss = 0.547284
  Training set accuracy = 0.864000, Test set accuracy = 0.850400
 epoch 56/200. Took 0.046901 seconds. 
  Full-batch training loss = 0.498019, test loss = 0.544317
  Training set accuracy = 0.865000, Test set accuracy = 0.851200
 epoch 57/200. Took 0.061703 seconds. 
  Full-batch training loss = 0.494888, test loss = 0.541680
  Training set accuracy = 0.867000, Test set accuracy = 0.851400
 epoch 58/200. Took 0.052379 seconds. 
  Full-batch training loss = 0.491793, test loss = 0.539296
  Training set accuracy = 0.867000, Test set accuracy = 0.852100
 epoch 59/200. Took 0.053347 seconds. 
  Full-batch training loss = 0.488763, test loss = 0.536716
  Training set accuracy = 0.867000, Test set accuracy = 0.852500
 epoch 60/200. Took 0.048844 seconds. 
  Full-batch training loss = 0.485844, test loss = 0.534163
  Training set accuracy = 0.866500, Test set accuracy = 0.853200
 epoch 61/200. Took 0.041488 seconds. 
  Full-batch training loss = 0.482942, test loss = 0.531752
  Training set accuracy = 0.868000, Test set accuracy = 0.853000
 epoch 62/200. Took 0.064155 seconds. 
  Full-batch training loss = 0.480203, test loss = 0.529568
  Training set accuracy = 0.869000, Test set accuracy = 0.853800
 epoch 63/200. Took 0.049221 seconds. 
  Full-batch training loss = 0.477459, test loss = 0.527315
  Training set accuracy = 0.870000, Test set accuracy = 0.853900
 epoch 64/200. Took 0.069149 seconds. 
  Full-batch training loss = 0.474778, test loss = 0.525158
  Training set accuracy = 0.870500, Test set accuracy = 0.853900
 epoch 65/200. Took 0.053882 seconds. 
  Full-batch training loss = 0.472196, test loss = 0.522913
  Training set accuracy = 0.869000, Test set accuracy = 0.854400
 epoch 66/200. Took 0.056776 seconds. 
  Full-batch training loss = 0.469631, test loss = 0.520982
  Training set accuracy = 0.871000, Test set accuracy = 0.854600
 epoch 67/200. Took 0.056102 seconds. 
  Full-batch training loss = 0.467159, test loss = 0.518843
  Training set accuracy = 0.872000, Test set accuracy = 0.854700
 epoch 68/200. Took 0.053753 seconds. 
  Full-batch training loss = 0.464706, test loss = 0.516804
  Training set accuracy = 0.872000, Test set accuracy = 0.854400
 epoch 69/200. Took 0.060093 seconds. 
  Full-batch training loss = 0.462320, test loss = 0.515002
  Training set accuracy = 0.873500, Test set accuracy = 0.855400
 epoch 70/200. Took 0.054485 seconds. 
  Full-batch training loss = 0.459984, test loss = 0.512994
  Training set accuracy = 0.872500, Test set accuracy = 0.856100
 epoch 71/200. Took 0.065571 seconds. 
  Full-batch training loss = 0.457719, test loss = 0.511369
  Training set accuracy = 0.875000, Test set accuracy = 0.856500
 epoch 72/200. Took 0.058792 seconds. 
  Full-batch training loss = 0.455444, test loss = 0.509465
  Training set accuracy = 0.874000, Test set accuracy = 0.856500
 epoch 73/200. Took 0.060781 seconds. 
  Full-batch training loss = 0.453238, test loss = 0.507711
  Training set accuracy = 0.876500, Test set accuracy = 0.856500
 epoch 74/200. Took 0.056095 seconds. 
  Full-batch training loss = 0.451073, test loss = 0.505981
  Training set accuracy = 0.876500, Test set accuracy = 0.857500
 epoch 75/200. Took 0.042544 seconds. 
  Full-batch training loss = 0.448956, test loss = 0.504374
  Training set accuracy = 0.878000, Test set accuracy = 0.857700
 epoch 76/200. Took 0.047921 seconds. 
  Full-batch training loss = 0.446866, test loss = 0.502766
  Training set accuracy = 0.877500, Test set accuracy = 0.857500
 epoch 77/200. Took 0.061296 seconds. 
  Full-batch training loss = 0.444838, test loss = 0.501175
  Training set accuracy = 0.878500, Test set accuracy = 0.857700
 epoch 78/200. Took 0.04607 seconds. 
  Full-batch training loss = 0.442875, test loss = 0.499507
  Training set accuracy = 0.877500, Test set accuracy = 0.858600
 epoch 79/200. Took 0.042623 seconds. 
  Full-batch training loss = 0.440864, test loss = 0.498155
  Training set accuracy = 0.879500, Test set accuracy = 0.857600
 epoch 80/200. Took 0.043288 seconds. 
  Full-batch training loss = 0.438902, test loss = 0.496604
  Training set accuracy = 0.879000, Test set accuracy = 0.858500
 epoch 81/200. Took 0.044397 seconds. 
  Full-batch training loss = 0.437021, test loss = 0.495050
  Training set accuracy = 0.878500, Test set accuracy = 0.858700
 epoch 82/200. Took 0.046523 seconds. 
  Full-batch training loss = 0.435120, test loss = 0.493775
  Training set accuracy = 0.879500, Test set accuracy = 0.859100
 epoch 83/200. Took 0.045767 seconds. 
  Full-batch training loss = 0.433298, test loss = 0.492301
  Training set accuracy = 0.879500, Test set accuracy = 0.859400
 epoch 84/200. Took 0.048285 seconds. 
  Full-batch training loss = 0.431480, test loss = 0.490912
  Training set accuracy = 0.880000, Test set accuracy = 0.860100
 epoch 85/200. Took 0.043096 seconds. 
  Full-batch training loss = 0.429722, test loss = 0.489525
  Training set accuracy = 0.881000, Test set accuracy = 0.860400
 epoch 86/200. Took 0.053595 seconds. 
  Full-batch training loss = 0.427949, test loss = 0.488267
  Training set accuracy = 0.881000, Test set accuracy = 0.860400
 epoch 87/200. Took 0.047043 seconds. 
  Full-batch training loss = 0.426237, test loss = 0.486820
  Training set accuracy = 0.881000, Test set accuracy = 0.860500
 epoch 88/200. Took 0.047099 seconds. 
  Full-batch training loss = 0.424517, test loss = 0.485503
  Training set accuracy = 0.882500, Test set accuracy = 0.860500
 epoch 89/200. Took 0.046791 seconds. 
  Full-batch training loss = 0.422846, test loss = 0.484317
  Training set accuracy = 0.883000, Test set accuracy = 0.860400
 epoch 90/200. Took 0.051914 seconds. 
  Full-batch training loss = 0.421186, test loss = 0.483168
  Training set accuracy = 0.882500, Test set accuracy = 0.861300
 epoch 91/200. Took 0.048105 seconds. 
  Full-batch training loss = 0.419568, test loss = 0.481956
  Training set accuracy = 0.883000, Test set accuracy = 0.861400
 epoch 92/200. Took 0.044083 seconds. 
  Full-batch training loss = 0.417961, test loss = 0.480750
  Training set accuracy = 0.885500, Test set accuracy = 0.861400
 epoch 93/200. Took 0.042584 seconds. 
  Full-batch training loss = 0.416367, test loss = 0.479539
  Training set accuracy = 0.884500, Test set accuracy = 0.862000
 epoch 94/200. Took 0.041282 seconds. 
  Full-batch training loss = 0.414822, test loss = 0.478428
  Training set accuracy = 0.886500, Test set accuracy = 0.861300
 epoch 95/200. Took 0.045582 seconds. 
  Full-batch training loss = 0.413278, test loss = 0.477405
  Training set accuracy = 0.886000, Test set accuracy = 0.861700
 epoch 96/200. Took 0.04833 seconds. 
  Full-batch training loss = 0.411753, test loss = 0.476275
  Training set accuracy = 0.887000, Test set accuracy = 0.861800
 epoch 97/200. Took 0.047888 seconds. 
  Full-batch training loss = 0.410251, test loss = 0.475217
  Training set accuracy = 0.888000, Test set accuracy = 0.862600
 epoch 98/200. Took 0.048469 seconds. 
  Full-batch training loss = 0.408776, test loss = 0.474034
  Training set accuracy = 0.887000, Test set accuracy = 0.861900
 epoch 99/200. Took 0.048641 seconds. 
  Full-batch training loss = 0.407301, test loss = 0.472963
  Training set accuracy = 0.888500, Test set accuracy = 0.862800
 epoch 100/200. Took 0.046023 seconds. 
  Full-batch training loss = 0.405862, test loss = 0.472065
  Training set accuracy = 0.889000, Test set accuracy = 0.863100
 epoch 101/200. Took 0.044512 seconds. 
  Full-batch training loss = 0.404443, test loss = 0.471017
  Training set accuracy = 0.888500, Test set accuracy = 0.863300
 epoch 102/200. Took 0.042783 seconds. 
  Full-batch training loss = 0.403041, test loss = 0.470038
  Training set accuracy = 0.889000, Test set accuracy = 0.864000
 epoch 103/200. Took 0.049451 seconds. 
  Full-batch training loss = 0.401644, test loss = 0.468958
  Training set accuracy = 0.890000, Test set accuracy = 0.863900
 epoch 104/200. Took 0.046304 seconds. 
  Full-batch training loss = 0.400270, test loss = 0.468017
  Training set accuracy = 0.890500, Test set accuracy = 0.864600
 epoch 105/200. Took 0.047171 seconds. 
  Full-batch training loss = 0.398918, test loss = 0.467112
  Training set accuracy = 0.891000, Test set accuracy = 0.864200
 epoch 106/200. Took 0.043793 seconds. 
  Full-batch training loss = 0.397559, test loss = 0.466132
  Training set accuracy = 0.889500, Test set accuracy = 0.864800
 epoch 107/200. Took 0.042563 seconds. 
  Full-batch training loss = 0.396238, test loss = 0.465284
  Training set accuracy = 0.889500, Test set accuracy = 0.864600
 epoch 108/200. Took 0.043567 seconds. 
  Full-batch training loss = 0.394944, test loss = 0.464389
  Training set accuracy = 0.891000, Test set accuracy = 0.865300
 epoch 109/200. Took 0.046381 seconds. 
  Full-batch training loss = 0.393634, test loss = 0.463453
  Training set accuracy = 0.891500, Test set accuracy = 0.865200
 epoch 110/200. Took 0.044046 seconds. 
  Full-batch training loss = 0.392378, test loss = 0.462590
  Training set accuracy = 0.891500, Test set accuracy = 0.865200
 epoch 111/200. Took 0.040251 seconds. 
  Full-batch training loss = 0.391086, test loss = 0.461728
  Training set accuracy = 0.891500, Test set accuracy = 0.865500
 epoch 112/200. Took 0.045432 seconds. 
  Full-batch training loss = 0.389838, test loss = 0.460718
  Training set accuracy = 0.891500, Test set accuracy = 0.866300
 epoch 113/200. Took 0.041682 seconds. 
  Full-batch training loss = 0.388606, test loss = 0.460038
  Training set accuracy = 0.893000, Test set accuracy = 0.865700
 epoch 114/200. Took 0.047347 seconds. 
  Full-batch training loss = 0.387368, test loss = 0.459304
  Training set accuracy = 0.894000, Test set accuracy = 0.865600
 epoch 115/200. Took 0.047007 seconds. 
  Full-batch training loss = 0.386153, test loss = 0.458259
  Training set accuracy = 0.891500, Test set accuracy = 0.866000
 epoch 116/200. Took 0.049824 seconds. 
  Full-batch training loss = 0.384948, test loss = 0.457572
  Training set accuracy = 0.893500, Test set accuracy = 0.866700
 epoch 117/200. Took 0.047281 seconds. 
  Full-batch training loss = 0.383774, test loss = 0.456750
  Training set accuracy = 0.893000, Test set accuracy = 0.867000
 epoch 118/200. Took 0.052101 seconds. 
  Full-batch training loss = 0.382596, test loss = 0.455861
  Training set accuracy = 0.894000, Test set accuracy = 0.867500
 epoch 119/200. Took 0.046849 seconds. 
  Full-batch training loss = 0.381422, test loss = 0.455259
  Training set accuracy = 0.894000, Test set accuracy = 0.867400
 epoch 120/200. Took 0.045429 seconds. 
  Full-batch training loss = 0.380294, test loss = 0.454392
  Training set accuracy = 0.894000, Test set accuracy = 0.867300
 epoch 121/200. Took 0.047328 seconds. 
  Full-batch training loss = 0.379128, test loss = 0.453625
  Training set accuracy = 0.894500, Test set accuracy = 0.868400
 epoch 122/200. Took 0.046938 seconds. 
  Full-batch training loss = 0.377979, test loss = 0.452875
  Training set accuracy = 0.894000, Test set accuracy = 0.868400
 epoch 123/200. Took 0.047299 seconds. 
  Full-batch training loss = 0.376891, test loss = 0.452272
  Training set accuracy = 0.894000, Test set accuracy = 0.868400
 epoch 124/200. Took 0.047252 seconds. 
  Full-batch training loss = 0.375742, test loss = 0.451398
  Training set accuracy = 0.895500, Test set accuracy = 0.868900
 epoch 125/200. Took 0.051855 seconds. 
  Full-batch training loss = 0.374646, test loss = 0.450757
  Training set accuracy = 0.895500, Test set accuracy = 0.868600
 epoch 126/200. Took 0.045287 seconds. 
  Full-batch training loss = 0.373581, test loss = 0.450205
  Training set accuracy = 0.895500, Test set accuracy = 0.868800
 epoch 127/200. Took 0.042215 seconds. 
  Full-batch training loss = 0.372480, test loss = 0.449333
  Training set accuracy = 0.895000, Test set accuracy = 0.868600
 epoch 128/200. Took 0.041918 seconds. 
  Full-batch training loss = 0.371408, test loss = 0.448840
  Training set accuracy = 0.895000, Test set accuracy = 0.869100
 epoch 129/200. Took 0.047337 seconds. 
  Full-batch training loss = 0.370331, test loss = 0.448062
  Training set accuracy = 0.896500, Test set accuracy = 0.869400
 epoch 130/200. Took 0.050044 seconds. 
  Full-batch training loss = 0.369265, test loss = 0.447290
  Training set accuracy = 0.897500, Test set accuracy = 0.869700
 epoch 131/200. Took 0.044546 seconds. 
  Full-batch training loss = 0.368233, test loss = 0.446695
  Training set accuracy = 0.896500, Test set accuracy = 0.869700
 epoch 132/200. Took 0.047074 seconds. 
  Full-batch training loss = 0.367190, test loss = 0.446058
  Training set accuracy = 0.896500, Test set accuracy = 0.869700
 epoch 133/200. Took 0.047636 seconds. 
  Full-batch training loss = 0.366158, test loss = 0.445270
  Training set accuracy = 0.896500, Test set accuracy = 0.869700
 epoch 134/200. Took 0.047275 seconds. 
  Full-batch training loss = 0.365141, test loss = 0.444655
  Training set accuracy = 0.897500, Test set accuracy = 0.869700
 epoch 135/200. Took 0.047419 seconds. 
  Full-batch training loss = 0.364123, test loss = 0.444067
  Training set accuracy = 0.897500, Test set accuracy = 0.869400
 epoch 136/200. Took 0.041703 seconds. 
  Full-batch training loss = 0.363137, test loss = 0.443605
  Training set accuracy = 0.897500, Test set accuracy = 0.869700
 epoch 137/200. Took 0.045756 seconds. 
  Full-batch training loss = 0.362121, test loss = 0.442819
  Training set accuracy = 0.898500, Test set accuracy = 0.869800
 epoch 138/200. Took 0.043712 seconds. 
  Full-batch training loss = 0.361143, test loss = 0.442236
  Training set accuracy = 0.898500, Test set accuracy = 0.870300
 epoch 139/200. Took 0.047564 seconds. 
  Full-batch training loss = 0.360142, test loss = 0.441589
  Training set accuracy = 0.898500, Test set accuracy = 0.870100
 epoch 140/200. Took 0.047273 seconds. 
  Full-batch training loss = 0.359194, test loss = 0.441098
  Training set accuracy = 0.899500, Test set accuracy = 0.870300
 epoch 141/200. Took 0.048233 seconds. 
  Full-batch training loss = 0.358244, test loss = 0.440424
  Training set accuracy = 0.900000, Test set accuracy = 0.870300
 epoch 142/200. Took 0.047789 seconds. 
  Full-batch training loss = 0.357287, test loss = 0.439940
  Training set accuracy = 0.899000, Test set accuracy = 0.871000
 epoch 143/200. Took 0.041559 seconds. 
  Full-batch training loss = 0.356319, test loss = 0.439280
  Training set accuracy = 0.900500, Test set accuracy = 0.870600
 epoch 144/200. Took 0.04199 seconds. 
  Full-batch training loss = 0.355373, test loss = 0.438702
  Training set accuracy = 0.900500, Test set accuracy = 0.870600
 epoch 145/200. Took 0.043306 seconds. 
  Full-batch training loss = 0.354431, test loss = 0.438155
  Training set accuracy = 0.901000, Test set accuracy = 0.870900
 epoch 146/200. Took 0.049694 seconds. 
  Full-batch training loss = 0.353512, test loss = 0.437634
  Training set accuracy = 0.901000, Test set accuracy = 0.870600
 epoch 147/200. Took 0.046861 seconds. 
  Full-batch training loss = 0.352582, test loss = 0.436977
  Training set accuracy = 0.902000, Test set accuracy = 0.870900
 epoch 148/200. Took 0.046022 seconds. 
  Full-batch training loss = 0.351697, test loss = 0.436338
  Training set accuracy = 0.901500, Test set accuracy = 0.871100
 epoch 149/200. Took 0.045494 seconds. 
  Full-batch training loss = 0.350752, test loss = 0.435944
  Training set accuracy = 0.901500, Test set accuracy = 0.870900
 epoch 150/200. Took 0.044404 seconds. 
  Full-batch training loss = 0.349853, test loss = 0.435408
  Training set accuracy = 0.902000, Test set accuracy = 0.870600
 epoch 151/200. Took 0.051458 seconds. 
  Full-batch training loss = 0.348974, test loss = 0.435000
  Training set accuracy = 0.902000, Test set accuracy = 0.871200
 epoch 152/200. Took 0.045896 seconds. 
  Full-batch training loss = 0.348062, test loss = 0.434459
  Training set accuracy = 0.902500, Test set accuracy = 0.871400
 epoch 153/200. Took 0.042074 seconds. 
  Full-batch training loss = 0.347175, test loss = 0.433826
  Training set accuracy = 0.903500, Test set accuracy = 0.871300
 epoch 154/200. Took 0.044176 seconds. 
  Full-batch training loss = 0.346300, test loss = 0.433407
  Training set accuracy = 0.903000, Test set accuracy = 0.871200
 epoch 155/200. Took 0.042651 seconds. 
  Full-batch training loss = 0.345437, test loss = 0.432946
  Training set accuracy = 0.902500, Test set accuracy = 0.871800
 epoch 156/200. Took 0.04378 seconds. 
  Full-batch training loss = 0.344565, test loss = 0.432358
  Training set accuracy = 0.903000, Test set accuracy = 0.871500
 epoch 157/200. Took 0.046492 seconds. 
  Full-batch training loss = 0.343694, test loss = 0.431809
  Training set accuracy = 0.903500, Test set accuracy = 0.871700
 epoch 158/200. Took 0.043334 seconds. 
  Full-batch training loss = 0.342838, test loss = 0.431411
  Training set accuracy = 0.904000, Test set accuracy = 0.872100
 epoch 159/200. Took 0.045888 seconds. 
  Full-batch training loss = 0.341997, test loss = 0.430908
  Training set accuracy = 0.904500, Test set accuracy = 0.871700
 epoch 160/200. Took 0.046699 seconds. 
  Full-batch training loss = 0.341171, test loss = 0.430384
  Training set accuracy = 0.905000, Test set accuracy = 0.871400
 epoch 161/200. Took 0.049879 seconds. 
  Full-batch training loss = 0.340325, test loss = 0.429929
  Training set accuracy = 0.905000, Test set accuracy = 0.871400
 epoch 162/200. Took 0.046749 seconds. 
  Full-batch training loss = 0.339475, test loss = 0.429539
  Training set accuracy = 0.905500, Test set accuracy = 0.872300
 epoch 163/200. Took 0.04597 seconds. 
  Full-batch training loss = 0.338649, test loss = 0.429080
  Training set accuracy = 0.905000, Test set accuracy = 0.872300
 epoch 164/200. Took 0.046016 seconds. 
  Full-batch training loss = 0.337831, test loss = 0.428583
  Training set accuracy = 0.905000, Test set accuracy = 0.872200
 epoch 165/200. Took 0.042103 seconds. 
  Full-batch training loss = 0.337005, test loss = 0.428149
  Training set accuracy = 0.905500, Test set accuracy = 0.872300
 epoch 166/200. Took 0.046011 seconds. 
  Full-batch training loss = 0.336218, test loss = 0.427844
  Training set accuracy = 0.906000, Test set accuracy = 0.873100
 epoch 167/200. Took 0.046558 seconds. 
  Full-batch training loss = 0.335386, test loss = 0.427184
  Training set accuracy = 0.906000, Test set accuracy = 0.872700
 epoch 168/200. Took 0.040649 seconds. 
  Full-batch training loss = 0.334575, test loss = 0.426772
  Training set accuracy = 0.906500, Test set accuracy = 0.872700
 epoch 169/200. Took 0.043791 seconds. 
  Full-batch training loss = 0.333791, test loss = 0.426367
  Training set accuracy = 0.907000, Test set accuracy = 0.872800
 epoch 170/200. Took 0.04329 seconds. 
  Full-batch training loss = 0.332991, test loss = 0.425820
  Training set accuracy = 0.907000, Test set accuracy = 0.872500
 epoch 171/200. Took 0.054192 seconds. 
  Full-batch training loss = 0.332213, test loss = 0.425360
  Training set accuracy = 0.908000, Test set accuracy = 0.872800
 epoch 172/200. Took 0.048898 seconds. 
  Full-batch training loss = 0.331420, test loss = 0.425134
  Training set accuracy = 0.907500, Test set accuracy = 0.872600
 epoch 173/200. Took 0.040387 seconds. 
  Full-batch training loss = 0.330640, test loss = 0.424658
  Training set accuracy = 0.908000, Test set accuracy = 0.872800
 epoch 174/200. Took 0.046403 seconds. 
  Full-batch training loss = 0.329871, test loss = 0.424151
  Training set accuracy = 0.908000, Test set accuracy = 0.873000
 epoch 175/200. Took 0.047578 seconds. 
  Full-batch training loss = 0.329115, test loss = 0.423773
  Training set accuracy = 0.909500, Test set accuracy = 0.873400
 epoch 176/200. Took 0.042965 seconds. 
  Full-batch training loss = 0.328335, test loss = 0.423519
  Training set accuracy = 0.909000, Test set accuracy = 0.873000
 epoch 177/200. Took 0.042684 seconds. 
  Full-batch training loss = 0.327574, test loss = 0.422964
  Training set accuracy = 0.909500, Test set accuracy = 0.873200
 epoch 178/200. Took 0.042566 seconds. 
  Full-batch training loss = 0.326813, test loss = 0.422572
  Training set accuracy = 0.909000, Test set accuracy = 0.873200
 epoch 179/200. Took 0.042905 seconds. 
  Full-batch training loss = 0.326058, test loss = 0.422138
  Training set accuracy = 0.909000, Test set accuracy = 0.873000
 epoch 180/200. Took 0.051961 seconds. 
  Full-batch training loss = 0.325311, test loss = 0.421806
  Training set accuracy = 0.909500, Test set accuracy = 0.873200
 epoch 181/200. Took 0.047147 seconds. 
  Full-batch training loss = 0.324567, test loss = 0.421326
  Training set accuracy = 0.910000, Test set accuracy = 0.873800
 epoch 182/200. Took 0.053838 seconds. 
  Full-batch training loss = 0.323817, test loss = 0.421035
  Training set accuracy = 0.911000, Test set accuracy = 0.873400
 epoch 183/200. Took 0.054515 seconds. 
  Full-batch training loss = 0.323089, test loss = 0.420710
  Training set accuracy = 0.911000, Test set accuracy = 0.873600
 epoch 184/200. Took 0.04805 seconds. 
  Full-batch training loss = 0.322371, test loss = 0.420419
  Training set accuracy = 0.910000, Test set accuracy = 0.873800
 epoch 185/200. Took 0.044335 seconds. 
  Full-batch training loss = 0.321626, test loss = 0.419966
  Training set accuracy = 0.912500, Test set accuracy = 0.873500
 epoch 186/200. Took 0.043438 seconds. 
  Full-batch training loss = 0.320890, test loss = 0.419468
  Training set accuracy = 0.912000, Test set accuracy = 0.873600
 epoch 187/200. Took 0.050791 seconds. 
  Full-batch training loss = 0.320165, test loss = 0.419157
  Training set accuracy = 0.914000, Test set accuracy = 0.873900
 epoch 188/200. Took 0.043159 seconds. 
  Full-batch training loss = 0.319459, test loss = 0.418689
  Training set accuracy = 0.913000, Test set accuracy = 0.873500
 epoch 189/200. Took 0.043394 seconds. 
  Full-batch training loss = 0.318759, test loss = 0.418487
  Training set accuracy = 0.913500, Test set accuracy = 0.873500
 epoch 190/200. Took 0.042815 seconds. 
  Full-batch training loss = 0.318029, test loss = 0.417920
  Training set accuracy = 0.913500, Test set accuracy = 0.873700
 epoch 191/200. Took 0.043833 seconds. 
  Full-batch training loss = 0.317333, test loss = 0.417801
  Training set accuracy = 0.912500, Test set accuracy = 0.874000
 epoch 192/200. Took 0.050771 seconds. 
  Full-batch training loss = 0.316616, test loss = 0.417331
  Training set accuracy = 0.914500, Test set accuracy = 0.873600
 epoch 193/200. Took 0.047474 seconds. 
  Full-batch training loss = 0.315918, test loss = 0.416896
  Training set accuracy = 0.913000, Test set accuracy = 0.874100
 epoch 194/200. Took 0.043633 seconds. 
  Full-batch training loss = 0.315221, test loss = 0.416674
  Training set accuracy = 0.915000, Test set accuracy = 0.873900
 epoch 195/200. Took 0.043974 seconds. 
  Full-batch training loss = 0.314543, test loss = 0.416218
  Training set accuracy = 0.913000, Test set accuracy = 0.874000
 epoch 196/200. Took 0.041912 seconds. 
  Full-batch training loss = 0.313831, test loss = 0.415883
  Training set accuracy = 0.915000, Test set accuracy = 0.874100
 epoch 197/200. Took 0.051712 seconds. 
  Full-batch training loss = 0.313153, test loss = 0.415597
  Training set accuracy = 0.915500, Test set accuracy = 0.874200
 epoch 198/200. Took 0.049549 seconds. 
  Full-batch training loss = 0.312469, test loss = 0.415265
  Training set accuracy = 0.915500, Test set accuracy = 0.874300
 epoch 199/200. Took 0.046871 seconds. 
  Full-batch training loss = 0.311800, test loss = 0.414971
  Training set accuracy = 0.914500, Test set accuracy = 0.874600
 epoch 200/200. Took 0.047929 seconds. 
  Full-batch training loss = 0.311130, test loss = 0.414645
  Training set accuracy = 0.916000, Test set accuracy = 0.874600
Elapsed time is 52.110330 seconds.
End Training

learningRateRBM =

    0.1000

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 50 epochs (batchsize: 100)
 epoch 1/50. Took 0.081706 seconds. Average reconstruction error is: 67.8925
 epoch 2/50. Took 0.083356 seconds. Average reconstruction error is: 38.9397
 epoch 3/50. Took 0.082111 seconds. Average reconstruction error is: 33.65
 epoch 4/50. Took 0.094789 seconds. Average reconstruction error is: 30.5391
 epoch 5/50. Took 0.091956 seconds. Average reconstruction error is: 28.3916
 epoch 6/50. Took 0.091943 seconds. Average reconstruction error is: 27.1109
 epoch 7/50. Took 0.099477 seconds. Average reconstruction error is: 26.0809
 epoch 8/50. Took 0.10174 seconds. Average reconstruction error is: 25.359
 epoch 9/50. Took 0.10325 seconds. Average reconstruction error is: 24.726
 epoch 10/50. Took 0.13434 seconds. Average reconstruction error is: 24.2684
 epoch 11/50. Took 0.13597 seconds. Average reconstruction error is: 23.8094
 epoch 12/50. Took 0.11536 seconds. Average reconstruction error is: 23.4736
 epoch 13/50. Took 0.09072 seconds. Average reconstruction error is: 23.1486
 epoch 14/50. Took 0.081816 seconds. Average reconstruction error is: 22.8099
 epoch 15/50. Took 0.081095 seconds. Average reconstruction error is: 22.5903
 epoch 16/50. Took 0.08647 seconds. Average reconstruction error is: 22.3814
 epoch 17/50. Took 0.080841 seconds. Average reconstruction error is: 22.1522
 epoch 18/50. Took 0.077743 seconds. Average reconstruction error is: 22.024
 epoch 19/50. Took 0.081606 seconds. Average reconstruction error is: 21.9351
 epoch 20/50. Took 0.08928 seconds. Average reconstruction error is: 21.6628
 epoch 21/50. Took 0.084346 seconds. Average reconstruction error is: 21.5423
 epoch 22/50. Took 0.088776 seconds. Average reconstruction error is: 21.3716
 epoch 23/50. Took 0.085796 seconds. Average reconstruction error is: 21.2694
 epoch 24/50. Took 0.086114 seconds. Average reconstruction error is: 21.1324
 epoch 25/50. Took 0.085577 seconds. Average reconstruction error is: 21.0032
 epoch 26/50. Took 0.086227 seconds. Average reconstruction error is: 20.9017
 epoch 27/50. Took 0.083659 seconds. Average reconstruction error is: 20.7949
 epoch 28/50. Took 0.083752 seconds. Average reconstruction error is: 20.6957
 epoch 29/50. Took 0.078053 seconds. Average reconstruction error is: 20.5705
 epoch 30/50. Took 0.086358 seconds. Average reconstruction error is: 20.5016
 epoch 31/50. Took 0.077889 seconds. Average reconstruction error is: 20.3991
 epoch 32/50. Took 0.078444 seconds. Average reconstruction error is: 20.3406
 epoch 33/50. Took 0.08436 seconds. Average reconstruction error is: 20.3279
 epoch 34/50. Took 0.085266 seconds. Average reconstruction error is: 20.2116
 epoch 35/50. Took 0.076102 seconds. Average reconstruction error is: 20.0875
 epoch 36/50. Took 0.083781 seconds. Average reconstruction error is: 20.0596
 epoch 37/50. Took 0.091664 seconds. Average reconstruction error is: 20.027
 epoch 38/50. Took 0.084586 seconds. Average reconstruction error is: 20.0027
 epoch 39/50. Took 0.081423 seconds. Average reconstruction error is: 19.8778
 epoch 40/50. Took 0.082329 seconds. Average reconstruction error is: 19.8175
 epoch 41/50. Took 0.086331 seconds. Average reconstruction error is: 19.7521
 epoch 42/50. Took 0.085211 seconds. Average reconstruction error is: 19.7468
 epoch 43/50. Took 0.083169 seconds. Average reconstruction error is: 19.7111
 epoch 44/50. Took 0.086965 seconds. Average reconstruction error is: 19.6329
 epoch 45/50. Took 0.084366 seconds. Average reconstruction error is: 19.5704
 epoch 46/50. Took 0.086842 seconds. Average reconstruction error is: 19.5764
 epoch 47/50. Took 0.084649 seconds. Average reconstruction error is: 19.501
 epoch 48/50. Took 0.085883 seconds. Average reconstruction error is: 19.4261
 epoch 49/50. Took 0.088191 seconds. Average reconstruction error is: 19.3466
 epoch 50/50. Took 0.085002 seconds. Average reconstruction error is: 19.345
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.050179 seconds. 
  Full-batch training loss = 2.154726, test loss = 2.137540
  Training set accuracy = 0.252500, Test set accuracy = 0.254900
 epoch 2/200. Took 0.061276 seconds. 
  Full-batch training loss = 1.936350, test loss = 1.921910
  Training set accuracy = 0.371500, Test set accuracy = 0.395800
 epoch 3/200. Took 0.070698 seconds. 
  Full-batch training loss = 1.758517, test loss = 1.747447
  Training set accuracy = 0.497500, Test set accuracy = 0.515100
 epoch 4/200. Took 0.080313 seconds. 
  Full-batch training loss = 1.612011, test loss = 1.602944
  Training set accuracy = 0.595000, Test set accuracy = 0.602100
 epoch 5/200. Took 0.071709 seconds. 
  Full-batch training loss = 1.489057, test loss = 1.482263
  Training set accuracy = 0.653000, Test set accuracy = 0.657900
 epoch 6/200. Took 0.052021 seconds. 
  Full-batch training loss = 1.385539, test loss = 1.380926
  Training set accuracy = 0.694000, Test set accuracy = 0.698300
 epoch 7/200. Took 0.048518 seconds. 
  Full-batch training loss = 1.297937, test loss = 1.295264
  Training set accuracy = 0.721000, Test set accuracy = 0.728600
 epoch 8/200. Took 0.045958 seconds. 
  Full-batch training loss = 1.222892, test loss = 1.221693
  Training set accuracy = 0.739500, Test set accuracy = 0.748600
 epoch 9/200. Took 0.06654 seconds. 
  Full-batch training loss = 1.158614, test loss = 1.158862
  Training set accuracy = 0.752500, Test set accuracy = 0.763700
 epoch 10/200. Took 0.06637 seconds. 
  Full-batch training loss = 1.102378, test loss = 1.103434
  Training set accuracy = 0.767500, Test set accuracy = 0.777100
 epoch 11/200. Took 0.071398 seconds. 
  Full-batch training loss = 1.053762, test loss = 1.056461
  Training set accuracy = 0.773000, Test set accuracy = 0.784000
 epoch 12/200. Took 0.04613 seconds. 
  Full-batch training loss = 1.010529, test loss = 1.013717
  Training set accuracy = 0.783000, Test set accuracy = 0.791500
 epoch 13/200. Took 0.044141 seconds. 
  Full-batch training loss = 0.972727, test loss = 0.977040
  Training set accuracy = 0.788000, Test set accuracy = 0.797000
 epoch 14/200. Took 0.066418 seconds. 
  Full-batch training loss = 0.938865, test loss = 0.943713
  Training set accuracy = 0.791500, Test set accuracy = 0.804000
 epoch 15/200. Took 0.072118 seconds. 
  Full-batch training loss = 0.908432, test loss = 0.913831
  Training set accuracy = 0.799000, Test set accuracy = 0.810300
 epoch 16/200. Took 0.063919 seconds. 
  Full-batch training loss = 0.880974, test loss = 0.887641
  Training set accuracy = 0.800500, Test set accuracy = 0.812100
 epoch 17/200. Took 0.045755 seconds. 
  Full-batch training loss = 0.856154, test loss = 0.863461
  Training set accuracy = 0.807000, Test set accuracy = 0.815300
 epoch 18/200. Took 0.043495 seconds. 
  Full-batch training loss = 0.833607, test loss = 0.842067
  Training set accuracy = 0.812500, Test set accuracy = 0.818700
 epoch 19/200. Took 0.047256 seconds. 
  Full-batch training loss = 0.812913, test loss = 0.820992
  Training set accuracy = 0.815500, Test set accuracy = 0.820600
 epoch 20/200. Took 0.0704 seconds. 
  Full-batch training loss = 0.793965, test loss = 0.803196
  Training set accuracy = 0.819500, Test set accuracy = 0.823700
 epoch 21/200. Took 0.071071 seconds. 
  Full-batch training loss = 0.776541, test loss = 0.786520
  Training set accuracy = 0.822000, Test set accuracy = 0.825100
 epoch 22/200. Took 0.056575 seconds. 
  Full-batch training loss = 0.760501, test loss = 0.770757
  Training set accuracy = 0.825000, Test set accuracy = 0.829100
 epoch 23/200. Took 0.05089 seconds. 
  Full-batch training loss = 0.745436, test loss = 0.756469
  Training set accuracy = 0.826000, Test set accuracy = 0.830300
 epoch 24/200. Took 0.051052 seconds. 
  Full-batch training loss = 0.731512, test loss = 0.742961
  Training set accuracy = 0.828000, Test set accuracy = 0.831400
 epoch 25/200. Took 0.097832 seconds. 
  Full-batch training loss = 0.718461, test loss = 0.730235
  Training set accuracy = 0.830500, Test set accuracy = 0.832700
 epoch 26/200. Took 0.066989 seconds. 
  Full-batch training loss = 0.706245, test loss = 0.718555
  Training set accuracy = 0.830000, Test set accuracy = 0.833000
 epoch 27/200. Took 0.052238 seconds. 
  Full-batch training loss = 0.694825, test loss = 0.708041
  Training set accuracy = 0.831500, Test set accuracy = 0.833900
 epoch 28/200. Took 0.048973 seconds. 
  Full-batch training loss = 0.684044, test loss = 0.697672
  Training set accuracy = 0.832500, Test set accuracy = 0.834500
 epoch 29/200. Took 0.04528 seconds. 
  Full-batch training loss = 0.673853, test loss = 0.688053
  Training set accuracy = 0.833000, Test set accuracy = 0.836600
 epoch 30/200. Took 0.079002 seconds. 
  Full-batch training loss = 0.664249, test loss = 0.678978
  Training set accuracy = 0.836500, Test set accuracy = 0.838000
 epoch 31/200. Took 0.062624 seconds. 
  Full-batch training loss = 0.655222, test loss = 0.670586
  Training set accuracy = 0.837500, Test set accuracy = 0.838600
 epoch 32/200. Took 0.06889 seconds. 
  Full-batch training loss = 0.646771, test loss = 0.662852
  Training set accuracy = 0.840000, Test set accuracy = 0.839600
 epoch 33/200. Took 0.050013 seconds. 
  Full-batch training loss = 0.638562, test loss = 0.654679
  Training set accuracy = 0.844500, Test set accuracy = 0.841000
 epoch 34/200. Took 0.051523 seconds. 
  Full-batch training loss = 0.630718, test loss = 0.647810
  Training set accuracy = 0.843000, Test set accuracy = 0.841400
 epoch 35/200. Took 0.051549 seconds. 
  Full-batch training loss = 0.623342, test loss = 0.640788
  Training set accuracy = 0.845500, Test set accuracy = 0.842600
 epoch 36/200. Took 0.046341 seconds. 
  Full-batch training loss = 0.616224, test loss = 0.634263
  Training set accuracy = 0.848000, Test set accuracy = 0.843100
 epoch 37/200. Took 0.049073 seconds. 
  Full-batch training loss = 0.609482, test loss = 0.627834
  Training set accuracy = 0.849500, Test set accuracy = 0.843900
 epoch 38/200. Took 0.043923 seconds. 
  Full-batch training loss = 0.603076, test loss = 0.621753
  Training set accuracy = 0.851500, Test set accuracy = 0.845300
 epoch 39/200. Took 0.045126 seconds. 
  Full-batch training loss = 0.596832, test loss = 0.616344
  Training set accuracy = 0.855000, Test set accuracy = 0.846800
 epoch 40/200. Took 0.048302 seconds. 
  Full-batch training loss = 0.590901, test loss = 0.610924
  Training set accuracy = 0.854500, Test set accuracy = 0.846500
 epoch 41/200. Took 0.042929 seconds. 
  Full-batch training loss = 0.585293, test loss = 0.606167
  Training set accuracy = 0.855500, Test set accuracy = 0.848100
 epoch 42/200. Took 0.048 seconds. 
  Full-batch training loss = 0.579686, test loss = 0.600823
  Training set accuracy = 0.857000, Test set accuracy = 0.848500
 epoch 43/200. Took 0.048784 seconds. 
  Full-batch training loss = 0.574402, test loss = 0.595862
  Training set accuracy = 0.857500, Test set accuracy = 0.850100
 epoch 44/200. Took 0.046859 seconds. 
  Full-batch training loss = 0.569319, test loss = 0.591342
  Training set accuracy = 0.861500, Test set accuracy = 0.850500
 epoch 45/200. Took 0.046733 seconds. 
  Full-batch training loss = 0.564427, test loss = 0.587509
  Training set accuracy = 0.859500, Test set accuracy = 0.850900
 epoch 46/200. Took 0.043196 seconds. 
  Full-batch training loss = 0.559649, test loss = 0.582860
  Training set accuracy = 0.862500, Test set accuracy = 0.851600
 epoch 47/200. Took 0.043387 seconds. 
  Full-batch training loss = 0.555075, test loss = 0.578630
  Training set accuracy = 0.863500, Test set accuracy = 0.851100
 epoch 48/200. Took 0.047538 seconds. 
  Full-batch training loss = 0.550683, test loss = 0.574769
  Training set accuracy = 0.862500, Test set accuracy = 0.852300
 epoch 49/200. Took 0.051807 seconds. 
  Full-batch training loss = 0.546361, test loss = 0.570992
  Training set accuracy = 0.865000, Test set accuracy = 0.852800
 epoch 50/200. Took 0.047025 seconds. 
  Full-batch training loss = 0.542242, test loss = 0.567767
  Training set accuracy = 0.864500, Test set accuracy = 0.854200
 epoch 51/200. Took 0.048685 seconds. 
  Full-batch training loss = 0.538183, test loss = 0.563970
  Training set accuracy = 0.866000, Test set accuracy = 0.854200
 epoch 52/200. Took 0.048775 seconds. 
  Full-batch training loss = 0.534269, test loss = 0.560590
  Training set accuracy = 0.866500, Test set accuracy = 0.854200
 epoch 53/200. Took 0.048813 seconds. 
  Full-batch training loss = 0.530494, test loss = 0.557210
  Training set accuracy = 0.865500, Test set accuracy = 0.854800
 epoch 54/200. Took 0.054999 seconds. 
  Full-batch training loss = 0.526750, test loss = 0.554134
  Training set accuracy = 0.866500, Test set accuracy = 0.855500
 epoch 55/200. Took 0.052125 seconds. 
  Full-batch training loss = 0.523225, test loss = 0.550876
  Training set accuracy = 0.866500, Test set accuracy = 0.856800
 epoch 56/200. Took 0.055412 seconds. 
  Full-batch training loss = 0.519722, test loss = 0.547947
  Training set accuracy = 0.866500, Test set accuracy = 0.857100
 epoch 57/200. Took 0.089193 seconds. 
  Full-batch training loss = 0.516333, test loss = 0.545418
  Training set accuracy = 0.867500, Test set accuracy = 0.857400
 epoch 58/200. Took 0.048072 seconds. 
  Full-batch training loss = 0.513061, test loss = 0.542589
  Training set accuracy = 0.869500, Test set accuracy = 0.858000
 epoch 59/200. Took 0.048388 seconds. 
  Full-batch training loss = 0.509833, test loss = 0.539818
  Training set accuracy = 0.869500, Test set accuracy = 0.859100
 epoch 60/200. Took 0.045321 seconds. 
  Full-batch training loss = 0.506708, test loss = 0.537083
  Training set accuracy = 0.870000, Test set accuracy = 0.858900
 epoch 61/200. Took 0.04879 seconds. 
  Full-batch training loss = 0.503617, test loss = 0.534771
  Training set accuracy = 0.871500, Test set accuracy = 0.859600
 epoch 62/200. Took 0.048198 seconds. 
  Full-batch training loss = 0.500642, test loss = 0.532284
  Training set accuracy = 0.871500, Test set accuracy = 0.860300
 epoch 63/200. Took 0.046903 seconds. 
  Full-batch training loss = 0.497767, test loss = 0.530025
  Training set accuracy = 0.871500, Test set accuracy = 0.860500
 epoch 64/200. Took 0.04815 seconds. 
  Full-batch training loss = 0.494901, test loss = 0.527469
  Training set accuracy = 0.872500, Test set accuracy = 0.860900
 epoch 65/200. Took 0.050278 seconds. 
  Full-batch training loss = 0.492126, test loss = 0.525045
  Training set accuracy = 0.873000, Test set accuracy = 0.861400
 epoch 66/200. Took 0.044346 seconds. 
  Full-batch training loss = 0.489417, test loss = 0.523054
  Training set accuracy = 0.873500, Test set accuracy = 0.860800
 epoch 67/200. Took 0.043684 seconds. 
  Full-batch training loss = 0.486721, test loss = 0.520703
  Training set accuracy = 0.873500, Test set accuracy = 0.862400
 epoch 68/200. Took 0.047846 seconds. 
  Full-batch training loss = 0.484167, test loss = 0.519047
  Training set accuracy = 0.873500, Test set accuracy = 0.862000
 epoch 69/200. Took 0.049047 seconds. 
  Full-batch training loss = 0.481675, test loss = 0.516773
  Training set accuracy = 0.874500, Test set accuracy = 0.862700
 epoch 70/200. Took 0.047894 seconds. 
  Full-batch training loss = 0.479152, test loss = 0.514858
  Training set accuracy = 0.875000, Test set accuracy = 0.863100
 epoch 71/200. Took 0.05148 seconds. 
  Full-batch training loss = 0.476732, test loss = 0.512981
  Training set accuracy = 0.874500, Test set accuracy = 0.862800
 epoch 72/200. Took 0.044295 seconds. 
  Full-batch training loss = 0.474338, test loss = 0.510944
  Training set accuracy = 0.875000, Test set accuracy = 0.863500
 epoch 73/200. Took 0.048226 seconds. 
  Full-batch training loss = 0.472024, test loss = 0.509244
  Training set accuracy = 0.876000, Test set accuracy = 0.864200
 epoch 74/200. Took 0.043753 seconds. 
  Full-batch training loss = 0.469721, test loss = 0.507457
  Training set accuracy = 0.875500, Test set accuracy = 0.864100
 epoch 75/200. Took 0.043182 seconds. 
  Full-batch training loss = 0.467473, test loss = 0.505840
  Training set accuracy = 0.876500, Test set accuracy = 0.864900
 epoch 76/200. Took 0.043817 seconds. 
  Full-batch training loss = 0.465284, test loss = 0.504087
  Training set accuracy = 0.876000, Test set accuracy = 0.864800
 epoch 77/200. Took 0.046893 seconds. 
  Full-batch training loss = 0.463094, test loss = 0.502163
  Training set accuracy = 0.878000, Test set accuracy = 0.865200
 epoch 78/200. Took 0.046282 seconds. 
  Full-batch training loss = 0.460985, test loss = 0.500668
  Training set accuracy = 0.877500, Test set accuracy = 0.865800
 epoch 79/200. Took 0.048174 seconds. 
  Full-batch training loss = 0.458903, test loss = 0.499154
  Training set accuracy = 0.878000, Test set accuracy = 0.865800
 epoch 80/200. Took 0.045007 seconds. 
  Full-batch training loss = 0.456850, test loss = 0.497491
  Training set accuracy = 0.878500, Test set accuracy = 0.866100
 epoch 81/200. Took 0.050923 seconds. 
  Full-batch training loss = 0.454864, test loss = 0.496024
  Training set accuracy = 0.879000, Test set accuracy = 0.866300
 epoch 82/200. Took 0.052639 seconds. 
  Full-batch training loss = 0.452884, test loss = 0.494629
  Training set accuracy = 0.879000, Test set accuracy = 0.866600
 epoch 83/200. Took 0.045852 seconds. 
  Full-batch training loss = 0.450968, test loss = 0.493180
  Training set accuracy = 0.879500, Test set accuracy = 0.866400
 epoch 84/200. Took 0.043419 seconds. 
  Full-batch training loss = 0.449054, test loss = 0.491627
  Training set accuracy = 0.881000, Test set accuracy = 0.866500
 epoch 85/200. Took 0.042546 seconds. 
  Full-batch training loss = 0.447169, test loss = 0.490280
  Training set accuracy = 0.882500, Test set accuracy = 0.866800
 epoch 86/200. Took 0.053609 seconds. 
  Full-batch training loss = 0.445332, test loss = 0.489121
  Training set accuracy = 0.882500, Test set accuracy = 0.866900
 epoch 87/200. Took 0.048655 seconds. 
  Full-batch training loss = 0.443538, test loss = 0.487683
  Training set accuracy = 0.883000, Test set accuracy = 0.867200
 epoch 88/200. Took 0.043414 seconds. 
  Full-batch training loss = 0.441740, test loss = 0.486450
  Training set accuracy = 0.884000, Test set accuracy = 0.867300
 epoch 89/200. Took 0.045352 seconds. 
  Full-batch training loss = 0.439983, test loss = 0.485204
  Training set accuracy = 0.883000, Test set accuracy = 0.867500
 epoch 90/200. Took 0.043756 seconds. 
  Full-batch training loss = 0.438238, test loss = 0.483935
  Training set accuracy = 0.885000, Test set accuracy = 0.867300
 epoch 91/200. Took 0.045099 seconds. 
  Full-batch training loss = 0.436533, test loss = 0.482625
  Training set accuracy = 0.884500, Test set accuracy = 0.867600
 epoch 92/200. Took 0.042184 seconds. 
  Full-batch training loss = 0.434876, test loss = 0.481520
  Training set accuracy = 0.885000, Test set accuracy = 0.868000
 epoch 93/200. Took 0.046623 seconds. 
  Full-batch training loss = 0.433245, test loss = 0.480321
  Training set accuracy = 0.887000, Test set accuracy = 0.868100
 epoch 94/200. Took 0.048148 seconds. 
  Full-batch training loss = 0.431609, test loss = 0.479309
  Training set accuracy = 0.886500, Test set accuracy = 0.868400
 epoch 95/200. Took 0.05017 seconds. 
  Full-batch training loss = 0.430017, test loss = 0.477984
  Training set accuracy = 0.885500, Test set accuracy = 0.868200
 epoch 96/200. Took 0.046372 seconds. 
  Full-batch training loss = 0.428426, test loss = 0.477068
  Training set accuracy = 0.887000, Test set accuracy = 0.868600
 epoch 97/200. Took 0.046043 seconds. 
  Full-batch training loss = 0.426897, test loss = 0.476008
  Training set accuracy = 0.888500, Test set accuracy = 0.868700
 epoch 98/200. Took 0.047572 seconds. 
  Full-batch training loss = 0.425339, test loss = 0.474854
  Training set accuracy = 0.889000, Test set accuracy = 0.868600
 epoch 99/200. Took 0.051566 seconds. 
  Full-batch training loss = 0.423868, test loss = 0.473872
  Training set accuracy = 0.887500, Test set accuracy = 0.869400
 epoch 100/200. Took 0.048337 seconds. 
  Full-batch training loss = 0.422383, test loss = 0.472769
  Training set accuracy = 0.890500, Test set accuracy = 0.868500
 epoch 101/200. Took 0.045074 seconds. 
  Full-batch training loss = 0.420914, test loss = 0.471979
  Training set accuracy = 0.890500, Test set accuracy = 0.869600
 epoch 102/200. Took 0.049444 seconds. 
  Full-batch training loss = 0.419455, test loss = 0.470868
  Training set accuracy = 0.890500, Test set accuracy = 0.870000
 epoch 103/200. Took 0.043102 seconds. 
  Full-batch training loss = 0.418005, test loss = 0.469817
  Training set accuracy = 0.892000, Test set accuracy = 0.869900
 epoch 104/200. Took 0.047378 seconds. 
  Full-batch training loss = 0.416613, test loss = 0.468912
  Training set accuracy = 0.891500, Test set accuracy = 0.869400
 epoch 105/200. Took 0.044765 seconds. 
  Full-batch training loss = 0.415253, test loss = 0.467909
  Training set accuracy = 0.894000, Test set accuracy = 0.870400
 epoch 106/200. Took 0.047207 seconds. 
  Full-batch training loss = 0.413851, test loss = 0.467031
  Training set accuracy = 0.893000, Test set accuracy = 0.869800
 epoch 107/200. Took 0.045758 seconds. 
  Full-batch training loss = 0.412462, test loss = 0.466206
  Training set accuracy = 0.893500, Test set accuracy = 0.869900
 epoch 108/200. Took 0.050778 seconds. 
  Full-batch training loss = 0.411137, test loss = 0.465370
  Training set accuracy = 0.895500, Test set accuracy = 0.870200
 epoch 109/200. Took 0.044558 seconds. 
  Full-batch training loss = 0.409827, test loss = 0.464683
  Training set accuracy = 0.894500, Test set accuracy = 0.870200
 epoch 110/200. Took 0.043015 seconds. 
  Full-batch training loss = 0.408516, test loss = 0.463594
  Training set accuracy = 0.895000, Test set accuracy = 0.870300
 epoch 111/200. Took 0.047925 seconds. 
  Full-batch training loss = 0.407207, test loss = 0.462951
  Training set accuracy = 0.895000, Test set accuracy = 0.870500
 epoch 112/200. Took 0.047501 seconds. 
  Full-batch training loss = 0.405944, test loss = 0.461930
  Training set accuracy = 0.896500, Test set accuracy = 0.870500
 epoch 113/200. Took 0.048173 seconds. 
  Full-batch training loss = 0.404675, test loss = 0.461306
  Training set accuracy = 0.896500, Test set accuracy = 0.870800
 epoch 114/200. Took 0.048602 seconds. 
  Full-batch training loss = 0.403437, test loss = 0.460262
  Training set accuracy = 0.896000, Test set accuracy = 0.870300
 epoch 115/200. Took 0.04845 seconds. 
  Full-batch training loss = 0.402185, test loss = 0.459670
  Training set accuracy = 0.896500, Test set accuracy = 0.871000
 epoch 116/200. Took 0.048424 seconds. 
  Full-batch training loss = 0.400972, test loss = 0.458966
  Training set accuracy = 0.897000, Test set accuracy = 0.870600
 epoch 117/200. Took 0.046296 seconds. 
  Full-batch training loss = 0.399769, test loss = 0.458235
  Training set accuracy = 0.897500, Test set accuracy = 0.871200
 epoch 118/200. Took 0.048089 seconds. 
  Full-batch training loss = 0.398568, test loss = 0.457453
  Training set accuracy = 0.898000, Test set accuracy = 0.870900
 epoch 119/200. Took 0.049956 seconds. 
  Full-batch training loss = 0.397413, test loss = 0.456681
  Training set accuracy = 0.898000, Test set accuracy = 0.871000
 epoch 120/200. Took 0.050159 seconds. 
  Full-batch training loss = 0.396242, test loss = 0.455933
  Training set accuracy = 0.899000, Test set accuracy = 0.871000
 epoch 121/200. Took 0.050656 seconds. 
  Full-batch training loss = 0.395087, test loss = 0.455213
  Training set accuracy = 0.898500, Test set accuracy = 0.871200
 epoch 122/200. Took 0.049976 seconds. 
  Full-batch training loss = 0.393978, test loss = 0.454683
  Training set accuracy = 0.898000, Test set accuracy = 0.871800
 epoch 123/200. Took 0.051657 seconds. 
  Full-batch training loss = 0.392849, test loss = 0.453864
  Training set accuracy = 0.898500, Test set accuracy = 0.871700
 epoch 124/200. Took 0.048925 seconds. 
  Full-batch training loss = 0.391720, test loss = 0.453175
  Training set accuracy = 0.900000, Test set accuracy = 0.871900
 epoch 125/200. Took 0.048396 seconds. 
  Full-batch training loss = 0.390623, test loss = 0.452680
  Training set accuracy = 0.899000, Test set accuracy = 0.871900
 epoch 126/200. Took 0.051794 seconds. 
  Full-batch training loss = 0.389523, test loss = 0.451998
  Training set accuracy = 0.899500, Test set accuracy = 0.872200
 epoch 127/200. Took 0.049232 seconds. 
  Full-batch training loss = 0.388451, test loss = 0.451332
  Training set accuracy = 0.899500, Test set accuracy = 0.872000
 epoch 128/200. Took 0.046549 seconds. 
  Full-batch training loss = 0.387370, test loss = 0.450675
  Training set accuracy = 0.900000, Test set accuracy = 0.871900
 epoch 129/200. Took 0.044481 seconds. 
  Full-batch training loss = 0.386309, test loss = 0.450086
  Training set accuracy = 0.900500, Test set accuracy = 0.872100
 epoch 130/200. Took 0.045662 seconds. 
  Full-batch training loss = 0.385269, test loss = 0.449341
  Training set accuracy = 0.900500, Test set accuracy = 0.872200
 epoch 131/200. Took 0.046878 seconds. 
  Full-batch training loss = 0.384220, test loss = 0.448942
  Training set accuracy = 0.901500, Test set accuracy = 0.872300
 epoch 132/200. Took 0.047507 seconds. 
  Full-batch training loss = 0.383195, test loss = 0.448154
  Training set accuracy = 0.902000, Test set accuracy = 0.872200
 epoch 133/200. Took 0.04849 seconds. 
  Full-batch training loss = 0.382164, test loss = 0.447574
  Training set accuracy = 0.903000, Test set accuracy = 0.872400
 epoch 134/200. Took 0.043415 seconds. 
  Full-batch training loss = 0.381181, test loss = 0.447092
  Training set accuracy = 0.903500, Test set accuracy = 0.871900
 epoch 135/200. Took 0.043723 seconds. 
  Full-batch training loss = 0.380174, test loss = 0.446581
  Training set accuracy = 0.904000, Test set accuracy = 0.872200
 epoch 136/200. Took 0.042966 seconds. 
  Full-batch training loss = 0.379181, test loss = 0.445915
  Training set accuracy = 0.904500, Test set accuracy = 0.872700
 epoch 137/200. Took 0.042248 seconds. 
  Full-batch training loss = 0.378203, test loss = 0.445356
  Training set accuracy = 0.905000, Test set accuracy = 0.872500
 epoch 138/200. Took 0.046804 seconds. 
  Full-batch training loss = 0.377235, test loss = 0.444756
  Training set accuracy = 0.904500, Test set accuracy = 0.873000
 epoch 139/200. Took 0.046297 seconds. 
  Full-batch training loss = 0.376266, test loss = 0.444210
  Training set accuracy = 0.906000, Test set accuracy = 0.873200
 epoch 140/200. Took 0.045958 seconds. 
  Full-batch training loss = 0.375307, test loss = 0.443804
  Training set accuracy = 0.905500, Test set accuracy = 0.873200
 epoch 141/200. Took 0.044503 seconds. 
  Full-batch training loss = 0.374344, test loss = 0.443067
  Training set accuracy = 0.905500, Test set accuracy = 0.873200
 epoch 142/200. Took 0.051679 seconds. 
  Full-batch training loss = 0.373420, test loss = 0.442727
  Training set accuracy = 0.906500, Test set accuracy = 0.873300
 epoch 143/200. Took 0.044065 seconds. 
  Full-batch training loss = 0.372479, test loss = 0.442201
  Training set accuracy = 0.907000, Test set accuracy = 0.873100
 epoch 144/200. Took 0.065188 seconds. 
  Full-batch training loss = 0.371558, test loss = 0.441658
  Training set accuracy = 0.906500, Test set accuracy = 0.873400
 epoch 145/200. Took 0.051526 seconds. 
  Full-batch training loss = 0.370640, test loss = 0.441177
  Training set accuracy = 0.906500, Test set accuracy = 0.873500
 epoch 146/200. Took 0.051543 seconds. 
  Full-batch training loss = 0.369732, test loss = 0.440610
  Training set accuracy = 0.907000, Test set accuracy = 0.873900
 epoch 147/200. Took 0.05504 seconds. 
  Full-batch training loss = 0.368841, test loss = 0.440219
  Training set accuracy = 0.907500, Test set accuracy = 0.874400
 epoch 148/200. Took 0.04941 seconds. 
  Full-batch training loss = 0.367969, test loss = 0.439846
  Training set accuracy = 0.906500, Test set accuracy = 0.873700
 epoch 149/200. Took 0.049446 seconds. 
  Full-batch training loss = 0.367055, test loss = 0.439218
  Training set accuracy = 0.907000, Test set accuracy = 0.873700
 epoch 150/200. Took 0.051962 seconds. 
  Full-batch training loss = 0.366165, test loss = 0.438750
  Training set accuracy = 0.908500, Test set accuracy = 0.874000
 epoch 151/200. Took 0.076856 seconds. 
  Full-batch training loss = 0.365312, test loss = 0.438159
  Training set accuracy = 0.908000, Test set accuracy = 0.874100
 epoch 152/200. Took 0.051539 seconds. 
  Full-batch training loss = 0.364450, test loss = 0.437866
  Training set accuracy = 0.908000, Test set accuracy = 0.873900
 epoch 153/200. Took 0.049595 seconds. 
  Full-batch training loss = 0.363579, test loss = 0.437594
  Training set accuracy = 0.908500, Test set accuracy = 0.873900
 epoch 154/200. Took 0.043724 seconds. 
  Full-batch training loss = 0.362733, test loss = 0.437119
  Training set accuracy = 0.908500, Test set accuracy = 0.873800
 epoch 155/200. Took 0.049647 seconds. 
  Full-batch training loss = 0.361890, test loss = 0.436614
  Training set accuracy = 0.908500, Test set accuracy = 0.874500
 epoch 156/200. Took 0.046353 seconds. 
  Full-batch training loss = 0.361051, test loss = 0.436107
  Training set accuracy = 0.908500, Test set accuracy = 0.874900
 epoch 157/200. Took 0.04828 seconds. 
  Full-batch training loss = 0.360226, test loss = 0.435715
  Training set accuracy = 0.908500, Test set accuracy = 0.874500
 epoch 158/200. Took 0.04944 seconds. 
  Full-batch training loss = 0.359404, test loss = 0.435259
  Training set accuracy = 0.909000, Test set accuracy = 0.875300
 epoch 159/200. Took 0.04781 seconds. 
  Full-batch training loss = 0.358584, test loss = 0.434848
  Training set accuracy = 0.909000, Test set accuracy = 0.875500
 epoch 160/200. Took 0.045898 seconds. 
  Full-batch training loss = 0.357788, test loss = 0.434691
  Training set accuracy = 0.909000, Test set accuracy = 0.874700
 epoch 161/200. Took 0.045189 seconds. 
  Full-batch training loss = 0.356955, test loss = 0.434124
  Training set accuracy = 0.908500, Test set accuracy = 0.875500
 epoch 162/200. Took 0.051475 seconds. 
  Full-batch training loss = 0.356175, test loss = 0.433621
  Training set accuracy = 0.909000, Test set accuracy = 0.875300
 epoch 163/200. Took 0.049756 seconds. 
  Full-batch training loss = 0.355377, test loss = 0.433285
  Training set accuracy = 0.909000, Test set accuracy = 0.875600
 epoch 164/200. Took 0.048847 seconds. 
  Full-batch training loss = 0.354596, test loss = 0.432837
  Training set accuracy = 0.909500, Test set accuracy = 0.875600
 epoch 165/200. Took 0.050606 seconds. 
  Full-batch training loss = 0.353804, test loss = 0.432447
  Training set accuracy = 0.909000, Test set accuracy = 0.875900
 epoch 166/200. Took 0.049049 seconds. 
  Full-batch training loss = 0.353021, test loss = 0.432211
  Training set accuracy = 0.909500, Test set accuracy = 0.875800
 epoch 167/200. Took 0.04903 seconds. 
  Full-batch training loss = 0.352262, test loss = 0.431698
  Training set accuracy = 0.909500, Test set accuracy = 0.876300
 epoch 168/200. Took 0.048807 seconds. 
  Full-batch training loss = 0.351503, test loss = 0.431408
  Training set accuracy = 0.909500, Test set accuracy = 0.876000
 epoch 169/200. Took 0.052863 seconds. 
  Full-batch training loss = 0.350744, test loss = 0.430947
  Training set accuracy = 0.910500, Test set accuracy = 0.876400
 epoch 170/200. Took 0.05432 seconds. 
  Full-batch training loss = 0.349980, test loss = 0.430658
  Training set accuracy = 0.910000, Test set accuracy = 0.876400
 epoch 171/200. Took 0.050353 seconds. 
  Full-batch training loss = 0.349258, test loss = 0.430139
  Training set accuracy = 0.910500, Test set accuracy = 0.876400
 epoch 172/200. Took 0.049627 seconds. 
  Full-batch training loss = 0.348506, test loss = 0.429862
  Training set accuracy = 0.909500, Test set accuracy = 0.876500
 epoch 173/200. Took 0.047851 seconds. 
  Full-batch training loss = 0.347762, test loss = 0.429667
  Training set accuracy = 0.910000, Test set accuracy = 0.876500
 epoch 174/200. Took 0.046837 seconds. 
  Full-batch training loss = 0.347031, test loss = 0.429421
  Training set accuracy = 0.910000, Test set accuracy = 0.876100
 epoch 175/200. Took 0.048686 seconds. 
  Full-batch training loss = 0.346302, test loss = 0.428942
  Training set accuracy = 0.909500, Test set accuracy = 0.876200
 epoch 176/200. Took 0.050019 seconds. 
  Full-batch training loss = 0.345589, test loss = 0.428460
  Training set accuracy = 0.910000, Test set accuracy = 0.876600
 epoch 177/200. Took 0.057105 seconds. 
  Full-batch training loss = 0.344870, test loss = 0.428352
  Training set accuracy = 0.909500, Test set accuracy = 0.876500
 epoch 178/200. Took 0.047784 seconds. 
  Full-batch training loss = 0.344156, test loss = 0.427941
  Training set accuracy = 0.910000, Test set accuracy = 0.876400
 epoch 179/200. Took 0.05034 seconds. 
  Full-batch training loss = 0.343456, test loss = 0.427447
  Training set accuracy = 0.910500, Test set accuracy = 0.876900
 epoch 180/200. Took 0.046416 seconds. 
  Full-batch training loss = 0.342739, test loss = 0.427243
  Training set accuracy = 0.910000, Test set accuracy = 0.876500
 epoch 181/200. Took 0.053251 seconds. 
  Full-batch training loss = 0.342058, test loss = 0.426926
  Training set accuracy = 0.910500, Test set accuracy = 0.876300
 epoch 182/200. Took 0.05171 seconds. 
  Full-batch training loss = 0.341363, test loss = 0.426791
  Training set accuracy = 0.910000, Test set accuracy = 0.876300
 epoch 183/200. Took 0.050091 seconds. 
  Full-batch training loss = 0.340664, test loss = 0.426311
  Training set accuracy = 0.911500, Test set accuracy = 0.876400
 epoch 184/200. Took 0.048172 seconds. 
  Full-batch training loss = 0.339980, test loss = 0.425995
  Training set accuracy = 0.911000, Test set accuracy = 0.876300
 epoch 185/200. Took 0.051899 seconds. 
  Full-batch training loss = 0.339303, test loss = 0.425682
  Training set accuracy = 0.910500, Test set accuracy = 0.876400
 epoch 186/200. Took 0.045075 seconds. 
  Full-batch training loss = 0.338610, test loss = 0.425405
  Training set accuracy = 0.911500, Test set accuracy = 0.876500
 epoch 187/200. Took 0.049504 seconds. 
  Full-batch training loss = 0.337948, test loss = 0.425090
  Training set accuracy = 0.911500, Test set accuracy = 0.876500
 epoch 188/200. Took 0.047637 seconds. 
  Full-batch training loss = 0.337273, test loss = 0.424730
  Training set accuracy = 0.912500, Test set accuracy = 0.876100
 epoch 189/200. Took 0.053924 seconds. 
  Full-batch training loss = 0.336618, test loss = 0.424550
  Training set accuracy = 0.913500, Test set accuracy = 0.876300
 epoch 190/200. Took 0.049088 seconds. 
  Full-batch training loss = 0.335958, test loss = 0.424215
  Training set accuracy = 0.912500, Test set accuracy = 0.876800
 epoch 191/200. Took 0.045563 seconds. 
  Full-batch training loss = 0.335318, test loss = 0.423843
  Training set accuracy = 0.912500, Test set accuracy = 0.876500
 epoch 192/200. Took 0.047726 seconds. 
  Full-batch training loss = 0.334643, test loss = 0.423814
  Training set accuracy = 0.912500, Test set accuracy = 0.876500
 epoch 193/200. Took 0.049052 seconds. 
  Full-batch training loss = 0.333993, test loss = 0.423315
  Training set accuracy = 0.913000, Test set accuracy = 0.876600
 epoch 194/200. Took 0.052328 seconds. 
  Full-batch training loss = 0.333339, test loss = 0.423202
  Training set accuracy = 0.913000, Test set accuracy = 0.876900
 epoch 195/200. Took 0.04851 seconds. 
  Full-batch training loss = 0.332694, test loss = 0.422765
  Training set accuracy = 0.912500, Test set accuracy = 0.876600
 epoch 196/200. Took 0.050261 seconds. 
  Full-batch training loss = 0.332075, test loss = 0.422486
  Training set accuracy = 0.913500, Test set accuracy = 0.876700
 epoch 197/200. Took 0.044139 seconds. 
  Full-batch training loss = 0.331430, test loss = 0.422199
  Training set accuracy = 0.913500, Test set accuracy = 0.876600
 epoch 198/200. Took 0.047254 seconds. 
  Full-batch training loss = 0.330786, test loss = 0.421969
  Training set accuracy = 0.913000, Test set accuracy = 0.876400
 epoch 199/200. Took 0.053169 seconds. 
  Full-batch training loss = 0.330162, test loss = 0.421743
  Training set accuracy = 0.914000, Test set accuracy = 0.876600
 epoch 200/200. Took 0.048055 seconds. 
  Full-batch training loss = 0.329530, test loss = 0.421625
  Training set accuracy = 0.913500, Test set accuracy = 0.876600
Elapsed time is 54.222919 seconds.
End Training

learningRateRBM =

    0.0100

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 20 epochs (batchsize: 100)
 epoch 1/20. Took 0.077655 seconds. Average reconstruction error is: 106.8607
 epoch 2/20. Took 0.087109 seconds. Average reconstruction error is: 60.9228
 epoch 3/20. Took 0.08073 seconds. Average reconstruction error is: 54.793
 epoch 4/20. Took 0.078742 seconds. Average reconstruction error is: 49.8286
 epoch 5/20. Took 0.087019 seconds. Average reconstruction error is: 45.8282
 epoch 6/20. Took 0.085388 seconds. Average reconstruction error is: 42.7863
 epoch 7/20. Took 0.083754 seconds. Average reconstruction error is: 40.7493
 epoch 8/20. Took 0.087219 seconds. Average reconstruction error is: 39.2286
 epoch 9/20. Took 0.089244 seconds. Average reconstruction error is: 38.0442
 epoch 10/20. Took 0.087434 seconds. Average reconstruction error is: 37.0522
 epoch 11/20. Took 0.080342 seconds. Average reconstruction error is: 36.1542
 epoch 12/20. Took 0.081125 seconds. Average reconstruction error is: 35.357
 epoch 13/20. Took 0.086195 seconds. Average reconstruction error is: 34.6602
 epoch 14/20. Took 0.081299 seconds. Average reconstruction error is: 33.9974
 epoch 15/20. Took 0.085937 seconds. Average reconstruction error is: 33.4716
 epoch 16/20. Took 0.089264 seconds. Average reconstruction error is: 32.9506
 epoch 17/20. Took 0.087943 seconds. Average reconstruction error is: 32.4761
 epoch 18/20. Took 0.084769 seconds. Average reconstruction error is: 32.0849
 epoch 19/20. Took 0.086783 seconds. Average reconstruction error is: 31.6921
 epoch 20/20. Took 0.081877 seconds. Average reconstruction error is: 31.2878
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.04625 seconds. 
  Full-batch training loss = 2.099553, test loss = 2.130143
  Training set accuracy = 0.329000, Test set accuracy = 0.306100
 epoch 2/200. Took 0.04825 seconds. 
  Full-batch training loss = 1.811564, test loss = 1.848845
  Training set accuracy = 0.489000, Test set accuracy = 0.459100
 epoch 3/200. Took 0.047318 seconds. 
  Full-batch training loss = 1.597530, test loss = 1.640669
  Training set accuracy = 0.582500, Test set accuracy = 0.554100
 epoch 4/200. Took 0.050203 seconds. 
  Full-batch training loss = 1.435426, test loss = 1.482164
  Training set accuracy = 0.648500, Test set accuracy = 0.610200
 epoch 5/200. Took 0.047183 seconds. 
  Full-batch training loss = 1.311453, test loss = 1.361209
  Training set accuracy = 0.685500, Test set accuracy = 0.645600
 epoch 6/200. Took 0.045908 seconds. 
  Full-batch training loss = 1.214247, test loss = 1.264980
  Training set accuracy = 0.713000, Test set accuracy = 0.678100
 epoch 7/200. Took 0.048021 seconds. 
  Full-batch training loss = 1.136926, test loss = 1.189740
  Training set accuracy = 0.725500, Test set accuracy = 0.697000
 epoch 8/200. Took 0.049001 seconds. 
  Full-batch training loss = 1.074289, test loss = 1.128056
  Training set accuracy = 0.741500, Test set accuracy = 0.710600
 epoch 9/200. Took 0.049482 seconds. 
  Full-batch training loss = 1.022363, test loss = 1.077332
  Training set accuracy = 0.755500, Test set accuracy = 0.724100
 epoch 10/200. Took 0.051566 seconds. 
  Full-batch training loss = 0.978927, test loss = 1.034847
  Training set accuracy = 0.761500, Test set accuracy = 0.730400
 epoch 11/200. Took 0.054362 seconds. 
  Full-batch training loss = 0.942053, test loss = 0.998625
  Training set accuracy = 0.768500, Test set accuracy = 0.740000
 epoch 12/200. Took 0.053209 seconds. 
  Full-batch training loss = 0.910006, test loss = 0.967165
  Training set accuracy = 0.775500, Test set accuracy = 0.745500
 epoch 13/200. Took 0.044669 seconds. 
  Full-batch training loss = 0.882576, test loss = 0.940041
  Training set accuracy = 0.778500, Test set accuracy = 0.751900
 epoch 14/200. Took 0.048632 seconds. 
  Full-batch training loss = 0.857844, test loss = 0.916019
  Training set accuracy = 0.781000, Test set accuracy = 0.755200
 epoch 15/200. Took 0.051972 seconds. 
  Full-batch training loss = 0.836453, test loss = 0.895948
  Training set accuracy = 0.785500, Test set accuracy = 0.757800
 epoch 16/200. Took 0.045402 seconds. 
  Full-batch training loss = 0.816617, test loss = 0.876020
  Training set accuracy = 0.784500, Test set accuracy = 0.762600
 epoch 17/200. Took 0.047615 seconds. 
  Full-batch training loss = 0.799382, test loss = 0.859731
  Training set accuracy = 0.786000, Test set accuracy = 0.765300
 epoch 18/200. Took 0.053127 seconds. 
  Full-batch training loss = 0.783344, test loss = 0.844229
  Training set accuracy = 0.788500, Test set accuracy = 0.768500
 epoch 19/200. Took 0.056165 seconds. 
  Full-batch training loss = 0.768773, test loss = 0.829890
  Training set accuracy = 0.790500, Test set accuracy = 0.770500
 epoch 20/200. Took 0.04567 seconds. 
  Full-batch training loss = 0.755284, test loss = 0.816407
  Training set accuracy = 0.793000, Test set accuracy = 0.774200
 epoch 21/200. Took 0.043946 seconds. 
  Full-batch training loss = 0.742843, test loss = 0.804900
  Training set accuracy = 0.795000, Test set accuracy = 0.773200
 epoch 22/200. Took 0.04079 seconds. 
  Full-batch training loss = 0.731407, test loss = 0.793930
  Training set accuracy = 0.796000, Test set accuracy = 0.777300
 epoch 23/200. Took 0.051907 seconds. 
  Full-batch training loss = 0.720657, test loss = 0.782984
  Training set accuracy = 0.797500, Test set accuracy = 0.780200
 epoch 24/200. Took 0.049735 seconds. 
  Full-batch training loss = 0.710558, test loss = 0.773567
  Training set accuracy = 0.798500, Test set accuracy = 0.780400
 epoch 25/200. Took 0.047811 seconds. 
  Full-batch training loss = 0.701138, test loss = 0.764370
  Training set accuracy = 0.800500, Test set accuracy = 0.780000
 epoch 26/200. Took 0.047341 seconds. 
  Full-batch training loss = 0.692343, test loss = 0.756280
  Training set accuracy = 0.798500, Test set accuracy = 0.782900
 epoch 27/200. Took 0.049002 seconds. 
  Full-batch training loss = 0.683868, test loss = 0.747880
  Training set accuracy = 0.803000, Test set accuracy = 0.783800
 epoch 28/200. Took 0.047938 seconds. 
  Full-batch training loss = 0.675908, test loss = 0.739915
  Training set accuracy = 0.807000, Test set accuracy = 0.786600
 epoch 29/200. Took 0.051295 seconds. 
  Full-batch training loss = 0.668350, test loss = 0.733667
  Training set accuracy = 0.805500, Test set accuracy = 0.786600
 epoch 30/200. Took 0.042603 seconds. 
  Full-batch training loss = 0.661106, test loss = 0.726590
  Training set accuracy = 0.803000, Test set accuracy = 0.787400
 epoch 31/200. Took 0.045722 seconds. 
  Full-batch training loss = 0.654107, test loss = 0.719357
  Training set accuracy = 0.806500, Test set accuracy = 0.789000
 epoch 32/200. Took 0.04695 seconds. 
  Full-batch training loss = 0.647679, test loss = 0.713268
  Training set accuracy = 0.809500, Test set accuracy = 0.790600
 epoch 33/200. Took 0.047675 seconds. 
  Full-batch training loss = 0.641329, test loss = 0.707375
  Training set accuracy = 0.808000, Test set accuracy = 0.791200
 epoch 34/200. Took 0.049932 seconds. 
  Full-batch training loss = 0.635220, test loss = 0.701721
  Training set accuracy = 0.810500, Test set accuracy = 0.793000
 epoch 35/200. Took 0.050096 seconds. 
  Full-batch training loss = 0.629406, test loss = 0.696448
  Training set accuracy = 0.812500, Test set accuracy = 0.793600
 epoch 36/200. Took 0.048707 seconds. 
  Full-batch training loss = 0.623890, test loss = 0.691374
  Training set accuracy = 0.812000, Test set accuracy = 0.795000
 epoch 37/200. Took 0.049361 seconds. 
  Full-batch training loss = 0.618486, test loss = 0.686210
  Training set accuracy = 0.813500, Test set accuracy = 0.795600
 epoch 38/200. Took 0.052789 seconds. 
  Full-batch training loss = 0.613236, test loss = 0.680985
  Training set accuracy = 0.817500, Test set accuracy = 0.797700
 epoch 39/200. Took 0.050514 seconds. 
  Full-batch training loss = 0.608164, test loss = 0.676413
  Training set accuracy = 0.819000, Test set accuracy = 0.798700
 epoch 40/200. Took 0.04933 seconds. 
  Full-batch training loss = 0.603334, test loss = 0.671841
  Training set accuracy = 0.818000, Test set accuracy = 0.800100
 epoch 41/200. Took 0.047732 seconds. 
  Full-batch training loss = 0.598522, test loss = 0.667843
  Training set accuracy = 0.820500, Test set accuracy = 0.800100
 epoch 42/200. Took 0.050543 seconds. 
  Full-batch training loss = 0.594008, test loss = 0.663729
  Training set accuracy = 0.821500, Test set accuracy = 0.801700
 epoch 43/200. Took 0.044839 seconds. 
  Full-batch training loss = 0.589459, test loss = 0.659052
  Training set accuracy = 0.822000, Test set accuracy = 0.803100
 epoch 44/200. Took 0.042049 seconds. 
  Full-batch training loss = 0.585093, test loss = 0.654838
  Training set accuracy = 0.824500, Test set accuracy = 0.804500
 epoch 45/200. Took 0.043226 seconds. 
  Full-batch training loss = 0.580981, test loss = 0.651571
  Training set accuracy = 0.827500, Test set accuracy = 0.804800
 epoch 46/200. Took 0.047135 seconds. 
  Full-batch training loss = 0.576771, test loss = 0.647541
  Training set accuracy = 0.825500, Test set accuracy = 0.806500
 epoch 47/200. Took 0.045249 seconds. 
  Full-batch training loss = 0.572850, test loss = 0.644100
  Training set accuracy = 0.829000, Test set accuracy = 0.806600
 epoch 48/200. Took 0.04567 seconds. 
  Full-batch training loss = 0.568876, test loss = 0.639603
  Training set accuracy = 0.830000, Test set accuracy = 0.809500
 epoch 49/200. Took 0.053604 seconds. 
  Full-batch training loss = 0.565063, test loss = 0.636868
  Training set accuracy = 0.831500, Test set accuracy = 0.809800
 epoch 50/200. Took 0.046368 seconds. 
  Full-batch training loss = 0.561303, test loss = 0.633219
  Training set accuracy = 0.830000, Test set accuracy = 0.811000
 epoch 51/200. Took 0.049003 seconds. 
  Full-batch training loss = 0.557607, test loss = 0.630040
  Training set accuracy = 0.833500, Test set accuracy = 0.812400
 epoch 52/200. Took 0.047448 seconds. 
  Full-batch training loss = 0.554043, test loss = 0.626578
  Training set accuracy = 0.832000, Test set accuracy = 0.813100
 epoch 53/200. Took 0.063442 seconds. 
  Full-batch training loss = 0.550538, test loss = 0.623761
  Training set accuracy = 0.834500, Test set accuracy = 0.814000
 epoch 54/200. Took 0.060472 seconds. 
  Full-batch training loss = 0.547100, test loss = 0.620655
  Training set accuracy = 0.835000, Test set accuracy = 0.814300
 epoch 55/200. Took 0.066 seconds. 
  Full-batch training loss = 0.543781, test loss = 0.617548
  Training set accuracy = 0.838500, Test set accuracy = 0.815500
 epoch 56/200. Took 0.051545 seconds. 
  Full-batch training loss = 0.540482, test loss = 0.614690
  Training set accuracy = 0.838500, Test set accuracy = 0.816200
 epoch 57/200. Took 0.047823 seconds. 
  Full-batch training loss = 0.537220, test loss = 0.611725
  Training set accuracy = 0.841000, Test set accuracy = 0.817300
 epoch 58/200. Took 0.047767 seconds. 
  Full-batch training loss = 0.534046, test loss = 0.608523
  Training set accuracy = 0.840500, Test set accuracy = 0.818300
 epoch 59/200. Took 0.048462 seconds. 
  Full-batch training loss = 0.530918, test loss = 0.606358
  Training set accuracy = 0.843000, Test set accuracy = 0.818800
 epoch 60/200. Took 0.046986 seconds. 
  Full-batch training loss = 0.527875, test loss = 0.603790
  Training set accuracy = 0.844500, Test set accuracy = 0.818600
 epoch 61/200. Took 0.049849 seconds. 
  Full-batch training loss = 0.524919, test loss = 0.600422
  Training set accuracy = 0.843000, Test set accuracy = 0.819800
 epoch 62/200. Took 0.050498 seconds. 
  Full-batch training loss = 0.521880, test loss = 0.597990
  Training set accuracy = 0.846500, Test set accuracy = 0.820300
 epoch 63/200. Took 0.04682 seconds. 
  Full-batch training loss = 0.519038, test loss = 0.596343
  Training set accuracy = 0.845500, Test set accuracy = 0.819200
 epoch 64/200. Took 0.042511 seconds. 
  Full-batch training loss = 0.516174, test loss = 0.593153
  Training set accuracy = 0.846500, Test set accuracy = 0.821300
 epoch 65/200. Took 0.046859 seconds. 
  Full-batch training loss = 0.513273, test loss = 0.590220
  Training set accuracy = 0.849000, Test set accuracy = 0.822600
 epoch 66/200. Took 0.054348 seconds. 
  Full-batch training loss = 0.510504, test loss = 0.588343
  Training set accuracy = 0.849500, Test set accuracy = 0.822800
 epoch 67/200. Took 0.058267 seconds. 
  Full-batch training loss = 0.507771, test loss = 0.585872
  Training set accuracy = 0.849500, Test set accuracy = 0.823400
 epoch 68/200. Took 0.04832 seconds. 
  Full-batch training loss = 0.505034, test loss = 0.583390
  Training set accuracy = 0.853500, Test set accuracy = 0.824800
 epoch 69/200. Took 0.042462 seconds. 
  Full-batch training loss = 0.502380, test loss = 0.581316
  Training set accuracy = 0.853000, Test set accuracy = 0.825300
 epoch 70/200. Took 0.043831 seconds. 
  Full-batch training loss = 0.499747, test loss = 0.579220
  Training set accuracy = 0.854500, Test set accuracy = 0.825800
 epoch 71/200. Took 0.048247 seconds. 
  Full-batch training loss = 0.497167, test loss = 0.576529
  Training set accuracy = 0.855000, Test set accuracy = 0.826900
 epoch 72/200. Took 0.04968 seconds. 
  Full-batch training loss = 0.494637, test loss = 0.574719
  Training set accuracy = 0.856000, Test set accuracy = 0.826700
 epoch 73/200. Took 0.047975 seconds. 
  Full-batch training loss = 0.492105, test loss = 0.572201
  Training set accuracy = 0.856000, Test set accuracy = 0.828000
 epoch 74/200. Took 0.049133 seconds. 
  Full-batch training loss = 0.489629, test loss = 0.570248
  Training set accuracy = 0.856500, Test set accuracy = 0.828000
 epoch 75/200. Took 0.049012 seconds. 
  Full-batch training loss = 0.487160, test loss = 0.567743
  Training set accuracy = 0.857500, Test set accuracy = 0.828300
 epoch 76/200. Took 0.04653 seconds. 
  Full-batch training loss = 0.484696, test loss = 0.565773
  Training set accuracy = 0.859500, Test set accuracy = 0.828900
 epoch 77/200. Took 0.052543 seconds. 
  Full-batch training loss = 0.482355, test loss = 0.564143
  Training set accuracy = 0.860500, Test set accuracy = 0.829000
 epoch 78/200. Took 0.04694 seconds. 
  Full-batch training loss = 0.479964, test loss = 0.561943
  Training set accuracy = 0.859500, Test set accuracy = 0.830600
 epoch 79/200. Took 0.044835 seconds. 
  Full-batch training loss = 0.477641, test loss = 0.560281
  Training set accuracy = 0.860500, Test set accuracy = 0.831300
 epoch 80/200. Took 0.047099 seconds. 
  Full-batch training loss = 0.475331, test loss = 0.557618
  Training set accuracy = 0.860000, Test set accuracy = 0.832200
 epoch 81/200. Took 0.047283 seconds. 
  Full-batch training loss = 0.472996, test loss = 0.555856
  Training set accuracy = 0.861000, Test set accuracy = 0.832000
 epoch 82/200. Took 0.048819 seconds. 
  Full-batch training loss = 0.470735, test loss = 0.554469
  Training set accuracy = 0.861500, Test set accuracy = 0.832900
 epoch 83/200. Took 0.047671 seconds. 
  Full-batch training loss = 0.468460, test loss = 0.552121
  Training set accuracy = 0.862500, Test set accuracy = 0.833700
 epoch 84/200. Took 0.051369 seconds. 
  Full-batch training loss = 0.466265, test loss = 0.550766
  Training set accuracy = 0.862500, Test set accuracy = 0.834100
 epoch 85/200. Took 0.047591 seconds. 
  Full-batch training loss = 0.464139, test loss = 0.548982
  Training set accuracy = 0.863500, Test set accuracy = 0.834500
 epoch 86/200. Took 0.047673 seconds. 
  Full-batch training loss = 0.461926, test loss = 0.547107
  Training set accuracy = 0.865500, Test set accuracy = 0.834400
 epoch 87/200. Took 0.053228 seconds. 
  Full-batch training loss = 0.459719, test loss = 0.544881
  Training set accuracy = 0.865000, Test set accuracy = 0.835600
 epoch 88/200. Took 0.042909 seconds. 
  Full-batch training loss = 0.457641, test loss = 0.542908
  Training set accuracy = 0.866000, Test set accuracy = 0.836500
 epoch 89/200. Took 0.045689 seconds. 
  Full-batch training loss = 0.455520, test loss = 0.541684
  Training set accuracy = 0.865500, Test set accuracy = 0.836400
 epoch 90/200. Took 0.054301 seconds. 
  Full-batch training loss = 0.453418, test loss = 0.539800
  Training set accuracy = 0.866500, Test set accuracy = 0.837200
 epoch 91/200. Took 0.04315 seconds. 
  Full-batch training loss = 0.451369, test loss = 0.538450
  Training set accuracy = 0.867000, Test set accuracy = 0.836500
 epoch 92/200. Took 0.043677 seconds. 
  Full-batch training loss = 0.449281, test loss = 0.536186
  Training set accuracy = 0.869500, Test set accuracy = 0.837900
 epoch 93/200. Took 0.052055 seconds. 
  Full-batch training loss = 0.447318, test loss = 0.534671
  Training set accuracy = 0.869500, Test set accuracy = 0.838500
 epoch 94/200. Took 0.047751 seconds. 
  Full-batch training loss = 0.445243, test loss = 0.532840
  Training set accuracy = 0.871000, Test set accuracy = 0.840100
 epoch 95/200. Took 0.075533 seconds. 
  Full-batch training loss = 0.443267, test loss = 0.531559
  Training set accuracy = 0.871000, Test set accuracy = 0.839600
 epoch 96/200. Took 0.060673 seconds. 
  Full-batch training loss = 0.441293, test loss = 0.529809
  Training set accuracy = 0.871000, Test set accuracy = 0.840800
 epoch 97/200. Took 0.050469 seconds. 
  Full-batch training loss = 0.439351, test loss = 0.528349
  Training set accuracy = 0.871500, Test set accuracy = 0.840300
 epoch 98/200. Took 0.053547 seconds. 
  Full-batch training loss = 0.437420, test loss = 0.526461
  Training set accuracy = 0.873000, Test set accuracy = 0.841700
 epoch 99/200. Took 0.047294 seconds. 
  Full-batch training loss = 0.435516, test loss = 0.525085
  Training set accuracy = 0.873500, Test set accuracy = 0.841700
 epoch 100/200. Took 0.048506 seconds. 
  Full-batch training loss = 0.433549, test loss = 0.523537
  Training set accuracy = 0.872500, Test set accuracy = 0.842300
 epoch 101/200. Took 0.048846 seconds. 
  Full-batch training loss = 0.431681, test loss = 0.522060
  Training set accuracy = 0.875000, Test set accuracy = 0.842600
 epoch 102/200. Took 0.049555 seconds. 
  Full-batch training loss = 0.429829, test loss = 0.520808
  Training set accuracy = 0.875500, Test set accuracy = 0.842700
 epoch 103/200. Took 0.047199 seconds. 
  Full-batch training loss = 0.427959, test loss = 0.518877
  Training set accuracy = 0.876000, Test set accuracy = 0.843100
 epoch 104/200. Took 0.046363 seconds. 
  Full-batch training loss = 0.426175, test loss = 0.517997
  Training set accuracy = 0.876500, Test set accuracy = 0.843700
 epoch 105/200. Took 0.048704 seconds. 
  Full-batch training loss = 0.424267, test loss = 0.516087
  Training set accuracy = 0.879500, Test set accuracy = 0.844500
 epoch 106/200. Took 0.046062 seconds. 
  Full-batch training loss = 0.422455, test loss = 0.514507
  Training set accuracy = 0.880000, Test set accuracy = 0.844900
 epoch 107/200. Took 0.048793 seconds. 
  Full-batch training loss = 0.420650, test loss = 0.513182
  Training set accuracy = 0.880000, Test set accuracy = 0.845300
 epoch 108/200. Took 0.046987 seconds. 
  Full-batch training loss = 0.418878, test loss = 0.511623
  Training set accuracy = 0.881500, Test set accuracy = 0.846700
 epoch 109/200. Took 0.050626 seconds. 
  Full-batch training loss = 0.417141, test loss = 0.510673
  Training set accuracy = 0.880000, Test set accuracy = 0.846100
 epoch 110/200. Took 0.049272 seconds. 
  Full-batch training loss = 0.415341, test loss = 0.508682
  Training set accuracy = 0.882500, Test set accuracy = 0.847700
 epoch 111/200. Took 0.047232 seconds. 
  Full-batch training loss = 0.413584, test loss = 0.507436
  Training set accuracy = 0.882500, Test set accuracy = 0.847600
 epoch 112/200. Took 0.04433 seconds. 
  Full-batch training loss = 0.411880, test loss = 0.505830
  Training set accuracy = 0.883500, Test set accuracy = 0.848700
 epoch 113/200. Took 0.047844 seconds. 
  Full-batch training loss = 0.410142, test loss = 0.504623
  Training set accuracy = 0.885000, Test set accuracy = 0.849100
 epoch 114/200. Took 0.04758 seconds. 
  Full-batch training loss = 0.408455, test loss = 0.503322
  Training set accuracy = 0.884500, Test set accuracy = 0.849000
 epoch 115/200. Took 0.047947 seconds. 
  Full-batch training loss = 0.406748, test loss = 0.502301
  Training set accuracy = 0.886000, Test set accuracy = 0.849600
 epoch 116/200. Took 0.048727 seconds. 
  Full-batch training loss = 0.405089, test loss = 0.501094
  Training set accuracy = 0.885000, Test set accuracy = 0.849600
 epoch 117/200. Took 0.047894 seconds. 
  Full-batch training loss = 0.403394, test loss = 0.499600
  Training set accuracy = 0.888000, Test set accuracy = 0.850300
 epoch 118/200. Took 0.047936 seconds. 
  Full-batch training loss = 0.401743, test loss = 0.498264
  Training set accuracy = 0.887500, Test set accuracy = 0.850600
 epoch 119/200. Took 0.048547 seconds. 
  Full-batch training loss = 0.400150, test loss = 0.497219
  Training set accuracy = 0.889000, Test set accuracy = 0.851700
 epoch 120/200. Took 0.047885 seconds. 
  Full-batch training loss = 0.398468, test loss = 0.495665
  Training set accuracy = 0.888500, Test set accuracy = 0.851900
 epoch 121/200. Took 0.050019 seconds. 
  Full-batch training loss = 0.396887, test loss = 0.494801
  Training set accuracy = 0.888000, Test set accuracy = 0.852400
 epoch 122/200. Took 0.049499 seconds. 
  Full-batch training loss = 0.395248, test loss = 0.493489
  Training set accuracy = 0.890500, Test set accuracy = 0.852800
 epoch 123/200. Took 0.048443 seconds. 
  Full-batch training loss = 0.393629, test loss = 0.492052
  Training set accuracy = 0.891500, Test set accuracy = 0.853500
 epoch 124/200. Took 0.046602 seconds. 
  Full-batch training loss = 0.392072, test loss = 0.490730
  Training set accuracy = 0.890500, Test set accuracy = 0.853600
 epoch 125/200. Took 0.045011 seconds. 
  Full-batch training loss = 0.390479, test loss = 0.489462
  Training set accuracy = 0.892000, Test set accuracy = 0.853400
 epoch 126/200. Took 0.057786 seconds. 
  Full-batch training loss = 0.388888, test loss = 0.488385
  Training set accuracy = 0.893000, Test set accuracy = 0.854400
 epoch 127/200. Took 0.046662 seconds. 
  Full-batch training loss = 0.387381, test loss = 0.486896
  Training set accuracy = 0.893000, Test set accuracy = 0.854400
 epoch 128/200. Took 0.04814 seconds. 
  Full-batch training loss = 0.385801, test loss = 0.485985
  Training set accuracy = 0.893500, Test set accuracy = 0.855000
 epoch 129/200. Took 0.057954 seconds. 
  Full-batch training loss = 0.384277, test loss = 0.485163
  Training set accuracy = 0.895000, Test set accuracy = 0.855400
 epoch 130/200. Took 0.060319 seconds. 
  Full-batch training loss = 0.382773, test loss = 0.484086
  Training set accuracy = 0.894500, Test set accuracy = 0.856000
 epoch 131/200. Took 0.050276 seconds. 
  Full-batch training loss = 0.381229, test loss = 0.482298
  Training set accuracy = 0.895000, Test set accuracy = 0.855800
 epoch 132/200. Took 0.058769 seconds. 
  Full-batch training loss = 0.379708, test loss = 0.481457
  Training set accuracy = 0.895000, Test set accuracy = 0.856100
 epoch 133/200. Took 0.0505 seconds. 
  Full-batch training loss = 0.378196, test loss = 0.480030
  Training set accuracy = 0.895000, Test set accuracy = 0.856600
 epoch 134/200. Took 0.051505 seconds. 
  Full-batch training loss = 0.376713, test loss = 0.479019
  Training set accuracy = 0.895500, Test set accuracy = 0.856900
 epoch 135/200. Took 0.056446 seconds. 
  Full-batch training loss = 0.375292, test loss = 0.478242
  Training set accuracy = 0.896000, Test set accuracy = 0.856900
 epoch 136/200. Took 0.044848 seconds. 
  Full-batch training loss = 0.373789, test loss = 0.476702
  Training set accuracy = 0.896000, Test set accuracy = 0.857100
 epoch 137/200. Took 0.044813 seconds. 
  Full-batch training loss = 0.372374, test loss = 0.475211
  Training set accuracy = 0.896000, Test set accuracy = 0.857700
 epoch 138/200. Took 0.04562 seconds. 
  Full-batch training loss = 0.370893, test loss = 0.474595
  Training set accuracy = 0.895500, Test set accuracy = 0.858200
 epoch 139/200. Took 0.053905 seconds. 
  Full-batch training loss = 0.369433, test loss = 0.473732
  Training set accuracy = 0.897500, Test set accuracy = 0.858300
 epoch 140/200. Took 0.051484 seconds. 
  Full-batch training loss = 0.368024, test loss = 0.472749
  Training set accuracy = 0.897500, Test set accuracy = 0.859100
 epoch 141/200. Took 0.055379 seconds. 
  Full-batch training loss = 0.366593, test loss = 0.471535
  Training set accuracy = 0.899500, Test set accuracy = 0.859100
 epoch 142/200. Took 0.074301 seconds. 
  Full-batch training loss = 0.365164, test loss = 0.470101
  Training set accuracy = 0.899000, Test set accuracy = 0.859400
 epoch 143/200. Took 0.080877 seconds. 
  Full-batch training loss = 0.363768, test loss = 0.469377
  Training set accuracy = 0.900500, Test set accuracy = 0.860200
 epoch 144/200. Took 0.093552 seconds. 
  Full-batch training loss = 0.362399, test loss = 0.468378
  Training set accuracy = 0.899500, Test set accuracy = 0.860000
 epoch 145/200. Took 0.07374 seconds. 
  Full-batch training loss = 0.360972, test loss = 0.467192
  Training set accuracy = 0.900000, Test set accuracy = 0.860400
 epoch 146/200. Took 0.054147 seconds. 
  Full-batch training loss = 0.359626, test loss = 0.466013
  Training set accuracy = 0.900000, Test set accuracy = 0.860700
 epoch 147/200. Took 0.053052 seconds. 
  Full-batch training loss = 0.358233, test loss = 0.464908
  Training set accuracy = 0.901000, Test set accuracy = 0.861500
 epoch 148/200. Took 0.051401 seconds. 
  Full-batch training loss = 0.356851, test loss = 0.464342
  Training set accuracy = 0.901000, Test set accuracy = 0.861400
 epoch 149/200. Took 0.050995 seconds. 
  Full-batch training loss = 0.355530, test loss = 0.463004
  Training set accuracy = 0.901500, Test set accuracy = 0.861400
 epoch 150/200. Took 0.058407 seconds. 
  Full-batch training loss = 0.354176, test loss = 0.461981
  Training set accuracy = 0.902000, Test set accuracy = 0.861900
 epoch 151/200. Took 0.045996 seconds. 
  Full-batch training loss = 0.352833, test loss = 0.461158
  Training set accuracy = 0.902000, Test set accuracy = 0.862300
 epoch 152/200. Took 0.04515 seconds. 
  Full-batch training loss = 0.351502, test loss = 0.460182
  Training set accuracy = 0.903500, Test set accuracy = 0.862600
 epoch 153/200. Took 0.055526 seconds. 
  Full-batch training loss = 0.350198, test loss = 0.459151
  Training set accuracy = 0.904000, Test set accuracy = 0.862400
 epoch 154/200. Took 0.050105 seconds. 
  Full-batch training loss = 0.348872, test loss = 0.458256
  Training set accuracy = 0.904000, Test set accuracy = 0.863000
 epoch 155/200. Took 0.077706 seconds. 
  Full-batch training loss = 0.347588, test loss = 0.457434
  Training set accuracy = 0.904500, Test set accuracy = 0.862900
 epoch 156/200. Took 0.050087 seconds. 
  Full-batch training loss = 0.346277, test loss = 0.456234
  Training set accuracy = 0.905000, Test set accuracy = 0.863900
 epoch 157/200. Took 0.048868 seconds. 
  Full-batch training loss = 0.344989, test loss = 0.455492
  Training set accuracy = 0.905000, Test set accuracy = 0.864100
 epoch 158/200. Took 0.047666 seconds. 
  Full-batch training loss = 0.343710, test loss = 0.454489
  Training set accuracy = 0.905500, Test set accuracy = 0.864500
 epoch 159/200. Took 0.047684 seconds. 
  Full-batch training loss = 0.342414, test loss = 0.453388
  Training set accuracy = 0.905500, Test set accuracy = 0.864800
 epoch 160/200. Took 0.040851 seconds. 
  Full-batch training loss = 0.341153, test loss = 0.452619
  Training set accuracy = 0.906500, Test set accuracy = 0.865400
 epoch 161/200. Took 0.071034 seconds. 
  Full-batch training loss = 0.339892, test loss = 0.451753
  Training set accuracy = 0.907500, Test set accuracy = 0.865100
 epoch 162/200. Took 0.078664 seconds. 
  Full-batch training loss = 0.338656, test loss = 0.450866
  Training set accuracy = 0.908500, Test set accuracy = 0.865600
 epoch 163/200. Took 0.048117 seconds. 
  Full-batch training loss = 0.337375, test loss = 0.449782
  Training set accuracy = 0.907000, Test set accuracy = 0.865700
 epoch 164/200. Took 0.062727 seconds. 
  Full-batch training loss = 0.336165, test loss = 0.449117
  Training set accuracy = 0.910000, Test set accuracy = 0.865700
 epoch 165/200. Took 0.055426 seconds. 
  Full-batch training loss = 0.334903, test loss = 0.447930
  Training set accuracy = 0.908500, Test set accuracy = 0.866500
 epoch 166/200. Took 0.072585 seconds. 
  Full-batch training loss = 0.333686, test loss = 0.446857
  Training set accuracy = 0.909500, Test set accuracy = 0.866600
 epoch 167/200. Took 0.063206 seconds. 
  Full-batch training loss = 0.332478, test loss = 0.446356
  Training set accuracy = 0.910000, Test set accuracy = 0.867400
 epoch 168/200. Took 0.046993 seconds. 
  Full-batch training loss = 0.331225, test loss = 0.445322
  Training set accuracy = 0.910000, Test set accuracy = 0.867400
 epoch 169/200. Took 0.049998 seconds. 
  Full-batch training loss = 0.330055, test loss = 0.444524
  Training set accuracy = 0.910500, Test set accuracy = 0.867700
 epoch 170/200. Took 0.042734 seconds. 
  Full-batch training loss = 0.328850, test loss = 0.443448
  Training set accuracy = 0.910000, Test set accuracy = 0.867800
 epoch 171/200. Took 0.055565 seconds. 
  Full-batch training loss = 0.327671, test loss = 0.442665
  Training set accuracy = 0.911500, Test set accuracy = 0.868300
 epoch 172/200. Took 0.048545 seconds. 
  Full-batch training loss = 0.326485, test loss = 0.442163
  Training set accuracy = 0.913000, Test set accuracy = 0.868300
 epoch 173/200. Took 0.058315 seconds. 
  Full-batch training loss = 0.325309, test loss = 0.440825
  Training set accuracy = 0.911000, Test set accuracy = 0.868800
 epoch 174/200. Took 0.052024 seconds. 
  Full-batch training loss = 0.324148, test loss = 0.440469
  Training set accuracy = 0.912500, Test set accuracy = 0.868600
 epoch 175/200. Took 0.065601 seconds. 
  Full-batch training loss = 0.322979, test loss = 0.439408
  Training set accuracy = 0.912000, Test set accuracy = 0.868700
 epoch 176/200. Took 0.066102 seconds. 
  Full-batch training loss = 0.321807, test loss = 0.438838
  Training set accuracy = 0.912500, Test set accuracy = 0.868600
 epoch 177/200. Took 0.049821 seconds. 
  Full-batch training loss = 0.320647, test loss = 0.437714
  Training set accuracy = 0.913000, Test set accuracy = 0.869600
 epoch 178/200. Took 0.066624 seconds. 
  Full-batch training loss = 0.319544, test loss = 0.437296
  Training set accuracy = 0.913000, Test set accuracy = 0.869600
 epoch 179/200. Took 0.049159 seconds. 
  Full-batch training loss = 0.318415, test loss = 0.435982
  Training set accuracy = 0.912000, Test set accuracy = 0.869900
 epoch 180/200. Took 0.049427 seconds. 
  Full-batch training loss = 0.317253, test loss = 0.435346
  Training set accuracy = 0.914000, Test set accuracy = 0.869700
 epoch 181/200. Took 0.047803 seconds. 
  Full-batch training loss = 0.316138, test loss = 0.434351
  Training set accuracy = 0.913500, Test set accuracy = 0.870900
 epoch 182/200. Took 0.061754 seconds. 
  Full-batch training loss = 0.315056, test loss = 0.434275
  Training set accuracy = 0.915500, Test set accuracy = 0.871000
 epoch 183/200. Took 0.065801 seconds. 
  Full-batch training loss = 0.313900, test loss = 0.432992
  Training set accuracy = 0.915000, Test set accuracy = 0.871300
 epoch 184/200. Took 0.047824 seconds. 
  Full-batch training loss = 0.312771, test loss = 0.432400
  Training set accuracy = 0.916000, Test set accuracy = 0.871500
 epoch 185/200. Took 0.054743 seconds. 
  Full-batch training loss = 0.311706, test loss = 0.431293
  Training set accuracy = 0.916500, Test set accuracy = 0.871800
 epoch 186/200. Took 0.067993 seconds. 
  Full-batch training loss = 0.310584, test loss = 0.430538
  Training set accuracy = 0.916500, Test set accuracy = 0.872000
 epoch 187/200. Took 0.069487 seconds. 
  Full-batch training loss = 0.309472, test loss = 0.429941
  Training set accuracy = 0.916500, Test set accuracy = 0.872100
 epoch 188/200. Took 0.080184 seconds. 
  Full-batch training loss = 0.308417, test loss = 0.429483
  Training set accuracy = 0.917000, Test set accuracy = 0.872300
 epoch 189/200. Took 0.051755 seconds. 
  Full-batch training loss = 0.307349, test loss = 0.428467
  Training set accuracy = 0.917500, Test set accuracy = 0.872300
 epoch 190/200. Took 0.068503 seconds. 
  Full-batch training loss = 0.306277, test loss = 0.427559
  Training set accuracy = 0.918000, Test set accuracy = 0.872400
 epoch 191/200. Took 0.066653 seconds. 
  Full-batch training loss = 0.305210, test loss = 0.427102
  Training set accuracy = 0.917500, Test set accuracy = 0.872900
 epoch 192/200. Took 0.054288 seconds. 
  Full-batch training loss = 0.304142, test loss = 0.425976
  Training set accuracy = 0.918500, Test set accuracy = 0.873100
 epoch 193/200. Took 0.079559 seconds. 
  Full-batch training loss = 0.303130, test loss = 0.424998
  Training set accuracy = 0.919000, Test set accuracy = 0.873200
 epoch 194/200. Took 0.050896 seconds. 
  Full-batch training loss = 0.302054, test loss = 0.424837
  Training set accuracy = 0.919500, Test set accuracy = 0.872700
 epoch 195/200. Took 0.06023 seconds. 
  Full-batch training loss = 0.300997, test loss = 0.424138
  Training set accuracy = 0.918500, Test set accuracy = 0.873000
 epoch 196/200. Took 0.048341 seconds. 
  Full-batch training loss = 0.299992, test loss = 0.423112
  Training set accuracy = 0.919000, Test set accuracy = 0.873800
 epoch 197/200. Took 0.050201 seconds. 
  Full-batch training loss = 0.298941, test loss = 0.422545
  Training set accuracy = 0.918500, Test set accuracy = 0.873400
 epoch 198/200. Took 0.044019 seconds. 
  Full-batch training loss = 0.297912, test loss = 0.421407
  Training set accuracy = 0.919500, Test set accuracy = 0.874500
 epoch 199/200. Took 0.057488 seconds. 
  Full-batch training loss = 0.296871, test loss = 0.420962
  Training set accuracy = 0.920500, Test set accuracy = 0.874200
 epoch 200/200. Took 0.052563 seconds. 
  Full-batch training loss = 0.295858, test loss = 0.420210
  Training set accuracy = 0.920500, Test set accuracy = 0.874400
Elapsed time is 51.846419 seconds.
End Training

learningRateRBM =

    0.0100

$$$Pretrain: FALSE	trainingExamples: 2000	epochsBP: 200	hiddenLayers: 1	hiddenUnits: 50	learningRateBP: 0.010
Loading data set: ../Data/mnist_uint8.mat
Setting parameters
Start Training
Number of training examples: 2000
Number of inputs: 784  Number of outputs: 10
Number of hidden layers: 1 (50)
Training binary-binary RBM in layer 1 (784   50) with CD1 for 50 epochs (batchsize: 100)
 epoch 1/50. Took 0.085468 seconds. Average reconstruction error is: 107.6716
 epoch 2/50. Took 0.08323 seconds. Average reconstruction error is: 60.9748
 epoch 3/50. Took 0.092627 seconds. Average reconstruction error is: 55.0537
 epoch 4/50. Took 0.085215 seconds. Average reconstruction error is: 50.3002
 epoch 5/50. Took 0.086396 seconds. Average reconstruction error is: 46.3739
 epoch 6/50. Took 0.085296 seconds. Average reconstruction error is: 43.4124
 epoch 7/50. Took 0.08287 seconds. Average reconstruction error is: 41.3424
 epoch 8/50. Took 0.080098 seconds. Average reconstruction error is: 39.8345
 epoch 9/50. Took 0.092571 seconds. Average reconstruction error is: 38.6255
 epoch 10/50. Took 0.091062 seconds. Average reconstruction error is: 37.6884
 epoch 11/50. Took 0.084101 seconds. Average reconstruction error is: 36.807
 epoch 12/50. Took 0.093229 seconds. Average reconstruction error is: 36.0864
 epoch 13/50. Took 0.11341 seconds. Average reconstruction error is: 35.379
 epoch 14/50. Took 0.11462 seconds. Average reconstruction error is: 34.8007
 epoch 15/50. Took 0.087292 seconds. Average reconstruction error is: 34.2122
 epoch 16/50. Took 0.091552 seconds. Average reconstruction error is: 33.6948
 epoch 17/50. Took 0.089686 seconds. Average reconstruction error is: 33.2685
 epoch 18/50. Took 0.087291 seconds. Average reconstruction error is: 32.8191
 epoch 19/50. Took 0.090055 seconds. Average reconstruction error is: 32.3628
 epoch 20/50. Took 0.096486 seconds. Average reconstruction error is: 32.0533
 epoch 21/50. Took 0.083893 seconds. Average reconstruction error is: 31.6944
 epoch 22/50. Took 0.083367 seconds. Average reconstruction error is: 31.3058
 epoch 23/50. Took 0.078389 seconds. Average reconstruction error is: 30.9803
 epoch 24/50. Took 0.077909 seconds. Average reconstruction error is: 30.5654
 epoch 25/50. Took 0.076493 seconds. Average reconstruction error is: 30.3186
 epoch 26/50. Took 0.081399 seconds. Average reconstruction error is: 30.0636
 epoch 27/50. Took 0.086802 seconds. Average reconstruction error is: 29.7618
 epoch 28/50. Took 0.084747 seconds. Average reconstruction error is: 29.4607
 epoch 29/50. Took 0.089443 seconds. Average reconstruction error is: 29.2051
 epoch 30/50. Took 0.087847 seconds. Average reconstruction error is: 29.0096
 epoch 31/50. Took 0.082623 seconds. Average reconstruction error is: 28.7419
 epoch 32/50. Took 0.091932 seconds. Average reconstruction error is: 28.5265
 epoch 33/50. Took 0.084804 seconds. Average reconstruction error is: 28.2937
 epoch 34/50. Took 0.085827 seconds. Average reconstruction error is: 28.0853
 epoch 35/50. Took 0.0776 seconds. Average reconstruction error is: 27.9089
 epoch 36/50. Took 0.083886 seconds. Average reconstruction error is: 27.6849
 epoch 37/50. Took 0.084524 seconds. Average reconstruction error is: 27.5229
 epoch 38/50. Took 0.081723 seconds. Average reconstruction error is: 27.32
 epoch 39/50. Took 0.087604 seconds. Average reconstruction error is: 27.13
 epoch 40/50. Took 0.083904 seconds. Average reconstruction error is: 26.9717
 epoch 41/50. Took 0.081543 seconds. Average reconstruction error is: 26.7976
 epoch 42/50. Took 0.084235 seconds. Average reconstruction error is: 26.7165
 epoch 43/50. Took 0.094454 seconds. Average reconstruction error is: 26.5411
 epoch 44/50. Took 0.085792 seconds. Average reconstruction error is: 26.3671
 epoch 45/50. Took 0.091322 seconds. Average reconstruction error is: 26.2197
 epoch 46/50. Took 0.11021 seconds. Average reconstruction error is: 26.0928
 epoch 47/50. Took 0.085708 seconds. Average reconstruction error is: 25.9581
 epoch 48/50. Took 0.093324 seconds. Average reconstruction error is: 25.818
 epoch 49/50. Took 0.084216 seconds. Average reconstruction error is: 25.7068
 epoch 50/50. Took 0.078034 seconds. Average reconstruction error is: 25.6139
Training NN  (784   50   10) with BackPropagation for 200 epochs (batchsize: 100)
 epoch 1/200. Took 0.046945 seconds. 
  Full-batch training loss = 2.115253, test loss = 2.099727
  Training set accuracy = 0.230000, Test set accuracy = 0.240600
 epoch 2/200. Took 0.051964 seconds. 
  Full-batch training loss = 1.848215, test loss = 1.839290
  Training set accuracy = 0.428500, Test set accuracy = 0.433000
 epoch 3/200. Took 0.049476 seconds. 
  Full-batch training loss = 1.642004, test loss = 1.636199
  Training set accuracy = 0.581000, Test set accuracy = 0.575800
 epoch 4/200. Took 0.046232 seconds. 
  Full-batch training loss = 1.480823, test loss = 1.475852
  Training set accuracy = 0.658000, Test set accuracy = 0.652800
 epoch 5/200. Took 0.049291 seconds. 
  Full-batch training loss = 1.353740, test loss = 1.349429
  Training set accuracy = 0.696500, Test set accuracy = 0.695000
 epoch 6/200. Took 0.041198 seconds. 
  Full-batch training loss = 1.252570, test loss = 1.250558
  Training set accuracy = 0.715500, Test set accuracy = 0.716100
 epoch 7/200. Took 0.053521 seconds. 
  Full-batch training loss = 1.170996, test loss = 1.169572
  Training set accuracy = 0.730000, Test set accuracy = 0.732800
 epoch 8/200. Took 0.053287 seconds. 
  Full-batch training loss = 1.104216, test loss = 1.103215
  Training set accuracy = 0.738000, Test set accuracy = 0.744800
 epoch 9/200. Took 0.055296 seconds. 
  Full-batch training loss = 1.048261, test loss = 1.048002
  Training set accuracy = 0.747500, Test set accuracy = 0.751600
 epoch 10/200. Took 0.057035 seconds. 
  Full-batch training loss = 1.001296, test loss = 1.001214
  Training set accuracy = 0.765500, Test set accuracy = 0.760200
 epoch 11/200. Took 0.043761 seconds. 
  Full-batch training loss = 0.961451, test loss = 0.962065
  Training set accuracy = 0.767500, Test set accuracy = 0.765900
 epoch 12/200. Took 0.050362 seconds. 
  Full-batch training loss = 0.926944, test loss = 0.928051
  Training set accuracy = 0.773000, Test set accuracy = 0.769100
 epoch 13/200. Took 0.060073 seconds. 
  Full-batch training loss = 0.896767, test loss = 0.898651
  Training set accuracy = 0.778000, Test set accuracy = 0.775200
 epoch 14/200. Took 0.052247 seconds. 
  Full-batch training loss = 0.870092, test loss = 0.872045
  Training set accuracy = 0.777500, Test set accuracy = 0.777000
 epoch 15/200. Took 0.054534 seconds. 
  Full-batch training loss = 0.846657, test loss = 0.849082
  Training set accuracy = 0.782500, Test set accuracy = 0.780900
 epoch 16/200. Took 0.047667 seconds. 
  Full-batch training loss = 0.825539, test loss = 0.827862
  Training set accuracy = 0.784500, Test set accuracy = 0.783900
 epoch 17/200. Took 0.055312 seconds. 
  Full-batch training loss = 0.806548, test loss = 0.809834
  Training set accuracy = 0.788500, Test set accuracy = 0.786600
 epoch 18/200. Took 0.054812 seconds. 
  Full-batch training loss = 0.789491, test loss = 0.793428
  Training set accuracy = 0.788500, Test set accuracy = 0.788400
 epoch 19/200. Took 0.054854 seconds. 
  Full-batch training loss = 0.773492, test loss = 0.777682
  Training set accuracy = 0.791000, Test set accuracy = 0.791600
 epoch 20/200. Took 0.047594 seconds. 
  Full-batch training loss = 0.759039, test loss = 0.763337
  Training set accuracy = 0.793500, Test set accuracy = 0.793200
 epoch 21/200. Took 0.05793 seconds. 
  Full-batch training loss = 0.745754, test loss = 0.750548
  Training set accuracy = 0.794000, Test set accuracy = 0.795200
 epoch 22/200. Took 0.053812 seconds. 
  Full-batch training loss = 0.733465, test loss = 0.739062
  Training set accuracy = 0.799500, Test set accuracy = 0.796700
 epoch 23/200. Took 0.047753 seconds. 
  Full-batch training loss = 0.722018, test loss = 0.727521
  Training set accuracy = 0.800000, Test set accuracy = 0.798800
 epoch 24/200. Took 0.049144 seconds. 
  Full-batch training loss = 0.711188, test loss = 0.717359
  Training set accuracy = 0.803500, Test set accuracy = 0.801300
 epoch 25/200. Took 0.046063 seconds. 
  Full-batch training loss = 0.701112, test loss = 0.707448
  Training set accuracy = 0.804000, Test set accuracy = 0.803600
 epoch 26/200. Took 0.046499 seconds. 
  Full-batch training loss = 0.691745, test loss = 0.698473
  Training set accuracy = 0.806000, Test set accuracy = 0.806000
 epoch 27/200. Took 0.047438 seconds. 
  Full-batch training loss = 0.682789, test loss = 0.689825
  Training set accuracy = 0.807500, Test set accuracy = 0.806500
 epoch 28/200. Took 0.046339 seconds. 
  Full-batch training loss = 0.674372, test loss = 0.682159
  Training set accuracy = 0.808500, Test set accuracy = 0.807900
 epoch 29/200. Took 0.045541 seconds. 
  Full-batch training loss = 0.666411, test loss = 0.674396
  Training set accuracy = 0.810500, Test set accuracy = 0.810300
 epoch 30/200. Took 0.042761 seconds. 
  Full-batch training loss = 0.658814, test loss = 0.667060
  Training set accuracy = 0.813000, Test set accuracy = 0.813000
 epoch 31/200. Took 0.044205 seconds. 
  Full-batch training loss = 0.651667, test loss = 0.660647
  Training set accuracy = 0.815000, Test set accuracy = 0.813300
 epoch 32/200. Took 0.048102 seconds. 
  Full-batch training loss = 0.644799, test loss = 0.653741
  Training set accuracy = 0.815000, Test set accuracy = 0.815200
 epoch 33/200. Took 0.043067 seconds. 
  Full-batch training loss = 0.638197, test loss = 0.647487
  Training set accuracy = 0.819500, Test set accuracy = 0.816400
 epoch 34/200. Took 0.048795 seconds. 
  Full-batch training loss = 0.631930, test loss = 0.641858
  Training set accuracy = 0.821500, Test set accuracy = 0.817700
 epoch 35/200. Took 0.047317 seconds. 
  Full-batch training loss = 0.625904, test loss = 0.636054
  Training set accuracy = 0.823000, Test set accuracy = 0.820200
 epoch 36/200. Took 0.047608 seconds. 
  Full-batch training loss = 0.620114, test loss = 0.630760
  Training set accuracy = 0.825000, Test set accuracy = 0.821300
 epoch 37/200. Took 0.048856 seconds. 
  Full-batch training loss = 0.614626, test loss = 0.625143
  Training set accuracy = 0.826000, Test set accuracy = 0.822900
 epoch 38/200. Took 0.045893 seconds. 
  Full-batch training loss = 0.609258, test loss = 0.620526
  Training set accuracy = 0.827500, Test set accuracy = 0.823400
 epoch 39/200. Took 0.049542 seconds. 
  Full-batch training loss = 0.604131, test loss = 0.615396
  Training set accuracy = 0.828500, Test set accuracy = 0.825300
 epoch 40/200. Took 0.048163 seconds. 
  Full-batch training loss = 0.599109, test loss = 0.610981
  Training set accuracy = 0.829000, Test set accuracy = 0.825700
 epoch 41/200. Took 0.048927 seconds. 
  Full-batch training loss = 0.594283, test loss = 0.606599
  Training set accuracy = 0.832500, Test set accuracy = 0.827000
 epoch 42/200. Took 0.047005 seconds. 
  Full-batch training loss = 0.589708, test loss = 0.601779
  Training set accuracy = 0.834500, Test set accuracy = 0.828300
 epoch 43/200. Took 0.048453 seconds. 
  Full-batch training loss = 0.585139, test loss = 0.597977
  Training set accuracy = 0.833500, Test set accuracy = 0.828800
 epoch 44/200. Took 0.049809 seconds. 
  Full-batch training loss = 0.580818, test loss = 0.593836
  Training set accuracy = 0.836500, Test set accuracy = 0.830500
 epoch 45/200. Took 0.041772 seconds. 
  Full-batch training loss = 0.576615, test loss = 0.590227
  Training set accuracy = 0.837500, Test set accuracy = 0.831600
 epoch 46/200. Took 0.047589 seconds. 
  Full-batch training loss = 0.572511, test loss = 0.586855
  Training set accuracy = 0.838000, Test set accuracy = 0.831900
 epoch 47/200. Took 0.057305 seconds. 
  Full-batch training loss = 0.568527, test loss = 0.582366
  Training set accuracy = 0.838500, Test set accuracy = 0.835000
 epoch 48/200. Took 0.047955 seconds. 
  Full-batch training loss = 0.564599, test loss = 0.579003
  Training set accuracy = 0.839500, Test set accuracy = 0.835800
 epoch 49/200. Took 0.042997 seconds. 
  Full-batch training loss = 0.560785, test loss = 0.576030
  Training set accuracy = 0.841500, Test set accuracy = 0.835100
 epoch 50/200. Took 0.045484 seconds. 
  Full-batch training loss = 0.557103, test loss = 0.572746
  Training set accuracy = 0.843000, Test set accuracy = 0.836500
 epoch 51/200. Took 0.047051 seconds. 
  Full-batch training loss = 0.553571, test loss = 0.569641
  Training set accuracy = 0.844000, Test set accuracy = 0.836100
 epoch 52/200. Took 0.051186 seconds. 
  Full-batch training loss = 0.550001, test loss = 0.566302
  Training set accuracy = 0.844000, Test set accuracy = 0.837700
 epoch 53/200. Took 0.050126 seconds. 
  Full-batch training loss = 0.546619, test loss = 0.563201
  Training set accuracy = 0.844500, Test set accuracy = 0.839100
 epoch 54/200. Took 0.043323 seconds. 
  Full-batch training loss = 0.543277, test loss = 0.560145
  Training set accuracy = 0.845000, Test set accuracy = 0.839500
 epoch 55/200. Took 0.047856 seconds. 
  Full-batch training loss = 0.539998, test loss = 0.557446
  Training set accuracy = 0.846000, Test set accuracy = 0.840600
 epoch 56/200. Took 0.051269 seconds. 
  Full-batch training loss = 0.536884, test loss = 0.554108
  Training set accuracy = 0.845500, Test set accuracy = 0.842300
 epoch 57/200. Took 0.058216 seconds. 
  Full-batch training loss = 0.533668, test loss = 0.551838
  Training set accuracy = 0.848000, Test set accuracy = 0.842200
 epoch 58/200. Took 0.054424 seconds. 
  Full-batch training loss = 0.530652, test loss = 0.548860
  Training set accuracy = 0.848500, Test set accuracy = 0.843800
 epoch 59/200. Took 0.052148 seconds. 
  Full-batch training loss = 0.527635, test loss = 0.546059
  Training set accuracy = 0.849000, Test set accuracy = 0.844400
 epoch 60/200. Took 0.05171 seconds. 
  Full-batch training loss = 0.524692, test loss = 0.543864
  Training set accuracy = 0.850000, Test set accuracy = 0.844600
 epoch 61/200. Took 0.055287 seconds. 
  Full-batch training loss = 0.521795, test loss = 0.541111
  Training set accuracy = 0.850500, Test set accuracy = 0.845700
 epoch 62/200. Took 0.057695 seconds. 
  Full-batch training loss = 0.519004, test loss = 0.538884
  Training set accuracy = 0.852000, Test set accuracy = 0.846600
 epoch 63/200. Took 0.097171 seconds. 
  Full-batch training loss = 0.516190, test loss = 0.536550
  Training set accuracy = 0.853500, Test set accuracy = 0.846700
 epoch 64/200. Took 0.050006 seconds. 
  Full-batch training loss = 0.513586, test loss = 0.534382
  Training set accuracy = 0.853500, Test set accuracy = 0.846200
 epoch 65/200. Took 0.055301 seconds. 
  Full-batch training loss = 0.510905, test loss = 0.532077
  Training set accuracy = 0.855500, Test set accuracy = 0.847900
 epoch 66/200. Took 0.045629 seconds. 
  Full-batch training loss = 0.508197, test loss = 0.529749
  Training set accuracy = 0.854500, Test set accuracy = 0.849200
 epoch 67/200. Took 0.053166 seconds. 
  Full-batch training loss = 0.505646, test loss = 0.527931
  Training set accuracy = 0.856000, Test set accuracy = 0.848700
 epoch 68/200. Took 0.048977 seconds. 
  Full-batch training loss = 0.503051, test loss = 0.525136
  Training set accuracy = 0.858000, Test set accuracy = 0.849900
 epoch 69/200. Took 0.047578 seconds. 
  Full-batch training loss = 0.500563, test loss = 0.522867
  Training set accuracy = 0.859000, Test set accuracy = 0.850900
 epoch 70/200. Took 0.047889 seconds. 
  Full-batch training loss = 0.498092, test loss = 0.520925
  Training set accuracy = 0.859500, Test set accuracy = 0.851200
 epoch 71/200. Took 0.059417 seconds. 
  Full-batch training loss = 0.495716, test loss = 0.519352
  Training set accuracy = 0.860500, Test set accuracy = 0.852300
 epoch 72/200. Took 0.060956 seconds. 
  Full-batch training loss = 0.493349, test loss = 0.516621
  Training set accuracy = 0.862000, Test set accuracy = 0.853900
 epoch 73/200. Took 0.05471 seconds. 
  Full-batch training loss = 0.490968, test loss = 0.515362
  Training set accuracy = 0.862000, Test set accuracy = 0.853500
 epoch 74/200. Took 0.060255 seconds. 
  Full-batch training loss = 0.488636, test loss = 0.512992
  Training set accuracy = 0.863000, Test set accuracy = 0.854300
 epoch 75/200. Took 0.052526 seconds. 
  Full-batch training loss = 0.486402, test loss = 0.510769
  Training set accuracy = 0.863500, Test set accuracy = 0.855800
 epoch 76/200. Took 0.04219 seconds. 
  Full-batch training loss = 0.484090, test loss = 0.509227
  Training set accuracy = 0.864500, Test set accuracy = 0.855200
 epoch 77/200. Took 0.050813 seconds. 
  Full-batch training loss = 0.481934, test loss = 0.507913
  Training set accuracy = 0.866000, Test set accuracy = 0.855200
 epoch 78/200. Took 0.048178 seconds. 
  Full-batch training loss = 0.479709, test loss = 0.505659
  Training set accuracy = 0.866500, Test set accuracy = 0.856700
 epoch 79/200. Took 0.047107 seconds. 
  Full-batch training loss = 0.477537, test loss = 0.504016
  Training set accuracy = 0.866000, Test set accuracy = 0.856400
 epoch 80/200. Took 0.048303 seconds. 
  Full-batch training loss = 0.475401, test loss = 0.502122
  Training set accuracy = 0.866000, Test set accuracy = 0.857100
 epoch 81/200. Took 0.050747 seconds. 
  Full-batch training loss = 0.473355, test loss = 0.500043
  Training set accuracy = 0.865500, Test set accuracy = 0.859500
 epoch 82/200. Took 0.048113 seconds. 
  Full-batch training loss = 0.471253, test loss = 0.498603
  Training set accuracy = 0.866500, Test set accuracy = 0.858900
 epoch 83/200. Took 0.045034 seconds. 
  Full-batch training loss = 0.469152, test loss = 0.497174
  Training set accuracy = 0.867000, Test set accuracy = 0.859300
 epoch 84/200. Took 0.043309 seconds. 
  Full-batch training loss = 0.467150, test loss = 0.495359
  Training set accuracy = 0.867500, Test set accuracy = 0.860200
 epoch 85/200. Took 0.046335 seconds. 
  Full-batch training loss = 0.465183, test loss = 0.493627
  Training set accuracy = 0.868500, Test set accuracy = 0.860400
 epoch 86/200. Took 0.046643 seconds. 
  Full-batch training loss = 0.463178, test loss = 0.492516
  Training set accuracy = 0.867500, Test set accuracy = 0.860400
 epoch 87/200. Took 0.047618 seconds. 
  Full-batch training loss = 0.461198, test loss = 0.490675
  Training set accuracy = 0.867500, Test set accuracy = 0.860800
 epoch 88/200. Took 0.048208 seconds. 
  Full-batch training loss = 0.459282, test loss = 0.489176
  Training set accuracy = 0.867500, Test set accuracy = 0.861300
 epoch 89/200. Took 0.049939 seconds. 
  Full-batch training loss = 0.457365, test loss = 0.487447
  Training set accuracy = 0.870000, Test set accuracy = 0.862100
 epoch 90/200. Took 0.051808 seconds. 
  Full-batch training loss = 0.455467, test loss = 0.486123
  Training set accuracy = 0.869500, Test set accuracy = 0.861700
 epoch 91/200. Took 0.049235 seconds. 
  Full-batch training loss = 0.453625, test loss = 0.484937
  Training set accuracy = 0.869500, Test set accuracy = 0.862200
 epoch 92/200. Took 0.052351 seconds. 
  Full-batch training loss = 0.451728, test loss = 0.483196
  Training set accuracy = 0.869500, Test set accuracy = 0.863300
 epoch 93/200. Took 0.043997 seconds. 
  Full-batch training loss = 0.449937, test loss = 0.481467
  Training set accuracy = 0.869500, Test set accuracy = 0.864000
 epoch 94/200. Took 0.045216 seconds. 
  Full-batch training loss = 0.448084, test loss = 0.480408
  Training set accuracy = 0.870500, Test set accuracy = 0.864100
 epoch 95/200. Took 0.047956 seconds. 
  Full-batch training loss = 0.446293, test loss = 0.479076
  Training set accuracy = 0.871000, Test set accuracy = 0.864100
 epoch 96/200. Took 0.043014 seconds. 
  Full-batch training loss = 0.444553, test loss = 0.477733
  Training set accuracy = 0.871000, Test set accuracy = 0.864700
 epoch 97/200. Took 0.050085 seconds. 
  Full-batch training loss = 0.442742, test loss = 0.476276
  Training set accuracy = 0.872000, Test set accuracy = 0.864800
 epoch 98/200. Took 0.044601 seconds. 
  Full-batch training loss = 0.441004, test loss = 0.474880
  Training set accuracy = 0.872500, Test set accuracy = 0.865900
 epoch 99/200. Took 0.047269 seconds. 
  Full-batch training loss = 0.439299, test loss = 0.473666
  Training set accuracy = 0.872000, Test set accuracy = 0.865700
 epoch 100/200. Took 0.049458 seconds. 
  Full-batch training loss = 0.437637, test loss = 0.472601
  Training set accuracy = 0.873000, Test set accuracy = 0.866300
 epoch 101/200. Took 0.048191 seconds. 
  Full-batch training loss = 0.435916, test loss = 0.470808
  Training set accuracy = 0.873500, Test set accuracy = 0.866900
 epoch 102/200. Took 0.047648 seconds. 
  Full-batch training loss = 0.434233, test loss = 0.469764
  Training set accuracy = 0.874500, Test set accuracy = 0.867500
 epoch 103/200. Took 0.047634 seconds. 
  Full-batch training loss = 0.432555, test loss = 0.468588
  Training set accuracy = 0.874000, Test set accuracy = 0.867300
 epoch 104/200. Took 0.05161 seconds. 
  Full-batch training loss = 0.430948, test loss = 0.466891
  Training set accuracy = 0.875000, Test set accuracy = 0.868500
 epoch 105/200. Took 0.052158 seconds. 
  Full-batch training loss = 0.429299, test loss = 0.465695
  Training set accuracy = 0.875500, Test set accuracy = 0.868100
 epoch 106/200. Took 0.048521 seconds. 
  Full-batch training loss = 0.427692, test loss = 0.464557
  Training set accuracy = 0.877500, Test set accuracy = 0.867900
 epoch 107/200. Took 0.05036 seconds. 
  Full-batch training loss = 0.426075, test loss = 0.463472
  Training set accuracy = 0.876000, Test set accuracy = 0.869000
 epoch 108/200. Took 0.049915 seconds. 
  Full-batch training loss = 0.424475, test loss = 0.462337
  Training set accuracy = 0.877000, Test set accuracy = 0.869400
 epoch 109/200. Took 0.052848 seconds. 
  Full-batch training loss = 0.422976, test loss = 0.461625
  Training set accuracy = 0.879000, Test set accuracy = 0.869500
 epoch 110/200. Took 0.048524 seconds. 
  Full-batch training loss = 0.421331, test loss = 0.459868
  Training set accuracy = 0.878500, Test set accuracy = 0.870600
 epoch 111/200. Took 0.045357 seconds. 
  Full-batch training loss = 0.419816, test loss = 0.459224
  Training set accuracy = 0.880500, Test set accuracy = 0.870400
 epoch 112/200. Took 0.050063 seconds. 
  Full-batch training loss = 0.418252, test loss = 0.457733
  Training set accuracy = 0.879500, Test set accuracy = 0.871000
 epoch 113/200. Took 0.04505 seconds. 
  Full-batch training loss = 0.416736, test loss = 0.456734
  Training set accuracy = 0.881000, Test set accuracy = 0.871000
 epoch 114/200. Took 0.046571 seconds. 
  Full-batch training loss = 0.415244, test loss = 0.455760
  Training set accuracy = 0.880500, Test set accuracy = 0.871200
 epoch 115/200. Took 0.049384 seconds. 
  Full-batch training loss = 0.413726, test loss = 0.454475
  Training set accuracy = 0.881000, Test set accuracy = 0.871100
 epoch 116/200. Took 0.056122 seconds. 
  Full-batch training loss = 0.412310, test loss = 0.453019
  Training set accuracy = 0.881000, Test set accuracy = 0.872900
 epoch 117/200. Took 0.05116 seconds. 
  Full-batch training loss = 0.410804, test loss = 0.452466
  Training set accuracy = 0.882000, Test set accuracy = 0.871700
 epoch 118/200. Took 0.045645 seconds. 
  Full-batch training loss = 0.409313, test loss = 0.451047
  Training set accuracy = 0.882500, Test set accuracy = 0.872200
 epoch 119/200. Took 0.046444 seconds. 
  Full-batch training loss = 0.407863, test loss = 0.450287
  Training set accuracy = 0.882500, Test set accuracy = 0.872500
 epoch 120/200. Took 0.050735 seconds. 
  Full-batch training loss = 0.406433, test loss = 0.448942
  Training set accuracy = 0.883000, Test set accuracy = 0.873500
 epoch 121/200. Took 0.049257 seconds. 
  Full-batch training loss = 0.405004, test loss = 0.448086
  Training set accuracy = 0.883500, Test set accuracy = 0.874000
 epoch 122/200. Took 0.046438 seconds. 
  Full-batch training loss = 0.403604, test loss = 0.447200
  Training set accuracy = 0.883000, Test set accuracy = 0.873800
 epoch 123/200. Took 0.048336 seconds. 
  Full-batch training loss = 0.402173, test loss = 0.446214
  Training set accuracy = 0.883500, Test set accuracy = 0.874400
 epoch 124/200. Took 0.049976 seconds. 
  Full-batch training loss = 0.400780, test loss = 0.445146
  Training set accuracy = 0.884000, Test set accuracy = 0.874300
 epoch 125/200. Took 0.048326 seconds. 
  Full-batch training loss = 0.399410, test loss = 0.443945
  Training set accuracy = 0.885000, Test set accuracy = 0.875300
 epoch 126/200. Took 0.048696 seconds. 
  Full-batch training loss = 0.398059, test loss = 0.443316
  Training set accuracy = 0.885000, Test set accuracy = 0.874900
 epoch 127/200. Took 0.059521 seconds. 
  Full-batch training loss = 0.396662, test loss = 0.442044
  Training set accuracy = 0.886000, Test set accuracy = 0.875300
 epoch 128/200. Took 0.050272 seconds. 
  Full-batch training loss = 0.395323, test loss = 0.441050
  Training set accuracy = 0.885500, Test set accuracy = 0.875200
 epoch 129/200. Took 0.051183 seconds. 
  Full-batch training loss = 0.393985, test loss = 0.440450
  Training set accuracy = 0.886000, Test set accuracy = 0.875100
 epoch 130/200. Took 0.047737 seconds. 
  Full-batch training loss = 0.392634, test loss = 0.439306
  Training set accuracy = 0.887000, Test set accuracy = 0.875600
 epoch 131/200. Took 0.047236 seconds. 
  Full-batch training loss = 0.391325, test loss = 0.438543
  Training set accuracy = 0.887000, Test set accuracy = 0.875900
 epoch 132/200. Took 0.047753 seconds. 
  Full-batch training loss = 0.390015, test loss = 0.437409
  Training set accuracy = 0.888000, Test set accuracy = 0.875800
 epoch 133/200. Took 0.041586 seconds. 
  Full-batch training loss = 0.388680, test loss = 0.436683
  Training set accuracy = 0.889000, Test set accuracy = 0.875100
 epoch 134/200. Took 0.043571 seconds. 
  Full-batch training loss = 0.387386, test loss = 0.435635
  Training set accuracy = 0.888500, Test set accuracy = 0.875700
 epoch 135/200. Took 0.045368 seconds. 
  Full-batch training loss = 0.386107, test loss = 0.434837
  Training set accuracy = 0.889500, Test set accuracy = 0.876000
 epoch 136/200. Took 0.049444 seconds. 
  Full-batch training loss = 0.384852, test loss = 0.434033
  Training set accuracy = 0.888500, Test set accuracy = 0.875900
 epoch 137/200. Took 0.051257 seconds. 
  Full-batch training loss = 0.383565, test loss = 0.433025
  Training set accuracy = 0.889500, Test set accuracy = 0.876500
 epoch 138/200. Took 0.049089 seconds. 
  Full-batch training loss = 0.382329, test loss = 0.431931
  Training set accuracy = 0.890000, Test set accuracy = 0.877300
 epoch 139/200. Took 0.046406 seconds. 
  Full-batch training loss = 0.381066, test loss = 0.431152
  Training set accuracy = 0.891500, Test set accuracy = 0.877400
 epoch 140/200. Took 0.052469 seconds. 
  Full-batch training loss = 0.379839, test loss = 0.430380
  Training set accuracy = 0.891500, Test set accuracy = 0.877500
 epoch 141/200. Took 0.051518 seconds. 
  Full-batch training loss = 0.378578, test loss = 0.429629
  Training set accuracy = 0.892000, Test set accuracy = 0.877300
 epoch 142/200. Took 0.043837 seconds. 
  Full-batch training loss = 0.377375, test loss = 0.428756
  Training set accuracy = 0.892000, Test set accuracy = 0.877300
 epoch 143/200. Took 0.050304 seconds. 
  Full-batch training loss = 0.376145, test loss = 0.427957
  Training set accuracy = 0.892000, Test set accuracy = 0.878200
 epoch 144/200. Took 0.044123 seconds. 
  Full-batch training loss = 0.374946, test loss = 0.427300
  Training set accuracy = 0.891000, Test set accuracy = 0.877800
 epoch 145/200. Took 0.04502 seconds. 
  Full-batch training loss = 0.373729, test loss = 0.426478
  Training set accuracy = 0.891500, Test set accuracy = 0.878300
 epoch 146/200. Took 0.046568 seconds. 
  Full-batch training loss = 0.372542, test loss = 0.425426
  Training set accuracy = 0.891500, Test set accuracy = 0.878700
 epoch 147/200. Took 0.043384 seconds. 
  Full-batch training loss = 0.371346, test loss = 0.424837
  Training set accuracy = 0.892000, Test set accuracy = 0.878400
 epoch 148/200. Took 0.049688 seconds. 
  Full-batch training loss = 0.370189, test loss = 0.424244
  Training set accuracy = 0.892000, Test set accuracy = 0.878300
 epoch 149/200. Took 0.047726 seconds. 
  Full-batch training loss = 0.369004, test loss = 0.423115
  Training set accuracy = 0.892000, Test set accuracy = 0.879500
 epoch 150/200. Took 0.042851 seconds. 
  Full-batch training loss = 0.367861, test loss = 0.422653
  Training set accuracy = 0.893500, Test set accuracy = 0.878800
 epoch 151/200. Took 0.044268 seconds. 
  Full-batch training loss = 0.366701, test loss = 0.421683
  Training set accuracy = 0.893000, Test set accuracy = 0.879900
 epoch 152/200. Took 0.04621 seconds. 
  Full-batch training loss = 0.365554, test loss = 0.420693
  Training set accuracy = 0.893500, Test set accuracy = 0.880200
 epoch 153/200. Took 0.04981 seconds. 
  Full-batch training loss = 0.364431, test loss = 0.420410
  Training set accuracy = 0.893500, Test set accuracy = 0.879900
 epoch 154/200. Took 0.044856 seconds. 
  Full-batch training loss = 0.363273, test loss = 0.419301
  Training set accuracy = 0.893500, Test set accuracy = 0.880800
 epoch 155/200. Took 0.04618 seconds. 
  Full-batch training loss = 0.362160, test loss = 0.418700
  Training set accuracy = 0.894000, Test set accuracy = 0.880500
 epoch 156/200. Took 0.052609 seconds. 
  Full-batch training loss = 0.361028, test loss = 0.417943
  Training set accuracy = 0.894000, Test set accuracy = 0.880600
 epoch 157/200. Took 0.054064 seconds. 
  Full-batch training loss = 0.359930, test loss = 0.417005
  Training set accuracy = 0.894000, Test set accuracy = 0.880800
 epoch 158/200. Took 0.048234 seconds. 
  Full-batch training loss = 0.358797, test loss = 0.416637
  Training set accuracy = 0.894000, Test set accuracy = 0.881100
 epoch 159/200. Took 0.05037 seconds. 
  Full-batch training loss = 0.357724, test loss = 0.415790
  Training set accuracy = 0.895000, Test set accuracy = 0.880900
 epoch 160/200. Took 0.043715 seconds. 
  Full-batch training loss = 0.356621, test loss = 0.415250
  Training set accuracy = 0.895000, Test set accuracy = 0.880900
 epoch 161/200. Took 0.048422 seconds. 
  Full-batch training loss = 0.355535, test loss = 0.414514
  Training set accuracy = 0.894500, Test set accuracy = 0.881100
 epoch 162/200. Took 0.049818 seconds. 
  Full-batch training loss = 0.354489, test loss = 0.413513
  Training set accuracy = 0.895000, Test set accuracy = 0.881400
 epoch 163/200. Took 0.050791 seconds. 
  Full-batch training loss = 0.353412, test loss = 0.412973
  Training set accuracy = 0.895500, Test set accuracy = 0.881600
 epoch 164/200. Took 0.04997 seconds. 
  Full-batch training loss = 0.352322, test loss = 0.412360
  Training set accuracy = 0.895500, Test set accuracy = 0.881900
 epoch 165/200. Took 0.053225 seconds. 
  Full-batch training loss = 0.351270, test loss = 0.411902
  Training set accuracy = 0.896000, Test set accuracy = 0.881800
 epoch 166/200. Took 0.053044 seconds. 
  Full-batch training loss = 0.350226, test loss = 0.410820
  Training set accuracy = 0.896500, Test set accuracy = 0.882300
 epoch 167/200. Took 0.048338 seconds. 
  Full-batch training loss = 0.349152, test loss = 0.410336
  Training set accuracy = 0.896000, Test set accuracy = 0.882300
 epoch 168/200. Took 0.047982 seconds. 
  Full-batch training loss = 0.348121, test loss = 0.409811
  Training set accuracy = 0.896500, Test set accuracy = 0.882400
 epoch 169/200. Took 0.04801 seconds. 
  Full-batch training loss = 0.347076, test loss = 0.408880
  Training set accuracy = 0.897000, Test set accuracy = 0.882400
 epoch 170/200. Took 0.043674 seconds. 
  Full-batch training loss = 0.346046, test loss = 0.408332
  Training set accuracy = 0.897500, Test set accuracy = 0.882700
 epoch 171/200. Took 0.052322 seconds. 
  Full-batch training loss = 0.345056, test loss = 0.407733
  Training set accuracy = 0.899000, Test set accuracy = 0.882700
 epoch 172/200. Took 0.051707 seconds. 
  Full-batch training loss = 0.344021, test loss = 0.407140
  Training set accuracy = 0.898500, Test set accuracy = 0.882700
 epoch 173/200. Took 0.047859 seconds. 
  Full-batch training loss = 0.342999, test loss = 0.406440
  Training set accuracy = 0.899000, Test set accuracy = 0.882800
 epoch 174/200. Took 0.045841 seconds. 
  Full-batch training loss = 0.342018, test loss = 0.405553
  Training set accuracy = 0.898500, Test set accuracy = 0.883500
 epoch 175/200. Took 0.049315 seconds. 
  Full-batch training loss = 0.341021, test loss = 0.405513
  Training set accuracy = 0.900500, Test set accuracy = 0.883500
 epoch 176/200. Took 0.048169 seconds. 
  Full-batch training loss = 0.340027, test loss = 0.404422
  Training set accuracy = 0.900000, Test set accuracy = 0.883100
 epoch 177/200. Took 0.052402 seconds. 
  Full-batch training loss = 0.339014, test loss = 0.403827
  Training set accuracy = 0.901500, Test set accuracy = 0.883100
 epoch 178/200. Took 0.048759 seconds. 
  Full-batch training loss = 0.338035, test loss = 0.403191
  Training set accuracy = 0.902500, Test set accuracy = 0.884000
if system_dependent('IsDebugMode')==1, dbquit; end
DeepBPN_RBM_example_complete_MNIST
